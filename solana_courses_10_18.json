{
  "courses": [
    {
      "id": "course-034",
      "slug": "solana-reliability",
      "title": "Reliability Engineering for Solana",
      "description": "Production-focused reliability engineering for Solana systems: fault tolerance, retries, deadlines, circuit breakers, and graceful degradation with measurable operational outcomes.",
      "difficulty": "advanced",
      "duration": "6 weeks",
      "totalXP": 2100,
      "tags": [
        "reliability",
        "fault-tolerance",
        "resilience",
        "production"
      ],
      "imageUrl": "/images/courses/solana-reliability.svg",
      "modules": [
        {
          "id": "mod-10-1",
          "title": "Fault Tolerance Patterns",
          "description": "Implement fault-tolerance building blocks with clear failure classification, retry boundaries, and deterministic recovery behavior.",
          "lessons": [
            {
              "id": "lesson-10-1-1",
              "type": "content",
              "title": "Understanding Fault Tolerance",
              "content": "Fault tolerance in Solana systems is not just about catching errors. It is about deciding which failures are safe to retry, which should fail fast, and how to preserve user trust while doing both.\n\nA practical reliability model starts with failure classes:\n1) transient failures (timeouts, temporary RPC unavailability),\n2) persistent external failures (rate limits, prolonged endpoint degradation),\n3) deterministic business failures (invalid input, invariant violations).\n\nTransient failures may justify bounded retries with backoff. Deterministic business failures should not be retried because retries only add latency and load. Persistent external failures often require fallback endpoints, degraded features, or temporary protection modes.\n\nIn Solana workflows, reliability is tightly coupled to freshness constraints. A request can be logically valid but still fail if supporting state has shifted (for example stale quote windows or expired blockhash contexts in client workflows). Reliable systems therefore combine retry logic with freshness checks and clear abort conditions.\n\nDefensive engineering means defining policies explicitly:\n- maximum retry count,\n- per-attempt timeout,\n- total deadline budget,\n- fallback behavior after budget exhaustion,\n- user-facing messaging for each failure class.\n\nWithout explicit budgets, systems drift into infinite retry loops or fail too early. With explicit budgets, behavior is predictable and testable.\n\nFor production teams, observability is mandatory. Every failed operation should include a deterministic reason code and context fields (attempt number, endpoint, elapsed time, policy branch). This turns reliability from guesswork into measurable behavior.\n\nReliable systems do not promise zero failures. They promise controlled failure behavior: bounded latency, clear outcomes, and safe degradation under stress."
            },
            {
              "id": "lesson-10-1-2",
              "type": "challenge",
              "title": "Retry Mechanism Challenge",
              "description": "Implement an exponential backoff retry mechanism for handling transient failures.",
              "starterCode": "#[derive(Debug, Clone, Copy, PartialEq)]\npub enum BackoffStrategy {\n    Fixed,\n    Linear,\n    Exponential,\n}\n\npub struct RetryConfig {\n    pub max_attempts: u32,\n    pub base_delay_ms: u64,\n    pub strategy: BackoffStrategy,\n}\n\npub struct RetryMechanism {\n    config: RetryConfig,\n}\n\nimpl RetryMechanism {\n    pub fn new(config: RetryConfig) -> Self {\n        Self { config }\n    }\n\n    pub fn calculate_delay(&self, attempt: u32) -> u64 {\n        // TODO: Calculate delay based on strategy\n        // Fixed: always return base_delay_ms\n        // Linear: base_delay_ms * attempt\n        // Exponential: base_delay_ms * 2^attempt\n        // Return 0 if attempt >= max_attempts\n        todo!(\"Implement calculate_delay\")\n    }\n\n    pub fn should_retry(&self, attempt: u32) -> bool {\n        // TODO: Return true if we should attempt another retry\n        todo!(\"Implement should_retry\")\n    }\n}",
              "solution": "#[derive(Debug, Clone, Copy, PartialEq)]\npub enum BackoffStrategy {\n    Fixed,\n    Linear,\n    Exponential,\n}\n\npub struct RetryConfig {\n    pub max_attempts: u32,\n    pub base_delay_ms: u64,\n    pub strategy: BackoffStrategy,\n}\n\npub struct RetryMechanism {\n    config: RetryConfig,\n}\n\nimpl RetryMechanism {\n    pub fn new(config: RetryConfig) -> Self {\n        Self { config }\n    }\n\n    pub fn calculate_delay(&self, attempt: u32) -> u64 {\n        if attempt >= self.config.max_attempts {\n            return 0;\n        }\n\n        match self.config.strategy {\n            BackoffStrategy::Fixed => self.config.base_delay_ms,\n            BackoffStrategy::Linear => self.config.base_delay_ms * attempt as u64,\n            BackoffStrategy::Exponential => {\n                self.config.base_delay_ms * 2_u64.pow(attempt)\n            }\n        }\n    }\n\n    pub fn should_retry(&self, attempt: u32) -> bool {\n        attempt < self.config.max_attempts\n    }\n}",
              "hints": [
                "Use match on the BackoffStrategy enum to handle each case",
                "For exponential backoff, use 2_u64.pow(attempt) to calculate the multiplier",
                "should_retry simply checks if attempt is less than max_attempts"
              ],
              "testCases": [
                {
                  "input": {
                    "strategy": "Fixed",
                    "max_attempts": 3,
                    "base_delay_ms": 100,
                    "attempt": 1
                  },
                  "expected": {
                    "delay": 100,
                    "should_retry": true
                  }
                },
                {
                  "input": {
                    "strategy": "Linear",
                    "max_attempts": 3,
                    "base_delay_ms": 100,
                    "attempt": 2
                  },
                  "expected": {
                    "delay": 200,
                    "should_retry": true
                  }
                },
                {
                  "input": {
                    "strategy": "Exponential",
                    "max_attempts": 3,
                    "base_delay_ms": 100,
                    "attempt": 2
                  },
                  "expected": {
                    "delay": 400,
                    "should_retry": true
                  }
                },
                {
                  "input": {
                    "strategy": "Fixed",
                    "max_attempts": 3,
                    "base_delay_ms": 100,
                    "attempt": 3
                  },
                  "expected": {
                    "delay": 0,
                    "should_retry": false
                  }
                }
              ]
            },
            {
              "id": "lesson-10-1-3",
              "type": "challenge",
              "title": "Deadline Manager Challenge",
              "description": "Implement a deadline management system to enforce time limits on operations.",
              "starterCode": "pub struct Deadline {\n    timestamp: u64,\n}\n\npub struct DeadlineManager;\n\nimpl DeadlineManager {\n    pub fn new_deadline(duration_ms: u64, current_time: u64) -> Deadline {\n        // TODO: Create a deadline that expires after duration_ms from current_time\n        todo!(\"Implement new_deadline\")\n    }\n\n    pub fn is_expired(&self, deadline: &Deadline, current_time: u64) -> bool {\n        // TODO: Return true if the deadline has passed\n        todo!(\"Implement is_expired\")\n    }\n\n    pub fn time_remaining(&self, deadline: &Deadline, current_time: u64) -> u64 {\n        // TODO: Return remaining time in ms, or 0 if expired\n        todo!(\"Implement time_remaining\")\n    }\n\n    pub fn extend_deadline(&self, deadline: &mut Deadline, extension_ms: u64, max_extension: u64) -> bool {\n        // TODO: Extend deadline by extension_ms, but not beyond max_extension from original\n        // Return true if extension was applied\n        todo!(\"Implement extend_deadline\")\n    }\n}",
              "solution": "pub struct Deadline {\n    timestamp: u64,\n}\n\npub struct DeadlineManager;\n\nimpl DeadlineManager {\n    pub fn new_deadline(duration_ms: u64, current_time: u64) -> Deadline {\n        Deadline {\n            timestamp: current_time + duration_ms,\n        }\n    }\n\n    pub fn is_expired(&self, deadline: &Deadline, current_time: u64) -> bool {\n        current_time >= deadline.timestamp\n    }\n\n    pub fn time_remaining(&self, deadline: &Deadline, current_time: u64) -> u64 {\n        if current_time >= deadline.timestamp {\n            0\n        } else {\n            deadline.timestamp - current_time\n        }\n    }\n\n    pub fn extend_deadline(&self, deadline: &mut Deadline, extension_ms: u64, max_extension: u64) -> bool {\n        let new_timestamp = deadline.timestamp + extension_ms;\n        let max_timestamp = deadline.timestamp + max_extension;\n\n        if new_timestamp <= max_timestamp {\n            deadline.timestamp = new_timestamp;\n            true\n        } else {\n            false\n        }\n    }\n}",
              "hints": [
                "Store the absolute expiration timestamp in the Deadline struct",
                "For time_remaining, subtract current_time from deadline timestamp if not expired",
                "For extend_deadline, calculate the new timestamp and check against max allowed"
              ],
              "testCases": [
                {
                  "input": {
                    "operation": "new_deadline",
                    "duration_ms": 5000,
                    "current_time": 1000
                  },
                  "expected": {
                    "timestamp": 6000
                  }
                },
                {
                  "input": {
                    "operation": "is_expired",
                    "deadline_timestamp": 6000,
                    "current_time": 7000
                  },
                  "expected": {
                    "expired": true
                  }
                },
                {
                  "input": {
                    "operation": "time_remaining",
                    "deadline_timestamp": 6000,
                    "current_time": 4000
                  },
                  "expected": {
                    "remaining": 2000
                  }
                },
                {
                  "input": {
                    "operation": "extend_deadline",
                    "deadline_timestamp": 6000,
                    "extension_ms": 1000,
                    "max_extension": 2000
                  },
                  "expected": {
                    "success": true,
                    "new_timestamp": 7000
                  }
                }
              ]
            },
            {
              "id": "lesson-10-1-4",
              "type": "challenge",
              "title": "Fallback Handler Challenge",
              "description": "Implement a fallback mechanism that provides alternative execution paths when primary operations fail.",
              "starterCode": "#[derive(Debug, Clone, PartialEq)]\npub enum OperationResult<T> {\n    Success(T),\n    Fallback(T),\n    Failure,\n}\n\npub struct FallbackHandler<T> {\n    primary: fn() -> Option<T>,\n    fallback: fn() -> Option<T>,\n}\n\nimpl<T: Clone> FallbackHandler<T> {\n    pub fn new(primary: fn() -> Option<T>, fallback: fn() -> Option<T>) -> Self {\n        Self { primary, fallback }\n    }\n\n    pub fn execute(&self) -> OperationResult<T> {\n        // TODO: Try primary first, then fallback if primary fails\n        // Return Success if primary succeeds, Fallback if fallback succeeds, Failure if both fail\n        todo!(\"Implement execute\")\n    }\n\n    pub fn execute_with_retry(&self, max_retries: u32) -> OperationResult<T> {\n        // TODO: Retry primary up to max_retries times before trying fallback\n        todo!(\"Implement execute_with_retry\")\n    }\n}",
              "solution": "#[derive(Debug, Clone, PartialEq)]\npub enum OperationResult<T> {\n    Success(T),\n    Fallback(T),\n    Failure,\n}\n\npub struct FallbackHandler<T> {\n    primary: fn() -> Option<T>,\n    fallback: fn() -> Option<T>,\n}\n\nimpl<T: Clone> FallbackHandler<T> {\n    pub fn new(primary: fn() -> Option<T>, fallback: fn() -> Option<T>) -> Self {\n        Self { primary, fallback }\n    }\n\n    pub fn execute(&self) -> OperationResult<T> {\n        if let Some(result) = (self.primary)() {\n            OperationResult::Success(result)\n        } else if let Some(result) = (self.fallback)() {\n            OperationResult::Fallback(result)\n        } else {\n            OperationResult::Failure\n        }\n    }\n\n    pub fn execute_with_retry(&self, max_retries: u32) -> OperationResult<T> {\n        for _ in 0..max_retries {\n            if let Some(result) = (self.primary)() {\n                return OperationResult::Success(result);\n            }\n        }\n\n        if let Some(result) = (self.fallback)() {\n            OperationResult::Fallback(result)\n        } else {\n            OperationResult::Failure\n        }\n    }\n}",
              "hints": [
                "Call the primary function first and check if it returns Some",
                "Only call fallback if primary returns None",
                "For retry, loop max_retries times trying primary before falling back"
              ],
              "testCases": [
                {
                  "input": {
                    "primary_succeeds": true,
                    "fallback_succeeds": true
                  },
                  "expected": {
                    "result": "Success"
                  }
                },
                {
                  "input": {
                    "primary_succeeds": false,
                    "fallback_succeeds": true
                  },
                  "expected": {
                    "result": "Fallback"
                  }
                },
                {
                  "input": {
                    "primary_succeeds": false,
                    "fallback_succeeds": false
                  },
                  "expected": {
                    "result": "Failure"
                  }
                }
              ]
            }
          ]
        },
        {
          "id": "mod-10-2",
          "title": "Resilience Mechanisms",
          "description": "Build resilience mechanisms (circuit breakers, bulkheads, and rate controls) that protect core user flows during provider instability.",
          "lessons": [
            {
              "id": "lesson-10-2-1",
              "type": "content",
              "title": "Resilience Patterns",
              "content": "Resilience patterns are controls that prevent localized failures from becoming system-wide incidents. On Solana integrations, they are especially important because provider health can change quickly under bursty network conditions.\n\nCircuit breaker pattern:\n- closed: normal operation,\n- open: block requests after repeated failures,\n- half-open: probe recovery with controlled trial requests.\n\nA good breaker uses deterministic thresholds and cooldowns, not ad hoc toggles. It should expose state transitions for monitoring and post-incident review.\n\nBulkhead pattern isolates resource pools so one failing workflow (for example expensive quote refresh loops) cannot starve unrelated workflows (like portfolio reads).\n\nRate limiting controls outbound pressure to providers. Proper limits reduce 429 storms and improve overall success rate. Token-bucket strategies are useful because they allow short bursts while preserving long-term bounds.\n\nThese patterns should be coordinated, not layered blindly. For example, aggressive retries plus weak rate limiting can bypass the intent of a circuit breaker. Policy composition must be reviewed end-to-end.\n\nA mature resilience stack includes:\n- deterministic policy config,\n- simulation fixtures for calm vs stressed traffic,\n- dashboard visibility for breaker states and reject reasons,\n- explicit user copy for degraded mode.\n\nResilience is successful when users experience predictable service quality under failure, not when systems appear perfect in ideal conditions."
            },
            {
              "id": "lesson-10-2-2",
              "type": "challenge",
              "title": "Circuit Breaker Challenge",
              "description": "Implement a circuit breaker pattern that opens after consecutive failures and closes after a recovery period.",
              "starterCode": "#[derive(Debug, Clone, Copy, PartialEq)]\npub enum CircuitState {\n    Closed,\n    Open,\n    HalfOpen,\n}\n\npub struct CircuitBreakerConfig {\n    pub failure_threshold: u32,\n    pub recovery_timeout_ms: u64,\n}\n\npub struct CircuitBreaker {\n    config: CircuitBreakerConfig,\n    state: CircuitState,\n    failure_count: u32,\n    last_failure_time: u64,\n}\n\nimpl CircuitBreaker {\n    pub fn new(config: CircuitBreakerConfig) -> Self {\n        Self {\n            config,\n            state: CircuitState::Closed,\n            failure_count: 0,\n            last_failure_time: 0,\n        }\n    }\n\n    pub fn can_execute(&self, current_time: u64) -> bool {\n        // TODO: Return true if the circuit allows execution\n        // Closed = always allow, Open = check if recovery timeout has passed\n        // HalfOpen = allow (test request)\n        todo!(\"Implement can_execute\")\n    }\n\n    pub fn record_success(&mut self) {\n        // TODO: Handle successful execution - reset failure count and close circuit\n        todo!(\"Implement record_success\")\n    }\n\n    pub fn record_failure(&mut self, current_time: u64) {\n        // TODO: Handle failed execution - increment count and open if threshold reached\n        todo!(\"Implement record_failure\")\n    }\n\n    pub fn state(&self) -> CircuitState {\n        self.state\n    }\n}",
              "solution": "#[derive(Debug, Clone, Copy, PartialEq)]\npub enum CircuitState {\n    Closed,\n    Open,\n    HalfOpen,\n}\n\npub struct CircuitBreakerConfig {\n    pub failure_threshold: u32,\n    pub recovery_timeout_ms: u64,\n}\n\npub struct CircuitBreaker {\n    config: CircuitBreakerConfig,\n    state: CircuitState,\n    failure_count: u32,\n    last_failure_time: u64,\n}\n\nimpl CircuitBreaker {\n    pub fn new(config: CircuitBreakerConfig) -> Self {\n        Self {\n            config,\n            state: CircuitState::Closed,\n            failure_count: 0,\n            last_failure_time: 0,\n        }\n    }\n\n    pub fn can_execute(&self, current_time: u64) -> bool {\n        match self.state {\n            CircuitState::Closed => true,\n            CircuitState::Open => {\n                if current_time >= self.last_failure_time + self.config.recovery_timeout_ms {\n                    true // Transition to HalfOpen happens on execution\n                } else {\n                    false\n                }\n            }\n            CircuitState::HalfOpen => true,\n        }\n    }\n\n    pub fn record_success(&mut self) {\n        self.failure_count = 0;\n        self.state = CircuitState::Closed;\n    }\n\n    pub fn record_failure(&mut self, current_time: u64) {\n        self.failure_count += 1;\n        self.last_failure_time = current_time;\n\n        if self.failure_count >= self.config.failure_threshold {\n            self.state = CircuitState::Open;\n        }\n    }\n\n    pub fn state(&self) -> CircuitState {\n        self.state\n    }\n}",
              "hints": [
                "In can_execute, check if recovery timeout has passed for Open state",
                "record_success should reset everything to Closed state",
                "record_failure increments count and opens circuit when threshold is reached"
              ],
              "testCases": [
                {
                  "input": {
                    "operation": "can_execute",
                    "state": "Closed",
                    "current_time": 1000
                  },
                  "expected": {
                    "can_execute": true
                  }
                },
                {
                  "input": {
                    "operation": "record_failure",
                    "state": "Closed",
                    "failure_threshold": 3,
                    "current_time": 1000
                  },
                  "expected_after_3_failures": {
                    "state": "Open"
                  }
                },
                {
                  "input": {
                    "operation": "can_execute",
                    "state": "Open",
                    "last_failure": 1000,
                    "recovery_timeout": 5000,
                    "current_time": 7000
                  },
                  "expected": {
                    "can_execute": true
                  }
                }
              ]
            },
            {
              "id": "lesson-10-2-3",
              "type": "challenge",
              "title": "Rate Limiter Challenge",
              "description": "Implement a token bucket rate limiter for controlling request rates.",
              "starterCode": "pub struct TokenBucketConfig {\n    pub capacity: u32,\n    pub refill_rate_per_sec: u32,\n}\n\npub struct TokenBucket {\n    config: TokenBucketConfig,\n    tokens: u32,\n    last_refill_time: u64,\n}\n\nimpl TokenBucket {\n    pub fn new(config: TokenBucketConfig) -> Self {\n        Self {\n            tokens: config.capacity,\n            config,\n            last_refill_time: 0,\n        }\n    }\n\n    pub fn try_consume(&mut self, amount: u32, current_time: u64) -> bool {\n        // TODO: Try to consume tokens, refilling first based on elapsed time\n        // Return true if consumption succeeds\n        todo!(\"Implement try_consume\")\n    }\n\n    pub fn refill(&mut self, current_time: u64) {\n        // TODO: Refill tokens based on elapsed time since last refill\n        // Don't exceed capacity\n        todo!(\"Implement refill\")\n    }\n\n    pub fn available_tokens(&self) -> u32 {\n        self.tokens\n    }\n}",
              "solution": "pub struct TokenBucketConfig {\n    pub capacity: u32,\n    pub refill_rate_per_sec: u32,\n}\n\npub struct TokenBucket {\n    config: TokenBucketConfig,\n    tokens: u32,\n    last_refill_time: u64,\n}\n\nimpl TokenBucket {\n    pub fn new(config: TokenBucketConfig) -> Self {\n        Self {\n            tokens: config.capacity,\n            config,\n            last_refill_time: 0,\n        }\n    }\n\n    pub fn try_consume(&mut self, amount: u32, current_time: u64) -> bool {\n        self.refill(current_time);\n\n        if self.tokens >= amount {\n            self.tokens -= amount;\n            true\n        } else {\n            false\n        }\n    }\n\n    pub fn refill(&mut self, current_time: u64) {\n        if current_time > self.last_refill_time {\n            let elapsed_secs = (current_time - self.last_refill_time) / 1000;\n            let tokens_to_add = elapsed_secs as u32 * self.config.refill_rate_per_sec;\n\n            self.tokens = (self.tokens + tokens_to_add).min(self.config.capacity);\n            self.last_refill_time = current_time;\n        }\n    }\n\n    pub fn available_tokens(&self) -> u32 {\n        self.tokens\n    }\n}",
              "hints": [
                "Always refill before checking if consumption is possible",
                "Calculate elapsed time and multiply by refill rate to get tokens to add",
                "Use min() to ensure tokens don't exceed capacity"
              ],
              "testCases": [
                {
                  "input": {
                    "operation": "try_consume",
                    "amount": 5,
                    "capacity": 10,
                    "current_time": 1000
                  },
                  "expected": {
                    "success": true,
                    "remaining": 5
                  }
                },
                {
                  "input": {
                    "operation": "try_consume",
                    "amount": 10,
                    "available": 5
                  },
                  "expected": {
                    "success": false
                  }
                },
                {
                  "input": {
                    "operation": "refill",
                    "elapsed_secs": 2,
                    "refill_rate": 3,
                    "capacity": 10,
                    "current_tokens": 4
                  },
                  "expected": {
                    "tokens": 10
                  }
                }
              ]
            },
            {
              "id": "lesson-10-2-4",
              "type": "challenge",
              "title": "Error Classifier Challenge",
              "description": "Implement an error classification system to determine if errors are retryable.",
              "starterCode": "#[derive(Debug, Clone, Copy, PartialEq)]\npub enum ErrorCategory {\n    Retryable,\n    NonRetryable,\n    Unknown,\n}\n\npub struct ErrorClassifier;\n\nimpl ErrorClassifier {\n    pub fn classify(error_code: u32) -> ErrorCategory {\n        // TODO: Classify error codes\n        // 1000-1999 = Retryable (transient errors)\n        // 2000-2999 = NonRetryable (permanent errors)\n        // Others = Unknown\n        todo!(\"Implement classify\")\n    }\n\n    pub fn should_retry(error_code: u32) -> bool {\n        // TODO: Return true only for Retryable errors\n        todo!(\"Implement should_retry\")\n    }\n\n    pub fn batch_classify(error_codes: &[u32]) -> Vec<ErrorCategory> {\n        // TODO: Classify multiple errors and return results\n        todo!(\"Implement batch_classify\")\n    }\n}",
              "solution": "#[derive(Debug, Clone, Copy, PartialEq)]\npub enum ErrorCategory {\n    Retryable,\n    NonRetryable,\n    Unknown,\n}\n\npub struct ErrorClassifier;\n\nimpl ErrorClassifier {\n    pub fn classify(error_code: u32) -> ErrorCategory {\n        match error_code {\n            1000..=1999 => ErrorCategory::Retryable,\n            2000..=2999 => ErrorCategory::NonRetryable,\n            _ => ErrorCategory::Unknown,\n        }\n    }\n\n    pub fn should_retry(error_code: u32) -> bool {\n        matches!(Self::classify(error_code), ErrorCategory::Retryable)\n    }\n\n    pub fn batch_classify(error_codes: &[u32]) -> Vec<ErrorCategory> {\n        error_codes.iter().map(|&code| Self::classify(code)).collect()\n    }\n}",
              "hints": [
                "Use match with range patterns (1000..=1999) to classify",
                "should_retry can use matches! macro or match on classify result",
                "batch_classify can use iter().map().collect() pattern"
              ],
              "testCases": [
                {
                  "input": {
                    "error_code": 1500
                  },
                  "expected": {
                    "category": "Retryable",
                    "should_retry": true
                  }
                },
                {
                  "input": {
                    "error_code": 2500
                  },
                  "expected": {
                    "category": "NonRetryable",
                    "should_retry": false
                  }
                },
                {
                  "input": {
                    "error_code": 999
                  },
                  "expected": {
                    "category": "Unknown",
                    "should_retry": false
                  }
                },
                {
                  "input": {
                    "batch": [
                      1001,
                      2001,
                      3001
                    ]
                  },
                  "expected": {
                    "categories": [
                      "Retryable",
                      "NonRetryable",
                      "Unknown"
                    ]
                  }
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course-035",
      "slug": "solana-testing-strategies",
      "title": "Testing Strategies for Solana",
      "description": "Comprehensive, production-oriented testing strategy for Solana: deterministic unit tests, realistic integration tests, fuzz/property testing, and release-confidence reporting.",
      "difficulty": "intermediate",
      "duration": "5 weeks",
      "totalXP": 1850,
      "tags": [
        "testing",
        "quality-assurance",
        "fuzzing",
        "property-testing"
      ],
      "imageUrl": "/images/courses/solana-testing.svg",
      "modules": [
        {
          "id": "mod-11-1",
          "title": "Unit and Integration Testing",
          "description": "Build deterministic unit and integration testing layers with clear ownership of invariants, fixtures, and failure diagnostics.",
          "lessons": [
            {
              "id": "lesson-11-1-1",
              "type": "content",
              "title": "Testing Fundamentals",
              "content": "Testing Solana systems effectively requires layered confidence, not one giant test suite.\n\nUnit tests validate pure logic: math, state transitions, and invariant checks. They should be fast, deterministic, and run on every change.\n\nIntegration tests validate component wiring: account modeling, instruction construction, and cross-module behavior under realistic inputs. They should catch schema drift and boundary errors that unit tests miss.\n\nA practical test pyramid for Solana work:\n1) deterministic unit tests (broadest coverage),\n2) deterministic integration tests (targeted workflow coverage),\n3) environment-dependent checks (smaller set, higher cost).\n\nCommon failure in teams is over-reliance on environment-dependent tests while neglecting deterministic core checks. This creates flaky CI and weak debugging signals.\n\nGood test design principles:\n- explicit fixture ownership,\n- stable expected outputs,\n- structured error assertions (not only success assertions),\n- regression fixtures for previously discovered bugs.\n\nFor production readiness, test outputs should be easy to audit. Summaries should include pass/fail counts by category, failing invariant IDs, and deterministic reproduction inputs.\n\nTesting is not just correctness verification; it is an operational communication tool. Strong test artifacts make release decisions clearer and incident response faster."
            },
            {
              "id": "lesson-11-1-2",
              "type": "challenge",
              "title": "Test Assertion Framework Challenge",
              "description": "Implement a test assertion framework for verifying program state.",
              "starterCode": "#[derive(Debug, Clone, PartialEq)]\npub struct AccountState {\n    pub balance: u64,\n    pub owner: String,\n    pub is_initialized: bool,\n}\n\npub struct TestAssertions;\n\nimpl TestAssertions {\n    pub fn assert_balance(state: &AccountState, expected: u64) -> Result<(), String> {\n        // TODO: Return Ok if balance matches, Err with message otherwise\n        todo!(\"Implement assert_balance\")\n    }\n\n    pub fn assert_initialized(state: &AccountState) -> Result<(), String> {\n        // TODO: Return Ok if initialized, Err otherwise\n        todo!(\"Implement assert_initialized\")\n    }\n\n    pub fn assert_owner(state: &AccountState, expected: &str) -> Result<(), String> {\n        // TODO: Return Ok if owner matches, Err otherwise\n        todo!(\"Implement assert_owner\")\n    }\n}",
              "solution": "#[derive(Debug, Clone, PartialEq)]\npub struct AccountState {\n    pub balance: u64,\n    pub owner: String,\n    pub is_initialized: bool,\n}\n\npub struct TestAssertions;\n\nimpl TestAssertions {\n    pub fn assert_balance(state: &AccountState, expected: u64) -> Result<(), String> {\n        if state.balance == expected {\n            Ok(())\n        } else {\n            Err(format!(\"Balance mismatch: expected {}, got {}\", expected, state.balance))\n        }\n    }\n\n    pub fn assert_initialized(state: &AccountState) -> Result<(), String> {\n        if state.is_initialized {\n            Ok(())\n        } else {\n            Err(\"Account not initialized\".to_string())\n        }\n    }\n\n    pub fn assert_owner(state: &AccountState, expected: &str) -> Result<(), String> {\n        if state.owner == expected {\n            Ok(())\n        } else {\n            Err(format!(\"Owner mismatch: expected {}, got {}\", expected, state.owner))\n        }\n    }\n}",
              "hints": [
                "Compare actual vs expected values and return appropriate Result",
                "Use format! to create descriptive error messages",
                "Return Ok(()) for success cases"
              ],
              "testCases": [
                {
                  "input": {
                    "balance": 100,
                    "expected": 100
                  },
                  "expected": {
                    "result": "Ok"
                  }
                },
                {
                  "input": {
                    "balance": 50,
                    "expected": 100
                  },
                  "expected": {
                    "result": "Err"
                  }
                },
                {
                  "input": {
                    "is_initialized": true
                  },
                  "expected": {
                    "result": "Ok"
                  }
                },
                {
                  "input": {
                    "owner": "Alice",
                    "expected": "Alice"
                  },
                  "expected": {
                    "result": "Ok"
                  }
                }
              ]
            },
            {
              "id": "lesson-11-1-3",
              "type": "challenge",
              "title": "Mock Account Generator Challenge",
              "description": "Create a mock account generator for testing with configurable parameters.",
              "starterCode": "pub struct MockAccountConfig {\n    pub balance: u64,\n    pub data_size: usize,\n    pub is_signer: bool,\n    pub is_writable: bool,\n}\n\npub struct MockAccount {\n    pub balance: u64,\n    pub data: Vec<u8>,\n    pub is_signer: bool,\n    pub is_writable: bool,\n}\n\npub struct MockAccountGenerator;\n\nimpl MockAccountGenerator {\n    pub fn generate(config: MockAccountConfig) -> MockAccount {\n        // TODO: Create a mock account with specified configuration\n        todo!(\"Implement generate\")\n    }\n\n    pub fn generate_with_lamports(lamports: u64) -> MockAccount {\n        // TODO: Create account with specific lamport balance\n        todo!(\"Implement generate_with_lamports\")\n    }\n\n    pub fn generate_signer() -> MockAccount {\n        // TODO: Create a signer account with default values\n        todo!(\"Implement generate_signer\")\n    }\n}",
              "solution": "pub struct MockAccountConfig {\n    pub balance: u64,\n    pub data_size: usize,\n    pub is_signer: bool,\n    pub is_writable: bool,\n}\n\npub struct MockAccount {\n    pub balance: u64,\n    pub data: Vec<u8>,\n    pub is_signer: bool,\n    pub is_writable: bool,\n}\n\npub struct MockAccountGenerator;\n\nimpl MockAccountGenerator {\n    pub fn generate(config: MockAccountConfig) -> MockAccount {\n        MockAccount {\n            balance: config.balance,\n            data: vec![0; config.data_size],\n            is_signer: config.is_signer,\n            is_writable: config.is_writable,\n        }\n    }\n\n    pub fn generate_with_lamports(lamports: u64) -> MockAccount {\n        MockAccount {\n            balance: lamports,\n            data: vec![],\n            is_signer: false,\n            is_writable: false,\n        }\n    }\n\n    pub fn generate_signer() -> MockAccount {\n        MockAccount {\n            balance: 0,\n            data: vec![],\n            is_signer: true,\n            is_writable: true,\n        }\n    }\n}",
              "hints": [
                "Use vec![0; size] to create zero-filled data of specified size",
                "For generate_with_lamports, use default values for other fields",
                "Signer accounts typically have is_writable set to true"
              ],
              "testCases": [
                {
                  "input": {
                    "balance": 1000,
                    "data_size": 128,
                    "is_signer": true
                  },
                  "expected": {
                    "balance": 1000,
                    "data_len": 128,
                    "is_signer": true
                  }
                },
                {
                  "input": {
                    "lamports": 5000
                  },
                  "expected": {
                    "balance": 5000
                  }
                },
                {
                  "input": {
                    "operation": "generate_signer"
                  },
                  "expected": {
                    "is_signer": true,
                    "is_writable": true
                  }
                }
              ]
            },
            {
              "id": "lesson-11-1-4",
              "type": "challenge",
              "title": "Test Scenario Builder Challenge",
              "description": "Build a test scenario builder for setting up complex test environments.",
              "starterCode": "pub struct TestScenario {\n    pub accounts: Vec<String>,\n    pub instructions: Vec<String>,\n    pub expected_state: String,\n}\n\npub struct TestScenarioBuilder {\n    accounts: Vec<String>,\n    instructions: Vec<String>,\n}\n\nimpl TestScenarioBuilder {\n    pub fn new() -> Self {\n        Self {\n            accounts: vec![],\n            instructions: vec![],\n        }\n    }\n\n    pub fn add_account(mut self, account: &str) -> Self {\n        // TODO: Add account to scenario\n        todo!(\"Implement add_account\")\n    }\n\n    pub fn add_instruction(mut self, instruction: &str) -> Self {\n        // TODO: Add instruction to scenario\n        todo!(\"Implement add_instruction\")\n    }\n\n    pub fn build(self, expected_state: &str) -> TestScenario {\n        // TODO: Build the final test scenario\n        todo!(\"Implement build\")\n    }\n}",
              "solution": "pub struct TestScenario {\n    pub accounts: Vec<String>,\n    pub instructions: Vec<String>,\n    pub expected_state: String,\n}\n\npub struct TestScenarioBuilder {\n    accounts: Vec<String>,\n    instructions: Vec<String>,\n}\n\nimpl TestScenarioBuilder {\n    pub fn new() -> Self {\n        Self {\n            accounts: vec![],\n            instructions: vec![],\n        }\n    }\n\n    pub fn add_account(mut self, account: &str) -> Self {\n        self.accounts.push(account.to_string());\n        self\n    }\n\n    pub fn add_instruction(mut self, instruction: &str) -> Self {\n        self.instructions.push(instruction.to_string());\n        self\n    }\n\n    pub fn build(self, expected_state: &str) -> TestScenario {\n        TestScenario {\n            accounts: self.accounts,\n            instructions: self.instructions,\n            expected_state: expected_state.to_string(),\n        }\n    }\n}",
              "hints": [
                "Use builder pattern with self return type for chaining",
                "Push strings into vectors (use to_string() to convert &str)",
                "build() consumes self and creates the final TestScenario"
              ],
              "testCases": [
                {
                  "input": {
                    "accounts": [
                      "alice",
                      "bob"
                    ],
                    "instructions": [
                      "transfer"
                    ],
                    "expected": "success"
                  },
                  "expected": {
                    "account_count": 2,
                    "instruction_count": 1
                  }
                },
                {
                  "input": {
                    "operation": "chain",
                    "calls": [
                      "add_account(alice)",
                      "add_instruction(transfer)",
                      "add_account(bob)"
                    ]
                  },
                  "expected": {
                    "accounts": [
                      "alice",
                      "bob"
                    ],
                    "instructions": [
                      "transfer"
                    ]
                  }
                }
              ]
            }
          ]
        },
        {
          "id": "mod-11-2",
          "title": "Advanced Testing Techniques",
          "description": "Use fuzzing, property-based tests, and mutation-style checks to expose edge-case failures before release.",
          "lessons": [
            {
              "id": "lesson-11-2-1",
              "type": "content",
              "title": "Fuzzing and Property Testing",
              "content": "Advanced testing techniques uncover failures that example-based tests rarely find.\n\nFuzzing explores broad random input space to trigger parser edge cases, boundary overflows, and unexpected state combinations. It is especially useful for serialization, decoding, and input validation layers.\n\nProperty-based testing defines invariants that must hold across many generated inputs. Instead of asserting one output, you assert a rule (for example: balances never become negative, or decoded-then-encoded payload remains stable).\n\nMutation-style thinking strengthens this further: intentionally alter assumptions and verify tests fail as expected. If tests still pass after a harmful change, coverage is weaker than it appears.\n\nTo keep advanced testing practical:\n- use deterministic seeds in CI for reproducibility,\n- store failing cases as permanent regression fixtures,\n- separate heavy campaigns from per-commit fast checks.\n\nAdvanced tests are most valuable when tied to explicit risk categories. Map each category (serialization safety, invariant consistency, edge-case arithmetic) to at least one dedicated property or fuzz campaign.\n\nTeams that treat fuzz/property failures as first-class release blockers catch subtle defects earlier and reduce high-severity production incidents."
            },
            {
              "id": "lesson-11-2-2",
              "type": "challenge",
              "title": "Fuzz Input Generator Challenge",
              "description": "Implement a fuzz input generator for testing with random data.",
              "starterCode": "pub struct FuzzInput {\n    pub data: Vec<u8>,\n    pub size: usize,\n}\n\npub struct FuzzInputGenerator {\n    seed: u64,\n}\n\nimpl FuzzInputGenerator {\n    pub fn new(seed: u64) -> Self {\n        Self { seed }\n    }\n\n    pub fn generate(&mut self, size: usize) -> FuzzInput {\n        // TODO: Generate random-ish data based on seed\n        // Use simple LCG: next = (seed * 1103515245 + 12345) % 2^31\n        todo!(\"Implement generate\")\n    }\n\n    pub fn generate_bounded(&mut self, min: u64, max: u64) -> u64 {\n        // TODO: Generate a random number in range [min, max]\n        todo!(\"Implement generate_bounded\")\n    }\n\n    fn next_random(&mut self) -> u64 {\n        // TODO: Generate next random number using LCG\n        todo!(\"Implement next_random\")\n    }\n}",
              "solution": "pub struct FuzzInput {\n    pub data: Vec<u8>,\n    pub size: usize,\n}\n\npub struct FuzzInputGenerator {\n    seed: u64,\n}\n\nimpl FuzzInputGenerator {\n    pub fn new(seed: u64) -> Self {\n        Self { seed }\n    }\n\n    pub fn generate(&mut self, size: usize) -> FuzzInput {\n        let mut data = Vec::with_capacity(size);\n        for _ in 0..size {\n            data.push((self.next_random() % 256) as u8);\n        }\n        FuzzInput { data, size }\n    }\n\n    pub fn generate_bounded(&mut self, min: u64, max: u64) -> u64 {\n        let range = max - min + 1;\n        min + (self.next_random() % range)\n    }\n\n    fn next_random(&mut self) -> u64 {\n        self.seed = self.seed.wrapping_mul(1103515245).wrapping_add(12345);\n        self.seed % (1 << 31)\n    }\n}",
              "hints": [
                "Use wrapping_mul and wrapping_add for LCG to avoid overflow panics",
                "Generate bytes by taking random % 256",
                "For bounded generation, calculate range and add to min"
              ],
              "testCases": [
                {
                  "input": {
                    "seed": 12345,
                    "size": 10
                  },
                  "expected": {
                    "size": 10
                  }
                },
                {
                  "input": {
                    "min": 10,
                    "max": 20
                  },
                  "expected": {
                    "in_range": true
                  }
                },
                {
                  "input": {
                    "seed": 12345,
                    "calls": 3
                  },
                  "expected": {
                    "deterministic": true
                  }
                }
              ]
            },
            {
              "id": "lesson-11-2-3",
              "type": "challenge",
              "title": "Property Verifier Challenge",
              "description": "Implement a property verifier that checks invariants hold across operations.",
              "starterCode": "pub struct PropertyVerifier;\n\nimpl PropertyVerifier {\n    pub fn verify_commutative(a: u64, b: u64, op: fn(u64, u64) -> u64) -> bool {\n        // TODO: Verify that op(a, b) == op(b, a)\n        todo!(\"Implement verify_commutative\")\n    }\n\n    pub fn verify_associative(a: u64, b: u64, c: u64, op: fn(u64, u64) -> u64) -> bool {\n        // TODO: Verify that op(op(a, b), c) == op(a, op(b, c))\n        todo!(\"Implement verify_associative\")\n    }\n\n    pub fn verify_identity(a: u64, identity: u64, op: fn(u64, u64) -> u64) -> bool {\n        // TODO: Verify that op(a, identity) == a\n        todo!(\"Implement verify_identity\")\n    }\n\n    pub fn verify_non_decreasing(values: &[u64]) -> bool {\n        // TODO: Verify that values are sorted in non-decreasing order\n        todo!(\"Implement verify_non_decreasing\")\n    }\n}",
              "solution": "pub struct PropertyVerifier;\n\nimpl PropertyVerifier {\n    pub fn verify_commutative(a: u64, b: u64, op: fn(u64, u64) -> u64) -> bool {\n        op(a, b) == op(b, a)\n    }\n\n    pub fn verify_associative(a: u64, b: u64, c: u64, op: fn(u64, u64) -> u64) -> bool {\n        op(op(a, b), c) == op(a, op(b, c))\n    }\n\n    pub fn verify_identity(a: u64, identity: u64, op: fn(u64, u64) -> u64) -> bool {\n        op(a, identity) == a\n    }\n\n    pub fn verify_non_decreasing(values: &[u64]) -> bool {\n        for i in 1..values.len() {\n            if values[i] < values[i - 1] {\n                return false;\n            }\n        }\n        true\n    }\n}",
              "hints": [
                "For commutative, call op both ways and compare",
                "For associative, nest the calls differently and compare",
                "For non_decreasing, iterate through pairs and check ordering"
              ],
              "testCases": [
                {
                  "input": {
                    "a": 5,
                    "b": 3,
                    "op": "add"
                  },
                  "expected": {
                    "commutative": true
                  }
                },
                {
                  "input": {
                    "a": 2,
                    "b": 3,
                    "c": 4,
                    "op": "add"
                  },
                  "expected": {
                    "associative": true
                  }
                },
                {
                  "input": {
                    "a": 10,
                    "identity": 0,
                    "op": "add"
                  },
                  "expected": {
                    "identity": true
                  }
                },
                {
                  "input": {
                    "values": [
                      1,
                      2,
                      2,
                      5
                    ]
                  },
                  "expected": {
                    "non_decreasing": true
                  }
                }
              ]
            },
            {
              "id": "lesson-11-2-4",
              "type": "challenge",
              "title": "Boundary Value Analyzer Challenge",
              "description": "Implement a boundary value analyzer for identifying edge cases.",
              "starterCode": "pub struct BoundaryValues {\n    pub min: i64,\n    pub max: i64,\n    pub just_below_min: i64,\n    pub just_above_min: i64,\n    pub just_below_max: i64,\n    pub just_above_max: i64,\n    pub typical: i64,\n}\n\npub struct BoundaryAnalyzer;\n\nimpl BoundaryAnalyzer {\n    pub fn analyze(min: i64, max: i64) -> BoundaryValues {\n        // TODO: Generate boundary values for the given range\n        // just_below_min = min - 1, just_above_min = min + 1\n        // just_below_max = max - 1, just_above_max = max + 1\n        // typical = (min + max) / 2\n        todo!(\"Implement analyze\")\n    }\n\n    pub fn is_within_bounds(value: i64, min: i64, max: i64) -> bool {\n        // TODO: Check if value is within inclusive bounds [min, max]\n        todo!(\"Implement is_within_bounds\")\n    }\n\n    pub fn get_test_cases(min: i64, max: i64) -> Vec<i64> {\n        // TODO: Return a vector of all boundary test cases\n        todo!(\"Implement get_test_cases\")\n    }\n}",
              "solution": "pub struct BoundaryValues {\n    pub min: i64,\n    pub max: i64,\n    pub just_below_min: i64,\n    pub just_above_min: i64,\n    pub just_below_max: i64,\n    pub just_above_max: i64,\n    pub typical: i64,\n}\n\npub struct BoundaryAnalyzer;\n\nimpl BoundaryAnalyzer {\n    pub fn analyze(min: i64, max: i64) -> BoundaryValues {\n        BoundaryValues {\n            min,\n            max,\n            just_below_min: min.saturating_sub(1),\n            just_above_min: min.saturating_add(1),\n            just_below_max: max.saturating_sub(1),\n            just_above_max: max.saturating_add(1),\n            typical: (min + max) / 2,\n        }\n    }\n\n    pub fn is_within_bounds(value: i64, min: i64, max: i64) -> bool {\n        value >= min && value <= max\n    }\n\n    pub fn get_test_cases(min: i64, max: i64) -> Vec<i64> {\n        let bv = Self::analyze(min, max);\n        vec![\n            bv.just_below_min,\n            bv.min,\n            bv.just_above_min,\n            bv.typical,\n            bv.just_below_max,\n            bv.max,\n            bv.just_above_max,\n        ]\n    }\n}",
              "hints": [
                "Use saturating_sub and saturating_add to avoid overflow",
                "Typical value is the midpoint of the range",
                "Return all 7 boundary values as test cases"
              ],
              "testCases": [
                {
                  "input": {
                    "min": 0,
                    "max": 100
                  },
                  "expected": {
                    "typical": 50,
                    "just_above_min": 1
                  }
                },
                {
                  "input": {
                    "value": 50,
                    "min": 0,
                    "max": 100
                  },
                  "expected": {
                    "within_bounds": true
                  }
                },
                {
                  "input": {
                    "min": 0,
                    "max": 10
                  },
                  "expected_test_cases": 7
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course-036",
      "slug": "solana-program-optimization",
      "title": "Solana Program Optimization",
      "description": "Engineer production-grade Solana performance: compute budgeting, account layout efficiency, memory/rent tradeoffs, and deterministic optimization workflows.",
      "difficulty": "intermediate",
      "duration": "5 weeks",
      "totalXP": 1800,
      "tags": [
        "optimization",
        "performance",
        "compute-units",
        "profiling"
      ],
      "imageUrl": "/images/courses/solana-optimization.svg",
      "modules": [
        {
          "id": "mod-12-1",
          "title": "Compute Unit Optimization",
          "description": "Optimize compute-heavy paths with explicit CU budgets, operation-level profiling, and predictable performance tradeoffs.",
          "lessons": [
            {
              "id": "lesson-12-1-1",
              "type": "content",
              "title": "Understanding Compute Units",
              "content": "Compute units are the hard resource budget that shapes what your Solana program can do in a single transaction. Performance optimization starts by treating CU usage as a contract, not an afterthought.\n\nA reliable optimization loop is:\n1) measure baseline CU by operation type,\n2) identify dominant cost buckets (deserialization, hashing, loops, CPI fan-out),\n3) optimize one hotspot at a time,\n4) re-measure and keep only changes with clear gains.\n\nCommon anti-patterns include optimizing cold paths, adding complexity without measurement, and ignoring account-size side effects. In Solana systems, compute and account design are coupled: a larger account can increase deserialization cost, which raises CU pressure.\n\nFor production teams, deterministic cost fixtures are crucial. They let you compare before/after behavior in CI and stop regressions early. Performance work is most useful when every claim is backed by reproducible evidence, not intuition."
            },
            {
              "id": "lesson-12-1-2",
              "type": "challenge",
              "title": "CU Counter Challenge",
              "description": "Implement a compute unit counter to estimate operation costs.",
              "starterCode": "pub struct CUCounter {\n    base_cost: u64,\n    per_iteration_cost: u64,\n}\n\npub struct CUEstimator;\n\nimpl CUEstimator {\n    pub fn estimate_loop_cost(iterations: u64, per_iter_cu: u64, overhead: u64) -> u64 {\n        // TODO: Calculate total CU cost for a loop\n        // Total = overhead + (iterations * per_iter_cu)\n        todo!(\"Implement estimate_loop_cost\")\n    }\n\n    pub fn estimate_account_access(accounts: u64, per_account_cu: u64) -> u64 {\n        // TODO: Calculate CU cost for account access\n        todo!(\"Implement estimate_account_access\")\n    }\n\n    pub fn within_budget(estimated: u64, budget: u64, safety_margin: f64) -> bool {\n        // TODO: Check if estimated CUs are within budget with safety margin\n        // Apply safety margin as percentage (e.g., 0.9 means 90% of budget)\n        todo!(\"Implement within_budget\")\n    }\n}",
              "solution": "pub struct CUCounter {\n    base_cost: u64,\n    per_iteration_cost: u64,\n}\n\npub struct CUEstimator;\n\nimpl CUEstimator {\n    pub fn estimate_loop_cost(iterations: u64, per_iter_cu: u64, overhead: u64) -> u64 {\n        overhead + (iterations * per_iter_cu)\n    }\n\n    pub fn estimate_account_access(accounts: u64, per_account_cu: u64) -> u64 {\n        accounts * per_account_cu\n    }\n\n    pub fn within_budget(estimated: u64, budget: u64, safety_margin: f64) -> bool {\n        let adjusted_budget = (budget as f64 * safety_margin) as u64;\n        estimated <= adjusted_budget\n    }\n}",
              "hints": [
                "Loop cost is overhead plus iterations times per-iteration cost",
                "Account access is simply accounts multiplied by per-account CU",
                "Apply safety margin by multiplying budget by the percentage"
              ],
              "testCases": [
                {
                  "input": {
                    "iterations": 100,
                    "per_iter_cu": 10,
                    "overhead": 500
                  },
                  "expected": {
                    "total": 1500
                  }
                },
                {
                  "input": {
                    "accounts": 5,
                    "per_account_cu": 100
                  },
                  "expected": {
                    "total": 500
                  }
                },
                {
                  "input": {
                    "estimated": 80000,
                    "budget": 100000,
                    "safety_margin": 0.9
                  },
                  "expected": {
                    "within_budget": true
                  }
                }
              ]
            },
            {
              "id": "lesson-12-1-3",
              "type": "challenge",
              "title": "Data Structure Optimizer Challenge",
              "description": "Optimize data structures for minimal serialization overhead.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct OptimizedAccount {\n    pub data: [u8; 128],  // Fixed size for efficiency\n    pub used: usize,\n}\n\npub struct AccountOptimizer;\n\nimpl AccountOptimizer {\n    pub fn new() -> OptimizedAccount {\n        // TODO: Create new optimized account with empty data\n        todo!(\"Implement new\")\n    }\n\n    pub fn write(account: &mut OptimizedAccount, offset: usize, data: &[u8]) -> Result<(), String> {\n        // TODO: Write data at offset if it fits within bounds\n        todo!(\"Implement write\")\n    }\n\n    pub fn read(account: &OptimizedAccount, offset: usize, len: usize) -> Result<Vec<u8>, String> {\n        // TODO: Read len bytes from offset\n        todo!(\"Implement read\")\n    }\n\n    pub fn serialized_size(account: &OptimizedAccount) -> usize {\n        // TODO: Return the actual serialized size (used bytes only)\n        todo!(\"Implement serialized_size\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct OptimizedAccount {\n    pub data: [u8; 128],\n    pub used: usize,\n}\n\npub struct AccountOptimizer;\n\nimpl AccountOptimizer {\n    pub fn new() -> OptimizedAccount {\n        OptimizedAccount {\n            data: [0; 128],\n            used: 0,\n        }\n    }\n\n    pub fn write(account: &mut OptimizedAccount, offset: usize, data: &[u8]) -> Result<(), String> {\n        if offset + data.len() > account.data.len() {\n            return Err(\"Write exceeds buffer\".to_string());\n        }\n        account.data[offset..offset + data.len()].copy_from_slice(data);\n        account.used = (account.used).max(offset + data.len());\n        Ok(())\n    }\n\n    pub fn read(account: &OptimizedAccount, offset: usize, len: usize) -> Result<Vec<u8>, String> {\n        if offset + len > account.data.len() {\n            return Err(\"Read exceeds buffer\".to_string());\n        }\n        Ok(account.data[offset..offset + len].to_vec())\n    }\n\n    pub fn serialized_size(account: &OptimizedAccount) -> usize {\n        account.used\n    }\n}",
              "hints": [
                "Use copy_from_slice to write data efficiently",
                "Track the highest written position as 'used'",
                "Always check bounds before read/write operations"
              ],
              "testCases": [
                {
                  "input": {
                    "operation": "new"
                  },
                  "expected": {
                    "used": 0
                  }
                },
                {
                  "input": {
                    "offset": 0,
                    "data": [
                      1,
                      2,
                      3
                    ]
                  },
                  "expected": {
                    "used": 3
                  }
                },
                {
                  "input": {
                    "offset": 10,
                    "len": 3
                  },
                  "expected": {
                    "data": [
                      0,
                      0,
                      0
                    ]
                  }
                },
                {
                  "input": {
                    "offset": 0,
                    "data": [
                      1,
                      2,
                      3
                    ]
                  },
                  "expected_size": 3
                }
              ]
            },
            {
              "id": "lesson-12-1-4",
              "type": "challenge",
              "title": "Batch Operation Optimizer Challenge",
              "description": "Optimize batch operations to minimize compute units.",
              "starterCode": "pub struct BatchOptimizer;\n\nimpl BatchOptimizer {\n    pub fn optimal_batch_size(total_items: u64, cu_per_item: u64, cu_overhead: u64, cu_budget: u64) -> u64 {\n        // TODO: Calculate optimal batch size given CU constraints\n        // Available CUs for items = budget - overhead\n        // Batch size = available / cu_per_item\n        todo!(\"Implement optimal_batch_size\")\n    }\n\n    pub fn create_batches(total_items: u64, batch_size: u64) -> Vec<(u64, u64)> {\n        // TODO: Create batch ranges (start, end) for processing\n        // Return vec of (start_index, end_index) tuples\n        todo!(\"Implement create_batches\")\n    }\n\n    pub fn estimate_total_cu(total_items: u64, batch_size: u64, cu_per_item: u64, cu_overhead: u64) -> u64 {\n        // TODO: Estimate total CUs for processing all items in batches\n        // Total = num_batches * overhead + total_items * cu_per_item\n        todo!(\"Implement estimate_total_cu\")\n    }\n}",
              "solution": "pub struct BatchOptimizer;\n\nimpl BatchOptimizer {\n    pub fn optimal_batch_size(total_items: u64, cu_per_item: u64, cu_overhead: u64, cu_budget: u64) -> u64 {\n        if cu_budget <= cu_overhead {\n            return 0;\n        }\n        let available_for_items = cu_budget - cu_overhead;\n        let batch_size = available_for_items / cu_per_item;\n        batch_size.min(total_items).max(1)\n    }\n\n    pub fn create_batches(total_items: u64, batch_size: u64) -> Vec<(u64, u64)> {\n        let mut batches = vec![];\n        let num_batches = (total_items + batch_size - 1) / batch_size;\n\n        for i in 0..num_batches {\n            let start = i * batch_size;\n            let end = ((i + 1) * batch_size).min(total_items);\n            batches.push((start, end));\n        }\n        batches\n    }\n\n    pub fn estimate_total_cu(total_items: u64, batch_size: u64, cu_per_item: u64, cu_overhead: u64) -> u64 {\n        let num_batches = (total_items + batch_size - 1) / batch_size;\n        num_batches * cu_overhead + total_items * cu_per_item\n    }\n}",
              "hints": [
                "Calculate available CUs after accounting for overhead",
                "Use ceiling division: (n + d - 1) / d for number of batches",
                "Total CU = (num_batches * overhead) + (items * per_item)"
              ],
              "testCases": [
                {
                  "input": {
                    "total_items": 100,
                    "cu_per_item": 100,
                    "cu_overhead": 1000,
                    "cu_budget": 5000
                  },
                  "expected": {
                    "batch_size": 40
                  }
                },
                {
                  "input": {
                    "total_items": 10,
                    "batch_size": 3
                  },
                  "expected": {
                    "batches": 4
                  }
                },
                {
                  "input": {
                    "total_items": 100,
                    "batch_size": 30,
                    "cu_per_item": 50,
                    "cu_overhead": 500
                  },
                  "expected": {
                    "total_cu": 6500
                  }
                }
              ]
            }
          ]
        },
        {
          "id": "mod-12-2",
          "title": "Memory and Storage Optimization",
          "description": "Design memory/storage-efficient account layouts with rent-aware sizing, serialization discipline, and safe migration planning.",
          "lessons": [
            {
              "id": "lesson-12-2-1",
              "type": "content",
              "title": "Account Data Optimization",
              "content": "Account data optimization is both a cost and correctness discipline. Poor layouts increase rent, slow parsing, and make migrations fragile.\n\nDesign principles:\n- Keep hot fields compact and easy to parse.\n- Use fixed-size representations where possible.\n- Reserve growth strategy explicitly instead of ad hoc field expansion.\n- Separate frequently-mutated data from rarely-changed metadata when practical.\n\nLayout decisions should be documented with deterministic artifacts: field offsets, total bytes, and expected rent class. If a schema change increases account size, reviewers should see the exact delta and migration implications.\n\nProduction optimization is not smallest possible struct at any cost. It is stable, readable, and migration-safe storage that keeps compute and rent budgets predictable over time."
            },
            {
              "id": "lesson-12-2-2",
              "type": "challenge",
              "title": "Data Packer Challenge",
              "description": "Implement a data packer that efficiently packs fields into account data.",
              "starterCode": "pub struct DataPacker;\n\nimpl DataPacker {\n    pub fn pack_u64(buffer: &mut [u8], offset: usize, value: u64) -> Result<(), String> {\n        // TODO: Pack u64 value into buffer at offset (little-endian)\n        todo!(\"Implement pack_u64\")\n    }\n\n    pub fn unpack_u64(buffer: &[u8], offset: usize) -> Result<u64, String> {\n        // TODO: Unpack u64 value from buffer at offset (little-endian)\n        todo!(\"Implement unpack_u64\")\n    }\n\n    pub fn pack_u16(buffer: &mut [u8], offset: usize, value: u16) -> Result<(), String> {\n        // TODO: Pack u16 value into buffer at offset (little-endian)\n        todo!(\"Implement pack_u16\")\n    }\n\n    pub fn calculate_alignment_offset(current_offset: usize, alignment: usize) -> usize {\n        // TODO: Calculate padding needed for alignment\n        // Return the aligned offset (next multiple of alignment)\n        todo!(\"Implement calculate_alignment_offset\")\n    }\n}",
              "solution": "pub struct DataPacker;\n\nimpl DataPacker {\n    pub fn pack_u64(buffer: &mut [u8], offset: usize, value: u64) -> Result<(), String> {\n        if offset + 8 > buffer.len() {\n            return Err(\"Buffer too small\".to_string());\n        }\n        buffer[offset..offset + 8].copy_from_slice(&value.to_le_bytes());\n        Ok(())\n    }\n\n    pub fn unpack_u64(buffer: &[u8], offset: usize) -> Result<u64, String> {\n        if offset + 8 > buffer.len() {\n            return Err(\"Buffer too small\".to_string());\n        }\n        let mut bytes = [0u8; 8];\n        bytes.copy_from_slice(&buffer[offset..offset + 8]);\n        Ok(u64::from_le_bytes(bytes))\n    }\n\n    pub fn pack_u16(buffer: &mut [u8], offset: usize, value: u16) -> Result<(), String> {\n        if offset + 2 > buffer.len() {\n            return Err(\"Buffer too small\".to_string());\n        }\n        buffer[offset..offset + 2].copy_from_slice(&value.to_le_bytes());\n        Ok(())\n    }\n\n    pub fn calculate_alignment_offset(current_offset: usize, alignment: usize) -> usize {\n        let remainder = current_offset % alignment;\n        if remainder == 0 {\n            current_offset\n        } else {\n            current_offset + (alignment - remainder)\n        }\n    }\n}",
              "hints": [
                "Use to_le_bytes() to convert integers to bytes",
                "Use from_le_bytes() to convert bytes back to integers",
                "Alignment formula: if remainder, add (alignment - remainder)"
              ],
              "testCases": [
                {
                  "input": {
                    "operation": "pack_u64",
                    "value": 72623859790382850,
                    "offset": 0
                  },
                  "expected": {
                    "bytes": [
                      8,
                      7,
                      6,
                      5,
                      4,
                      3,
                      2,
                      1
                    ]
                  }
                },
                {
                  "input": {
                    "operation": "unpack_u64",
                    "bytes": [
                      8,
                      7,
                      6,
                      5,
                      4,
                      3,
                      2,
                      1
                    ],
                    "offset": 0
                  },
                  "expected": {
                    "value": 72623859790382850
                  }
                },
                {
                  "input": {
                    "current_offset": 5,
                    "alignment": 4
                  },
                  "expected": {
                    "aligned_offset": 8
                  }
                }
              ]
            },
            {
              "id": "lesson-12-2-3",
              "type": "challenge",
              "title": "Rent Calculator Challenge",
              "description": "Implement a rent calculator for estimating account storage costs.",
              "starterCode": "pub struct RentCalculator {\n    pub lamports_per_byte_year: u64,\n    pub exemption_threshold_years: f64,\n}\n\npub struct RentEstimate {\n    pub annual_rent: u64,\n    pub exemption_threshold: u64,\n}\n\nimpl RentCalculator {\n    pub fn new(lamports_per_byte_year: u64, exemption_threshold_years: f64) -> Self {\n        Self {\n            lamports_per_byte_year,\n            exemption_threshold_years,\n        }\n    }\n\n    pub fn estimate(&self, data_size: usize) -> RentEstimate {\n        // TODO: Calculate annual rent and exemption threshold\n        // annual_rent = data_size * lamports_per_byte_year\n        // exemption = annual_rent * exemption_threshold_years\n        todo!(\"Implement estimate\")\n    }\n\n    pub fn is_exempt(&self, balance: u64, data_size: usize) -> bool {\n        // TODO: Check if balance is sufficient for rent exemption\n        todo!(\"Implement is_exempt\")\n    }\n\n    pub fn min_balance_for_size(&self, data_size: usize) -> u64 {\n        // TODO: Calculate minimum balance for rent exemption\n        todo!(\"Implement min_balance_for_size\")\n    }\n}",
              "solution": "pub struct RentCalculator {\n    pub lamports_per_byte_year: u64,\n    pub exemption_threshold_years: f64,\n}\n\npub struct RentEstimate {\n    pub annual_rent: u64,\n    pub exemption_threshold: u64,\n}\n\nimpl RentCalculator {\n    pub fn new(lamports_per_byte_year: u64, exemption_threshold_years: f64) -> Self {\n        Self {\n            lamports_per_byte_year,\n            exemption_threshold_years,\n        }\n    }\n\n    pub fn estimate(&self, data_size: usize) -> RentEstimate {\n        let annual_rent = data_size as u64 * self.lamports_per_byte_year;\n        let exemption_threshold = (annual_rent as f64 * self.exemption_threshold_years) as u64;\n        RentEstimate {\n            annual_rent,\n            exemption_threshold,\n        }\n    }\n\n    pub fn is_exempt(&self, balance: u64, data_size: usize) -> bool {\n        let min_balance = self.min_balance_for_size(data_size);\n        balance >= min_balance\n    }\n\n    pub fn min_balance_for_size(&self, data_size: usize) -> u64 {\n        let annual_rent = data_size as u64 * self.lamports_per_byte_year;\n        (annual_rent as f64 * self.exemption_threshold_years) as u64\n    }\n}",
              "hints": [
                "Annual rent is data size times lamports per byte per year",
                "Exemption threshold is annual rent times threshold years",
                "Check if balance is greater than or equal to minimum"
              ],
              "testCases": [
                {
                  "input": {
                    "data_size": 128,
                    "lamports_per_byte_year": 3480,
                    "exemption_threshold_years": 2
                  },
                  "expected": {
                    "annual_rent": 445440,
                    "exemption": 890880
                  }
                },
                {
                  "input": {
                    "balance": 1000000,
                    "data_size": 128
                  },
                  "expected": {
                    "exempt": true
                  }
                },
                {
                  "input": {
                    "data_size": 256
                  },
                  "expected": {
                    "min_balance": 1781760
                  }
                }
              ]
            },
            {
              "id": "lesson-12-2-4",
              "type": "challenge",
              "title": "Zero-Copy Deserializer Challenge",
              "description": "Implement a zero-copy deserializer for reading data without allocation.",
              "starterCode": "pub struct ZeroCopyReader<'a> {\n    data: &'a [u8],\n    offset: usize,\n}\n\nimpl<'a> ZeroCopyReader<'a> {\n    pub fn new(data: &'a [u8]) -> Self {\n        Self { data, offset: 0 }\n    }\n\n    pub fn read_u64(&mut self) -> Result<u64, String> {\n        // TODO: Read u64 from current offset without copying data\n        // Advance offset by 8 bytes\n        todo!(\"Implement read_u64\")\n    }\n\n    pub fn read_u32(&mut self) -> Result<u32, String> {\n        // TODO: Read u32 from current offset\n        todo!(\"Implement read_u32\")\n    }\n\n    pub fn read_bytes(&mut self, len: usize) -> Result<&'a [u8], String> {\n        // TODO: Return a slice of the data without copying\n        todo!(\"Implement read_bytes\")\n    }\n\n    pub fn remaining(&self) -> usize {\n        // TODO: Return remaining bytes\n        todo!(\"Implement remaining\")\n    }\n}",
              "solution": "pub struct ZeroCopyReader<'a> {\n    data: &'a [u8],\n    offset: usize,\n}\n\nimpl<'a> ZeroCopyReader<'a> {\n    pub fn new(data: &'a [u8]) -> Self {\n        Self { data, offset: 0 }\n    }\n\n    pub fn read_u64(&mut self) -> Result<u64, String> {\n        if self.offset + 8 > self.data.len() {\n            return Err(\"Insufficient data\".to_string());\n        }\n        let mut bytes = [0u8; 8];\n        bytes.copy_from_slice(&self.data[self.offset..self.offset + 8]);\n        self.offset += 8;\n        Ok(u64::from_le_bytes(bytes))\n    }\n\n    pub fn read_u32(&mut self) -> Result<u32, String> {\n        if self.offset + 4 > self.data.len() {\n            return Err(\"Insufficient data\".to_string());\n        }\n        let mut bytes = [0u8; 4];\n        bytes.copy_from_slice(&self.data[self.offset..self.offset + 4]);\n        self.offset += 4;\n        Ok(u32::from_le_bytes(bytes))\n    }\n\n    pub fn read_bytes(&mut self, len: usize) -> Result<&'a [u8], String> {\n        if self.offset + len > self.data.len() {\n            return Err(\"Insufficient data\".to_string());\n        }\n        let slice = &self.data[self.offset..self.offset + len];\n        self.offset += len;\n        Ok(slice)\n    }\n\n    pub fn remaining(&self) -> usize {\n        self.data.len() - self.offset\n    }\n}",
              "hints": [
                "Use copy_from_slice to read fixed-size data into stack arrays",
                "For read_bytes, return a slice of the original data (zero-copy)",
                "Always advance offset after reading"
              ],
              "testCases": [
                {
                  "input": {
                    "data": [
                      8,
                      7,
                      6,
                      5,
                      4,
                      3,
                      2,
                      1
                    ],
                    "operation": "read_u64"
                  },
                  "expected": {
                    "value": 72623859790382850,
                    "remaining": 0
                  }
                },
                {
                  "input": {
                    "data": [
                      4,
                      3,
                      2,
                      1
                    ],
                    "operation": "read_u32"
                  },
                  "expected": {
                    "value": 16909060
                  }
                },
                {
                  "input": {
                    "data": [
                      1,
                      2,
                      3,
                      4,
                      5
                    ],
                    "operation": "read_bytes",
                    "len": 3
                  },
                  "expected": {
                    "bytes": [
                      1,
                      2,
                      3
                    ],
                    "remaining": 2
                  }
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course-037",
      "slug": "solana-tokenomics-design",
      "title": "Tokenomics Design for Solana",
      "description": "Design robust Solana token economies with distribution discipline, vesting safety, staking incentives, and governance mechanics that remain operationally defensible.",
      "difficulty": "intermediate",
      "duration": "5 weeks",
      "totalXP": 1900,
      "tags": [
        "tokenomics",
        "vesting",
        "staking",
        "governance",
        "incentives"
      ],
      "imageUrl": "/images/courses/solana-tokenomics.svg",
      "modules": [
        {
          "id": "mod-13-1",
          "title": "Token Distribution and Vesting",
          "description": "Model token allocation and vesting systems with explicit fairness, unlock predictability, and deterministic accounting rules.",
          "lessons": [
            {
              "id": "lesson-13-1-1",
              "type": "content",
              "title": "Token Distribution Fundamentals",
              "content": "Token distribution is a security and credibility decision, not just a spreadsheet exercise. Allocation and vesting rules shape long-term trust in the protocol.\n\nA strong distribution model answers:\n- who receives tokens and why,\n- when they unlock,\n- how unlock schedules affect circulating supply,\n- what controls prevent accidental over-distribution.\n\nVesting design should be deterministic and auditable. Cliff and linear phases must produce reproducible release amounts for any timestamp. Ambiguous rounding rules create disputes and operational risk.\n\nProduction teams should maintain allocation invariants in tests (for example: total distributed <= total supply, per-bucket caps respected, no negative vesting balances). Tokenomics quality improves when economics and implementation are validated together."
            },
            {
              "id": "lesson-13-1-2",
              "type": "challenge",
              "title": "Vesting Schedule Calculator Challenge",
              "description": "Implement a vesting schedule calculator with cliff and linear release.",
              "starterCode": "pub struct VestingConfig {\n    pub total_amount: u64,\n    pub cliff_duration: u64,\n    pub vesting_duration: u64,\n    pub start_time: u64,\n}\n\npub struct VestingSchedule;\n\nimpl VestingSchedule {\n    pub fn calculate_vested(config: &VestingConfig, current_time: u64) -> u64 {\n        // TODO: Calculate vested amount based on elapsed time\n        // If before cliff, return 0\n        // If after vesting complete, return total_amount\n        // Otherwise, linear vesting after cliff\n        todo!(\"Implement calculate_vested\")\n    }\n\n    pub fn calculate_releasable(config: &VestingConfig, already_released: u64, current_time: u64) -> u64 {\n        // TODO: Calculate amount available to release now\n        // Return vested - already_released\n        todo!(\"Implement calculate_releasable\")\n    }\n\n    pub fn is_fully_vested(config: &VestingConfig, current_time: u64) -> bool {\n        // TODO: Return true if vesting is complete\n        todo!(\"Implement is_fully_vested\")\n    }\n}",
              "solution": "pub struct VestingConfig {\n    pub total_amount: u64,\n    pub cliff_duration: u64,\n    pub vesting_duration: u64,\n    pub start_time: u64,\n}\n\npub struct VestingSchedule;\n\nimpl VestingSchedule {\n    pub fn calculate_vested(config: &VestingConfig, current_time: u64) -> u64 {\n        let elapsed = current_time.saturating_sub(config.start_time);\n\n        if elapsed < config.cliff_duration {\n            return 0;\n        }\n\n        if elapsed >= config.vesting_duration {\n            return config.total_amount;\n        }\n\n        let vesting_elapsed = elapsed - config.cliff_duration;\n        let vesting_period = config.vesting_duration - config.cliff_duration;\n\n        (config.total_amount as u128 * vesting_elapsed as u128 / vesting_period as u128) as u64\n    }\n\n    pub fn calculate_releasable(config: &VestingConfig, already_released: u64, current_time: u64) -> u64 {\n        let vested = Self::calculate_vested(config, current_time);\n        vested.saturating_sub(already_released)\n    }\n\n    pub fn is_fully_vested(config: &VestingConfig, current_time: u64) -> bool {\n        let elapsed = current_time.saturating_sub(config.start_time);\n        elapsed >= config.vesting_duration\n    }\n}",
              "hints": [
                "Use saturating_sub to avoid underflow when calculating elapsed time",
                "For linear vesting, use u128 for intermediate calculation to avoid overflow",
                "Releasable is simply vested minus already released"
              ],
              "testCases": [
                {
                  "input": {
                    "cliff": 100,
                    "vesting": 500,
                    "start": 0,
                    "current": 50,
                    "total": 10000
                  },
                  "expected": {
                    "vested": 0
                  }
                },
                {
                  "input": {
                    "cliff": 100,
                    "vesting": 500,
                    "start": 0,
                    "current": 600,
                    "total": 10000
                  },
                  "expected": {
                    "vested": 10000
                  }
                },
                {
                  "input": {
                    "cliff": 100,
                    "vesting": 500,
                    "start": 0,
                    "current": 300,
                    "total": 10000
                  },
                  "expected": {
                    "vested": 5000
                  }
                }
              ]
            },
            {
              "id": "lesson-13-1-3",
              "type": "challenge",
              "title": "Token Allocation Distributor Challenge",
              "description": "Implement a token allocation distributor for managing different stakeholder groups.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct Allocation {\n    pub recipient: String,\n    pub percentage: u8,\n    pub vesting_config: Option<String>,\n}\n\npub struct TokenAllocation {\n    pub total_supply: u64,\n    pub allocations: Vec<Allocation>,\n}\n\npub struct AllocationDistributor;\n\nimpl AllocationDistributor {\n    pub fn validate(allocations: &[Allocation]) -> Result<(), String> {\n        // TODO: Validate that percentages sum to 100\n        todo!(\"Implement validate\")\n    }\n\n    pub fn calculate_amount(total_supply: u64, percentage: u8) -> u64 {\n        // TODO: Calculate token amount for given percentage\n        // Use u128 for intermediate calculation\n        todo!(\"Implement calculate_amount\")\n    }\n\n    pub fn get_allocation(allocations: &[Allocation], recipient: &str) -> Option<&Allocation> {\n        // TODO: Find allocation by recipient name\n        todo!(\"Implement get_allocation\")\n    }\n\n    pub fn remaining_percentage(allocations: &[Allocation]) -> u8 {\n        // TODO: Calculate remaining unallocated percentage\n        todo!(\"Implement remaining_percentage\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct Allocation {\n    pub recipient: String,\n    pub percentage: u8,\n    pub vesting_config: Option<String>,\n}\n\npub struct TokenAllocation {\n    pub total_supply: u64,\n    pub allocations: Vec<Allocation>,\n}\n\npub struct AllocationDistributor;\n\nimpl AllocationDistributor {\n    pub fn validate(allocations: &[Allocation]) -> Result<(), String> {\n        let total: u8 = allocations.iter().map(|a| a.percentage).sum();\n        if total == 100 {\n            Ok(())\n        } else {\n            Err(format!(\"Percentages sum to {}, expected 100\", total))\n        }\n    }\n\n    pub fn calculate_amount(total_supply: u64, percentage: u8) -> u64 {\n        (total_supply as u128 * percentage as u128 / 100) as u64\n    }\n\n    pub fn get_allocation<'a>(allocations: &'a [Allocation], recipient: &str) -> Option<&'a Allocation> {\n        allocations.iter().find(|a| a.recipient == recipient)\n    }\n\n    pub fn remaining_percentage(allocations: &[Allocation]) -> u8 {\n        let allocated: u8 = allocations.iter().map(|a| a.percentage).sum();\n        100 - allocated\n    }\n}",
              "hints": [
                "Use iter().map().sum() to calculate total percentage",
                "Use u128 for percentage calculation to avoid overflow",
                "Use find() to locate allocation by recipient"
              ],
              "testCases": [
                {
                  "input": {
                    "allocations": [
                      {
                        "percentage": 40
                      },
                      {
                        "percentage": 60
                      }
                    ]
                  },
                  "expected": {
                    "valid": true
                  }
                },
                {
                  "input": {
                    "total_supply": 1000000,
                    "percentage": 25
                  },
                  "expected": {
                    "amount": 250000
                  }
                },
                {
                  "input": {
                    "allocations": [
                      {
                        "recipient": "team",
                        "percentage": 30
                      }
                    ],
                    "find": "team"
                  },
                  "expected": {
                    "found": true,
                    "percentage": 30
                  }
                },
                {
                  "input": {
                    "allocations": [
                      {
                        "percentage": 30
                      },
                      {
                        "percentage": 40
                      }
                    ]
                  },
                  "expected": {
                    "remaining": 30
                  }
                }
              ]
            },
            {
              "id": "lesson-13-1-4",
              "type": "challenge",
              "title": "Release Schedule Generator Challenge",
              "description": "Generate a complete release schedule with dates and amounts.",
              "starterCode": "pub struct ReleaseEvent {\n    pub timestamp: u64,\n    pub amount: u64,\n}\n\npub struct ReleaseScheduleGenerator;\n\nimpl ReleaseScheduleGenerator {\n    pub fn generate_linear(\n        total_amount: u64,\n        start_time: u64,\n        duration: u64,\n        intervals: u32,\n    ) -> Vec<ReleaseEvent> {\n        // TODO: Generate linear release schedule with equal amounts at each interval\n        todo!(\"Implement generate_linear\")\n    }\n\n    pub fn generate_monthly(\n        total_amount: u64,\n        start_time: u64,\n        months: u32,\n    ) -> Vec<ReleaseEvent> {\n        // TODO: Generate monthly release schedule\n        // Assume 30 days per month for simplicity\n        todo!(\"Implement generate_monthly\")\n    }\n\n    pub fn total_by_timestamp(schedule: &[ReleaseEvent], timestamp: u64) -> u64 {\n        // TODO: Calculate total amount released by given timestamp\n        todo!(\"Implement total_by_timestamp\")\n    }\n}",
              "solution": "pub struct ReleaseEvent {\n    pub timestamp: u64,\n    pub amount: u64,\n}\n\npub struct ReleaseScheduleGenerator;\n\nimpl ReleaseScheduleGenerator {\n    pub fn generate_linear(\n        total_amount: u64,\n        start_time: u64,\n        duration: u64,\n        intervals: u32,\n    ) -> Vec<ReleaseEvent> {\n        let mut schedule = vec![];\n        let interval_duration = duration / intervals as u64;\n        let amount_per_interval = total_amount / intervals as u64;\n\n        for i in 0..intervals {\n            schedule.push(ReleaseEvent {\n                timestamp: start_time + (i as u64 * interval_duration),\n                amount: amount_per_interval,\n            });\n        }\n\n        schedule\n    }\n\n    pub fn generate_monthly(\n        total_amount: u64,\n        start_time: u64,\n        months: u32,\n    ) -> Vec<ReleaseEvent> {\n        let seconds_per_month = 30 * 24 * 60 * 60;\n        let mut schedule = vec![];\n        let amount_per_month = total_amount / months as u64;\n\n        for i in 0..months {\n            schedule.push(ReleaseEvent {\n                timestamp: start_time + (i as u64 * seconds_per_month),\n                amount: amount_per_month,\n            });\n        }\n\n        schedule\n    }\n\n    pub fn total_by_timestamp(schedule: &[ReleaseEvent], timestamp: u64) -> u64 {\n        schedule\n            .iter()\n            .filter(|e| e.timestamp <= timestamp)\n            .map(|e| e.amount)\n            .sum()\n    }\n}",
              "hints": [
                "Divide duration by intervals to get interval duration",
                "Use filter and sum to calculate total by timestamp",
                "For monthly, use 30 days * 24 hours * 60 minutes * 60 seconds"
              ],
              "testCases": [
                {
                  "input": {
                    "total": 10000,
                    "duration": 1000,
                    "intervals": 4
                  },
                  "expected": {
                    "events": 4,
                    "amount_per_event": 2500
                  }
                },
                {
                  "input": {
                    "total": 12000,
                    "months": 12
                  },
                  "expected": {
                    "events": 12,
                    "amount_per_month": 1000
                  }
                },
                {
                  "input": {
                    "schedule": [
                      {
                        "timestamp": 100,
                        "amount": 100
                      },
                      {
                        "timestamp": 200,
                        "amount": 200
                      }
                    ],
                    "timestamp": 150
                  },
                  "expected": {
                    "total": 100
                  }
                }
              ]
            }
          ]
        },
        {
          "id": "mod-13-2",
          "title": "Staking and Governance",
          "description": "Design staking and governance mechanics with clear incentive alignment, anti-manipulation constraints, and measurable participation health.",
          "lessons": [
            {
              "id": "lesson-13-2-1",
              "type": "content",
              "title": "Staking and Governance Design",
              "content": "Staking and governance systems must balance participation incentives with manipulation resistance. Rewarding lock behavior is useful, but poorly tuned models can over-concentrate influence.\n\nCore design questions:\n1) How is staking reward rate set and adjusted?\n2) How is voting power calculated (raw balance, delegated balance, time-weighted)?\n3) What prevents short-term governance capture?\n\nGovernance math should be transparent and deterministic so users can verify voting outcomes independently. If power calculations are opaque or inconsistent, governance trust collapses quickly.\n\nOperationally, track governance health metrics: voter participation, delegation concentration, proposal pass patterns, and inactive stake ratios. Tokenomics is successful only when on-chain incentive behavior matches intended governance outcomes."
            },
            {
              "id": "lesson-13-2-2",
              "type": "challenge",
              "title": "Staking Calculator Challenge",
              "description": "Implement a staking rewards calculator with compounding.",
              "starterCode": "pub struct StakingConfig {\n    pub annual_yield_bps: u64,  // Basis points (10000 = 100%)\n    pub compounding_frequency: u32,  // Times per year\n}\n\npub struct StakingCalculator;\n\nimpl StakingCalculator {\n    pub fn calculate_rewards(\n        principal: u64,\n        config: &StakingConfig,\n        duration_days: u32,\n    ) -> u64 {\n        // TODO: Calculate staking rewards with compounding\n        // A = P * (1 + r/n)^(n*t)\n        // where r = annual rate, n = frequency, t = time in years\n        todo!(\"Implement calculate_rewards\")\n    }\n\n    pub fn calculate_apy(config: &StakingConfig) -> f64 {\n        // TODO: Calculate APY from APR with compounding\n        // APY = (1 + APR/n)^n - 1\n        todo!(\"Implement calculate_apy\")\n    }\n\n    pub fn days_to_target(\n        principal: u64,\n        target: u64,\n        config: &StakingConfig,\n    ) -> u32 {\n        // TODO: Calculate days needed to reach target amount\n        // Return u32::MAX if impossible\n        todo!(\"Implement days_to_target\")\n    }\n}",
              "solution": "pub struct StakingConfig {\n    pub annual_yield_bps: u64,\n    pub compounding_frequency: u32,\n}\n\npub struct StakingCalculator;\n\nimpl StakingCalculator {\n    pub fn calculate_rewards(\n        principal: u64,\n        config: &StakingConfig,\n        duration_days: u32,\n    ) -> u64 {\n        let rate = config.annual_yield_bps as f64 / 10000.0;\n        let n = config.compounding_frequency as f64;\n        let t = duration_days as f64 / 365.0;\n\n        let amount = principal as f64 * (1.0 + rate / n).powf(n * t);\n        (amount - principal as f64) as u64\n    }\n\n    pub fn calculate_apy(config: &StakingConfig) -> f64 {\n        let apr = config.annual_yield_bps as f64 / 10000.0;\n        let n = config.compounding_frequency as f64;\n        (1.0 + apr / n).powf(n) - 1.0\n    }\n\n    pub fn days_to_target(\n        principal: u64,\n        target: u64,\n        config: &StakingConfig,\n    ) -> u32 {\n        if target <= principal {\n            return 0;\n        }\n\n        let rate = config.annual_yield_bps as f64 / 10000.0;\n        let n = config.compounding_frequency as f64;\n        let ratio = target as f64 / principal as f64;\n\n        let years = ratio.ln() / (n * (1.0 + rate / n).ln());\n        let days = (years * 365.0) as u32;\n\n        if days > u32::MAX {\n            u32::MAX\n        } else {\n            days\n        }\n    }\n}",
              "hints": [
                "Use compound interest formula: A = P(1 + r/n)^(nt)",
                "Convert basis points to decimal by dividing by 10000",
                "For days to target, use logarithms to solve for time"
              ],
              "testCases": [
                {
                  "input": {
                    "principal": 10000,
                    "yield_bps": 1000,
                    "frequency": 12,
                    "days": 365
                  },
                  "expected": {
                    "rewards_approx": 1051
                  }
                },
                {
                  "input": {
                    "yield_bps": 1000,
                    "frequency": 12
                  },
                  "expected": {
                    "apy_approx": 0.1047
                  }
                },
                {
                  "input": {
                    "principal": 10000,
                    "target": 11000,
                    "yield_bps": 1000,
                    "frequency": 12
                  },
                  "expected": {
                    "days_approx": 348
                  }
                }
              ]
            },
            {
              "id": "lesson-13-2-3",
              "type": "challenge",
              "title": "Voting Power Calculator Challenge",
              "description": "Implement a voting power calculator with delegation support.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct Voter {\n    pub address: String,\n    pub staked_amount: u64,\n    pub delegated_to: Option<String>,\n}\n\npub struct VotingPowerCalculator;\n\nimpl VotingPowerCalculator {\n    pub fn calculate_voting_power(voter: &Voter) -> u64 {\n        // TODO: Return voting power (staked amount if not delegated, 0 if delegated)\n        todo!(\"Implement calculate_voting_power\")\n    }\n\n    pub fn calculate_total_voting_power(voters: &[Voter]) -> u64 {\n        // TODO: Sum voting power of all voters\n        todo!(\"Implement calculate_total_voting_power\")\n    }\n\n    pub fn get_delegates(voters: &[Voter], delegate: &str) -> Vec<&Voter> {\n        // TODO: Return all voters who delegated to the given address\n        todo!(\"Implement get_delegates\")\n    }\n\n    pub fn calculate_delegated_power(voters: &[Voter], delegate: &str) -> u64 {\n        // TODO: Calculate total voting power delegated to an address\n        todo!(\"Implement calculate_delegated_power\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct Voter {\n    pub address: String,\n    pub staked_amount: u64,\n    pub delegated_to: Option<String>,\n}\n\npub struct VotingPowerCalculator;\n\nimpl VotingPowerCalculator {\n    pub fn calculate_voting_power(voter: &Voter) -> u64 {\n        if voter.delegated_to.is_some() {\n            0\n        } else {\n            voter.staked_amount\n        }\n    }\n\n    pub fn calculate_total_voting_power(voters: &[Voter]) -> u64 {\n        voters.iter().map(|v| Self::calculate_voting_power(v)).sum()\n    }\n\n    pub fn get_delegates<'a>(voters: &'a [Voter], delegate: &str) -> Vec<&'a Voter> {\n        voters\n            .iter()\n            .filter(|v| v.delegated_to.as_ref().map(|d| d == delegate).unwrap_or(false))\n            .collect()\n    }\n\n    pub fn calculate_delegated_power(voters: &[Voter], delegate: &str) -> u64 {\n        Self::get_delegates(voters, delegate)\n            .iter()\n            .map(|v| v.staked_amount)\n            .sum()\n    }\n}",
              "hints": [
                "If delegated_to is Some, voting power is 0 (they gave it away)",
                "Use filter to find voters who delegated to a specific address",
                "Sum staked amounts to calculate delegated power"
              ],
              "testCases": [
                {
                  "input": {
                    "staked": 1000,
                    "delegated": null
                  },
                  "expected": {
                    "power": 1000
                  }
                },
                {
                  "input": {
                    "staked": 1000,
                    "delegated": "Some(alice)"
                  },
                  "expected": {
                    "power": 0
                  }
                },
                {
                  "input": {
                    "voters": [
                      {
                        "staked": 100
                      },
                      {
                        "staked": 200
                      }
                    ]
                  },
                  "expected": {
                    "total": 300
                  }
                },
                {
                  "input": {
                    "voters": [
                      {
                        "staked": 100,
                        "delegated": "alice"
                      },
                      {
                        "staked": 200,
                        "delegated": "alice"
                      }
                    ],
                    "delegate": "alice"
                  },
                  "expected": {
                    "delegated_power": 300
                  }
                }
              ]
            },
            {
              "id": "lesson-13-2-4",
              "type": "challenge",
              "title": "Proposal Threshold Calculator Challenge",
              "description": "Implement a proposal threshold calculator for governance.",
              "starterCode": "pub struct GovernanceConfig {\n    pub proposal_threshold_bps: u64,  // Basis points of total supply\n    pub quorum_bps: u64,              // Basis points needed to pass\n    pub total_supply: u64,\n}\n\npub struct ProposalThresholdCalculator;\n\nimpl ProposalThresholdCalculator {\n    pub fn proposal_threshold(config: &GovernanceConfig) -> u64 {\n        // TODO: Calculate minimum tokens needed to create proposal\n        todo!(\"Implement proposal_threshold\")\n    }\n\n    pub fn quorum_required(config: &GovernanceConfig) -> u64 {\n        // TODO: Calculate minimum votes needed for proposal to pass\n        todo!(\"Implement quorum_required\")\n    }\n\n    pub fn has_proposal_threshold(balance: u64, config: &GovernanceConfig) -> bool {\n        // TODO: Check if balance meets proposal threshold\n        todo!(\"Implement has_proposal_threshold\")\n    }\n\n    pub fn proposal_passed(votes_for: u64, votes_against: u64, config: &GovernanceConfig) -> bool {\n        // TODO: Check if proposal has passed based on quorum and majority\n        // Must meet quorum AND have more for than against\n        todo!(\"Implement proposal_passed\")\n    }\n}",
              "solution": "pub struct GovernanceConfig {\n    pub proposal_threshold_bps: u64,\n    pub quorum_bps: u64,\n    pub total_supply: u64,\n}\n\npub struct ProposalThresholdCalculator;\n\nimpl ProposalThresholdCalculator {\n    pub fn proposal_threshold(config: &GovernanceConfig) -> u64 {\n        (config.total_supply as u128 * config.proposal_threshold_bps as u128 / 10000) as u64\n    }\n\n    pub fn quorum_required(config: &GovernanceConfig) -> u64 {\n        (config.total_supply as u128 * config.quorum_bps as u128 / 10000) as u64\n    }\n\n    pub fn has_proposal_threshold(balance: u64, config: &GovernanceConfig) -> bool {\n        balance >= Self::proposal_threshold(config)\n    }\n\n    pub fn proposal_passed(votes_for: u64, votes_against: u64, config: &GovernanceConfig) -> bool {\n        let total_votes = votes_for + votes_against;\n        let quorum = Self::quorum_required(config);\n\n        total_votes >= quorum && votes_for > votes_against\n    }\n}",
              "hints": [
                "Convert basis points to amount: (supply * bps) / 10000",
                "Use u128 for intermediate calculation to avoid overflow",
                "Proposal passes if quorum met AND more for than against"
              ],
              "testCases": [
                {
                  "input": {
                    "total_supply": 1000000,
                    "threshold_bps": 100
                  },
                  "expected": {
                    "threshold": 10000
                  }
                },
                {
                  "input": {
                    "total_supply": 1000000,
                    "quorum_bps": 500
                  },
                  "expected": {
                    "quorum": 50000
                  }
                },
                {
                  "input": {
                    "balance": 15000,
                    "threshold_bps": 100
                  },
                  "expected": {
                    "has_threshold": true
                  }
                },
                {
                  "input": {
                    "for": 60000,
                    "against": 10000,
                    "quorum_bps": 500
                  },
                  "expected": {
                    "passed": true
                  }
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course-038",
      "slug": "solana-defi-primitives",
      "title": "DeFi Primitives on Solana",
      "description": "Build practical Solana DeFi foundations: AMM mechanics, liquidity accounting, lending primitives, and flash-loan-safe composition patterns.",
      "difficulty": "intermediate",
      "duration": "6 weeks",
      "totalXP": 2000,
      "tags": [
        "defi",
        "amm",
        "lending",
        "yield-farming",
        "flash-loans"
      ],
      "imageUrl": "/images/courses/solana-defi.svg",
      "modules": [
        {
          "id": "mod-14-1",
          "title": "AMM and Liquidity",
          "description": "Implement AMM and liquidity primitives with deterministic math, slippage-aware outputs, and LP accounting correctness.",
          "lessons": [
            {
              "id": "lesson-14-1-1",
              "type": "content",
              "title": "AMM Fundamentals",
              "content": "AMM fundamentals are simple in formula but subtle in implementation quality. The invariant math must be deterministic, fee handling explicit, and rounding behavior consistent across paths.\n\nFor constant-product pools, route quality is determined by output-at-size, not headline spot price. Larger trades move further on the curve and experience stronger impact, so quote logic must be size-aware.\n\nLiquidity accounting must also be exact: LP shares, fee accrual, and pool reserve updates should remain internally consistent under repeated swaps and edge-case sizes.\n\nProduction DeFi teams treat AMM math as critical infrastructure. They use fixed fixtures for swap-in/swap-out cases, boundary amounts, and fee tiers so regressions are caught before deployment."
            },
            {
              "id": "lesson-14-1-2",
              "type": "challenge",
              "title": "Constant Product AMM Challenge",
              "description": "Implement a constant product AMM for token swaps.",
              "starterCode": "pub struct Pool {\n    pub token_a_reserve: u64,\n    pub token_b_reserve: u64,\n    pub fee_bps: u64,  // Basis points\n}\n\npub struct ConstantProductAMM;\n\nimpl ConstantProductAMM {\n    pub fn get_constant_product(pool: &Pool) -> u128 {\n        // TODO: Calculate and return k = x * y as u128\n        todo!(\"Implement get_constant_product\")\n    }\n\n    pub fn calculate_swap_output(pool: &Pool, input_amount: u64, input_is_a: bool) -> u64 {\n        // TODO: Calculate output amount for swap\n        // Apply fee, then use constant product formula\n        // output = (output_reserve * input_with_fee) / (input_reserve + input_with_fee)\n        todo!(\"Implement calculate_swap_output\")\n    }\n\n    pub fn calculate_price(pool: &Pool, a_to_b: bool) -> f64 {\n        // TODO: Calculate current price as ratio of reserves\n        todo!(\"Implement calculate_price\")\n    }\n\n    pub fn calculate_slippage(pool: &Pool, input_amount: u64, input_is_a: bool) -> f64 {\n        // TODO: Calculate price slippage for given trade\n        todo!(\"Implement calculate_slippage\")\n    }\n}",
              "solution": "pub struct Pool {\n    pub token_a_reserve: u64,\n    pub token_b_reserve: u64,\n    pub fee_bps: u64,\n}\n\npub struct ConstantProductAMM;\n\nimpl ConstantProductAMM {\n    pub fn get_constant_product(pool: &Pool) -> u128 {\n        pool.token_a_reserve as u128 * pool.token_b_reserve as u128\n    }\n\n    pub fn calculate_swap_output(pool: &Pool, input_amount: u64, input_is_a: bool) -> u64 {\n        let fee_multiplier = 10000 - pool.fee_bps;\n        let input_with_fee = (input_amount as u128 * fee_multiplier as u128) / 10000;\n\n        let (input_reserve, output_reserve) = if input_is_a {\n            (pool.token_a_reserve as u128, pool.token_b_reserve as u128)\n        } else {\n            (pool.token_b_reserve as u128, pool.token_a_reserve as u128)\n        };\n\n        let numerator = output_reserve * input_with_fee;\n        let denominator = input_reserve + input_with_fee;\n\n        (numerator / denominator) as u64\n    }\n\n    pub fn calculate_price(pool: &Pool, a_to_b: bool) -> f64 {\n        if a_to_b {\n            pool.token_b_reserve as f64 / pool.token_a_reserve as f64\n        } else {\n            pool.token_a_reserve as f64 / pool.token_b_reserve as f64\n        }\n    }\n\n    pub fn calculate_slippage(pool: &Pool, input_amount: u64, input_is_a: bool) -> f64 {\n        let price_before = Self::calculate_price(pool, input_is_a);\n\n        let output = Self::calculate_swap_output(pool, input_amount, input_is_a);\n        let effective_price = output as f64 / input_amount as f64;\n\n        if price_before > 0.0 {\n            (price_before - effective_price) / price_before\n        } else {\n            0.0\n        }\n    }\n}",
              "hints": [
                "Use u128 for intermediate calculations to prevent overflow",
                "Apply fee by multiplying by (10000 - fee_bps) / 10000",
                "Slippage is (price_before - effective_price) / price_before"
              ],
              "testCases": [
                {
                  "input": {
                    "a_reserve": 10000,
                    "b_reserve": 20000
                  },
                  "expected": {
                    "k": 200000000
                  }
                },
                {
                  "input": {
                    "a_reserve": 10000,
                    "b_reserve": 20000,
                    "input": 100,
                    "fee": 30
                  },
                  "expected": {
                    "output": 197
                  }
                },
                {
                  "input": {
                    "a_reserve": 10000,
                    "b_reserve": 20000,
                    "a_to_b": true
                  },
                  "expected": {
                    "price": 2
                  }
                }
              ]
            },
            {
              "id": "lesson-14-1-3",
              "type": "challenge",
              "title": "Liquidity Provider Calculator Challenge",
              "description": "Calculate LP token minting and rewards for liquidity providers.",
              "starterCode": "pub struct LiquidityPosition {\n    pub lp_tokens: u64,\n    pub pool_share_bps: u64,  // Basis points\n}\n\npub struct LPCalculator;\n\nimpl LPCalculator {\n    pub fn calculate_lp_tokens_to_mint(\n        pool_a: u64,\n        pool_b: u64,\n        total_lp_supply: u64,\n        added_a: u64,\n        added_b: u64,\n    ) -> u64 {\n        // TODO: Calculate LP tokens to mint for added liquidity\n        // If first liquidity, use geometric mean\n        // Otherwise, mint proportional to contribution\n        todo!(\"Implement calculate_lp_tokens_to_mint\")\n    }\n\n    pub fn calculate_pool_share(lp_tokens: u64, total_lp_supply: u64) -> u64 {\n        // TODO: Calculate pool share in basis points\n        todo!(\"Implement calculate_pool_share\")\n    }\n\n    pub fn calculate_rewards(\n        lp_tokens: u64,\n        total_fees_collected: u64,\n        total_lp_supply: u64,\n    ) -> u64 {\n        // TODO: Calculate rewards share for LP holder\n        todo!(\"Implement calculate_rewards\")\n    }\n\n    pub fn calculate_withdraw_amount(\n        lp_tokens_to_burn: u64,\n        total_lp_supply: u64,\n        pool_a: u64,\n        pool_b: u64,\n    ) -> (u64, u64) {\n        // TODO: Calculate token amounts to return when burning LP tokens\n        todo!(\"Implement calculate_withdraw_amount\")\n    }\n}",
              "solution": "pub struct LiquidityPosition {\n    pub lp_tokens: u64,\n    pub pool_share_bps: u64,\n}\n\npub struct LPCalculator;\n\nimpl LPCalculator {\n    pub fn calculate_lp_tokens_to_mint(\n        pool_a: u64,\n        pool_b: u64,\n        total_lp_supply: u64,\n        added_a: u64,\n        added_b: u64,\n    ) -> u64 {\n        if total_lp_supply == 0 {\n            // First liquidity - use geometric mean\n            ((added_a as u128 * added_b as u128) as f64).sqrt() as u64\n        } else {\n            // Mint proportional to contribution\n            let share_a = (added_a as u128 * total_lp_supply as u128) / pool_a as u128;\n            let share_b = (added_b as u128 * total_lp_supply as u128) / pool_b as u128;\n            share_a.min(share_b) as u64\n        }\n    }\n\n    pub fn calculate_pool_share(lp_tokens: u64, total_lp_supply: u64) -> u64 {\n        if total_lp_supply == 0 {\n            return 0;\n        }\n        ((lp_tokens as u128 * 10000) / total_lp_supply as u128) as u64\n    }\n\n    pub fn calculate_rewards(\n        lp_tokens: u64,\n        total_fees_collected: u64,\n        total_lp_supply: u64,\n    ) -> u64 {\n        ((total_fees_collected as u128 * lp_tokens as u128) / total_lp_supply as u128) as u64\n    }\n\n    pub fn calculate_withdraw_amount(\n        lp_tokens_to_burn: u64,\n        total_lp_supply: u64,\n        pool_a: u64,\n        pool_b: u64,\n    ) -> (u64, u64) {\n        let share = lp_tokens_to_burn as u128 * 10000 / total_lp_supply as u128;\n        let amount_a = (pool_a as u128 * share / 10000) as u64;\n        let amount_b = (pool_b as u128 * share / 10000) as u64;\n        (amount_a, amount_b)\n    }\n}",
              "hints": [
                "For first liquidity, use sqrt(a * b) as LP tokens",
                "Pool share is (lp_tokens / total_supply) * 10000 bps",
                "Rewards are proportional to LP token holdings"
              ],
              "testCases": [
                {
                  "input": {
                    "pool_a": 10000,
                    "pool_b": 20000,
                    "total_lp": 0,
                    "added_a": 1000,
                    "added_b": 2000
                  },
                  "expected": {
                    "lp_tokens": 1414
                  }
                },
                {
                  "input": {
                    "lp_tokens": 1000,
                    "total_lp": 10000
                  },
                  "expected": {
                    "share_bps": 1000
                  }
                },
                {
                  "input": {
                    "lp_tokens": 500,
                    "fees": 1000,
                    "total_lp": 10000
                  },
                  "expected": {
                    "rewards": 50
                  }
                },
                {
                  "input": {
                    "lp_burn": 1000,
                    "total_lp": 10000,
                    "pool_a": 5000,
                    "pool_b": 10000
                  },
                  "expected": {
                    "a": 500,
                    "b": 1000
                  }
                }
              ]
            },
            {
              "id": "lesson-14-1-4",
              "type": "challenge",
              "title": "Price Oracle Challenge",
              "description": "Implement a time-weighted average price oracle.",
              "starterCode": "pub struct PriceObservation {\n    pub timestamp: u64,\n    pub price: u64,  // Price with 6 decimal places\n}\n\npub struct TWAPOracle {\n    pub observations: Vec<PriceObservation>,\n    pub window_size: u64,  // Time window in seconds\n}\n\nimpl TWAPOracle {\n    pub fn new(window_size: u64) -> Self {\n        Self {\n            observations: vec![],\n            window_size,\n        }\n    }\n\n    pub fn add_observation(&mut self, timestamp: u64, price: u64) {\n        // TODO: Add new price observation and remove old ones outside window\n        todo!(\"Implement add_observation\")\n    }\n\n    pub fn calculate_twap(&self, current_time: u64) -> u64 {\n        // TODO: Calculate time-weighted average price\n        // TWAP = sum(price * duration) / total_duration\n        todo!(\"Implement calculate_twap\")\n    }\n\n    pub fn is_fresh(&self, current_time: u64, max_age: u64) -> bool {\n        // TODO: Check if the most recent observation is within max_age\n        todo!(\"Implement is_fresh\")\n    }\n}",
              "solution": "pub struct PriceObservation {\n    pub timestamp: u64,\n    pub price: u64,\n}\n\npub struct TWAPOracle {\n    pub observations: Vec<PriceObservation>,\n    pub window_size: u64,\n}\n\nimpl TWAPOracle {\n    pub fn new(window_size: u64) -> Self {\n        Self {\n            observations: vec![],\n            window_size,\n        }\n    }\n\n    pub fn add_observation(&mut self, timestamp: u64, price: u64) {\n        self.observations.push(PriceObservation { timestamp, price });\n\n        // Remove observations outside the window\n        let cutoff = timestamp.saturating_sub(self.window_size);\n        self.observations.retain(|obs| obs.timestamp >= cutoff);\n    }\n\n    pub fn calculate_twap(&self, current_time: u64) -> u64 {\n        if self.observations.len() < 2 {\n            return self.observations.first().map(|o| o.price).unwrap_or(0);\n        }\n\n        let mut weighted_sum: u128 = 0;\n        let mut total_duration: u64 = 0;\n\n        for i in 0..self.observations.len() - 1 {\n            let duration = self.observations[i + 1].timestamp - self.observations[i].timestamp;\n            weighted_sum += self.observations[i].price as u128 * duration as u128;\n            total_duration += duration;\n        }\n\n        // Add duration from last observation to current time\n        if let Some(last) = self.observations.last() {\n            let duration = current_time.saturating_sub(last.timestamp);\n            weighted_sum += last.price as u128 * duration as u128;\n            total_duration += duration;\n        }\n\n        if total_duration == 0 {\n            return 0;\n        }\n\n        (weighted_sum / total_duration as u128) as u64\n    }\n\n    pub fn is_fresh(&self, current_time: u64, max_age: u64) -> bool {\n        self.observations\n            .last()\n            .map(|obs| current_time - obs.timestamp <= max_age)\n            .unwrap_or(false)\n    }\n}",
              "hints": [
                "Use retain() to filter out old observations",
                "Calculate duration between consecutive observations",
                "TWAP is weighted sum divided by total duration"
              ],
              "testCases": [
                {
                  "input": {
                    "observations": [
                      {
                        "t": 0,
                        "p": 100
                      },
                      {
                        "t": 100,
                        "p": 110
                      }
                    ],
                    "current_time": 200
                  },
                  "expected": {
                    "twap": 105
                  }
                },
                {
                  "input": {
                    "observations": [
                      {
                        "t": 100,
                        "p": 100
                      }
                    ],
                    "current_time": 150,
                    "max_age": 100
                  },
                  "expected": {
                    "fresh": true
                  }
                },
                {
                  "input": {
                    "observations": [
                      {
                        "t": 0,
                        "p": 100
                      }
                    ],
                    "current_time": 200,
                    "window": 100
                  },
                  "expected": {
                    "observations": 0
                  }
                }
              ]
            }
          ]
        },
        {
          "id": "mod-14-2",
          "title": "Lending and Flash Loans",
          "description": "Model lending and flash-loan flows with collateral safety, utilization-aware pricing, and strict repayment invariants.",
          "lessons": [
            {
              "id": "lesson-14-2-1",
              "type": "content",
              "title": "Lending Protocol Mechanics",
              "content": "Lending primitives and flash-loan logic are powerful but unforgiving. Safety depends on strict collateral valuation, clear LTV/threshold rules, and deterministic repayment checks.\n\nA practical lending model should define:\n- collateral valuation source and freshness policy,\n- borrow limits and liquidation thresholds,\n- utilization-based rate behavior,\n- liquidation and bad-debt handling paths.\n\nFlash loans add atomic constraints: borrowed amount plus fee must be repaid in the same transaction context. Any relaxation of this invariant introduces severe risk.\n\nComposable DeFi design works when every primitive preserves local safety contracts while exposing clear interfaces for higher-level orchestration."
            },
            {
              "id": "lesson-14-2-2",
              "type": "challenge",
              "title": "Collateral Calculator Challenge",
              "description": "Implement collateral and borrowing power calculations.",
              "starterCode": "pub struct CollateralConfig {\n    pub ltv_bps: u64,           // Loan-to-value in basis points\n    pub liquidation_threshold_bps: u64,\n    pub collateral_price: u64,   // Price with 6 decimals\n}\n\npub struct CollateralPosition {\n    pub collateral_amount: u64,\n    pub borrowed_amount: u64,\n}\n\npub struct CollateralCalculator;\n\nimpl CollateralCalculator {\n    pub fn calculate_max_borrow(collateral: u64, config: &CollateralConfig) -> u64 {\n        // TODO: Calculate maximum borrowable amount based on collateral value and LTV\n        todo!(\"Implement calculate_max_borrow\")\n    }\n\n    pub fn calculate_collateral_value(collateral: u64, config: &CollateralConfig) -> u64 {\n        // TODO: Calculate USD value of collateral\n        todo!(\"Implement calculate_collateral_value\")\n    }\n\n    pub fn is_liquidatable(position: &CollateralPosition, config: &CollateralConfig) -> bool {\n        // TODO: Check if position should be liquidated\n        // True if borrowed > liquidation_threshold * collateral_value\n        todo!(\"Implement is_liquidatable\")\n    }\n\n    pub fn calculate_health_factor(position: &CollateralPosition, config: &CollateralConfig) -> f64 {\n        // TODO: Calculate health factor (collateral_value * ltv / borrowed)\n        // Returns infinity if no borrow\n        todo!(\"Implement calculate_health_factor\")\n    }\n}",
              "solution": "pub struct CollateralConfig {\n    pub ltv_bps: u64,\n    pub liquidation_threshold_bps: u64,\n    pub collateral_price: u64,\n}\n\npub struct CollateralPosition {\n    pub collateral_amount: u64,\n    pub borrowed_amount: u64,\n}\n\npub struct CollateralCalculator;\n\nimpl CollateralCalculator {\n    pub fn calculate_max_borrow(collateral: u64, config: &CollateralConfig) -> u64 {\n        let collateral_value = Self::calculate_collateral_value(collateral, config);\n        (collateral_value as u128 * config.ltv_bps as u128 / 10000) as u64\n    }\n\n    pub fn calculate_collateral_value(collateral: u64, config: &CollateralConfig) -> u64 {\n        // Price has 6 decimals, so divide by 1_000_000\n        (collateral as u128 * config.collateral_price as u128 / 1_000_000) as u64\n    }\n\n    pub fn is_liquidatable(position: &CollateralPosition, config: &CollateralConfig) -> bool {\n        let collateral_value = Self::calculate_collateral_value(position.collateral_amount, config);\n        let max_safe_borrow = (collateral_value as u128 * config.liquidation_threshold_bps as u128 / 10000) as u64;\n        position.borrowed_amount > max_safe_borrow\n    }\n\n    pub fn calculate_health_factor(position: &CollateralPosition, config: &CollateralConfig) -> f64 {\n        if position.borrowed_amount == 0 {\n            return f64::INFINITY;\n        }\n        let collateral_value = Self::calculate_collateral_value(position.collateral_amount, config);\n        (collateral_value as f64 * config.ltv_bps as f64 / 10000.0) / position.borrowed_amount as f64\n    }\n}",
              "hints": [
                "Max borrow is collateral value times LTV ratio",
                "Position is liquidatable when borrowed exceeds threshold * value",
                "Health factor shows how close to liquidation (higher is safer)"
              ],
              "testCases": [
                {
                  "input": {
                    "collateral": 1000000,
                    "price": 1000000,
                    "ltv": 7500
                  },
                  "expected": {
                    "max_borrow": 750000
                  }
                },
                {
                  "input": {
                    "collateral": 1000000,
                    "price": 2000000
                  },
                  "expected": {
                    "value": 2000000
                  }
                },
                {
                  "input": {
                    "collateral": 1000000,
                    "borrowed": 900000,
                    "price": 1000000,
                    "liq_threshold": 8000
                  },
                  "expected": {
                    "liquidatable": true
                  }
                }
              ]
            },
            {
              "id": "lesson-14-2-3",
              "type": "challenge",
              "title": "Interest Rate Model Challenge",
              "description": "Implement a utilization-based interest rate model.",
              "starterCode": "pub struct InterestRateModel {\n    pub base_rate_bps: u64,\n    pub slope1_bps: u64,\n    pub slope2_bps: u64,\n    pub optimal_utilization_bps: u64,\n}\n\npub struct InterestRateCalculator;\n\nimpl InterestRateCalculator {\n    pub fn calculate_utilization(total_borrowed: u64, total_supplied: u64) -> u64 {\n        // TODO: Calculate utilization rate in basis points\n        // utilization = borrowed / supplied * 10000\n        todo!(\"Implement calculate_utilization\")\n    }\n\n    pub fn calculate_borrow_rate(model: &InterestRateModel, utilization: u64) -> u64 {\n        // TODO: Calculate borrow interest rate based on utilization\n        // Below optimal: base + slope1 * (util / optimal)\n        // Above optimal: base + slope1 + slope2 * ((util - optimal) / (10000 - optimal))\n        todo!(\"Implement calculate_borrow_rate\")\n    }\n\n    pub fn calculate_supply_rate(borrow_rate: u64, utilization: u64, reserve_factor_bps: u64) -> u64 {\n        // TODO: Calculate supply rate (what lenders earn)\n        // supply_rate = borrow_rate * utilization * (1 - reserve_factor)\n        todo!(\"Implement calculate_supply_rate\")\n    }\n\n    pub fn accrue_interest(principal: u64, rate_bps: u64, time_seconds: u64) -> u64 {\n        // TODO: Calculate accrued interest over time\n        // Assume rate is APR in basis points\n        // Seconds per year = 31,536,000\n        todo!(\"Implement accrue_interest\")\n    }\n}",
              "solution": "pub struct InterestRateModel {\n    pub base_rate_bps: u64,\n    pub slope1_bps: u64,\n    pub slope2_bps: u64,\n    pub optimal_utilization_bps: u64,\n}\n\npub struct InterestRateCalculator;\n\nimpl InterestRateCalculator {\n    pub fn calculate_utilization(total_borrowed: u64, total_supplied: u64) -> u64 {\n        if total_supplied == 0 {\n            return 0;\n        }\n        ((total_borrowed as u128 * 10000) / total_supplied as u128) as u64\n    }\n\n    pub fn calculate_borrow_rate(model: &InterestRateModel, utilization: u64) -> u64 {\n        if utilization <= model.optimal_utilization_bps {\n            // Below optimal\n            let slope_multiplier = (utilization as u128 * 10000) / model.optimal_utilization_bps as u128;\n            model.base_rate_bps + ((model.slope1_bps as u128 * slope_multiplier) / 10000) as u64\n        } else {\n            // Above optimal\n            let excess_util = utilization - model.optimal_utilization_bps;\n            let max_excess = 10000 - model.optimal_utilization_bps;\n            let slope2_multiplier = (excess_util as u128 * 10000) / max_excess as u128;\n            model.base_rate_bps + model.slope1_bps + ((model.slope2_bps as u128 * slope2_multiplier) / 10000) as u64\n        }\n    }\n\n    pub fn calculate_supply_rate(borrow_rate: u64, utilization: u64, reserve_factor_bps: u64) -> u64 {\n        let lender_share = 10000 - reserve_factor_bps;\n        ((borrow_rate as u128 * utilization as u128 * lender_share as u128) / (10000 * 10000)) as u64\n    }\n\n    pub fn accrue_interest(principal: u64, rate_bps: u64, time_seconds: u64) -> u64 {\n        let seconds_per_year: u64 = 31_536_000;\n        ((principal as u128 * rate_bps as u128 * time_seconds as u128) / (seconds_per_year as u128 * 10000)) as u64\n    }\n}",
              "hints": [
                "Utilization is borrowed divided by supplied",
                "Use piecewise function for borrow rate (below/above optimal)",
                "Supply rate accounts for reserve factor taken by protocol"
              ],
              "testCases": [
                {
                  "input": {
                    "borrowed": 7500,
                    "supplied": 10000
                  },
                  "expected": {
                    "utilization": 7500
                  }
                },
                {
                  "input": {
                    "utilization": 5000,
                    "base": 200,
                    "slope1": 1000,
                    "optimal": 8000
                  },
                  "expected": {
                    "rate": 825
                  }
                },
                {
                  "input": {
                    "principal": 1000000,
                    "rate": 1000,
                    "time": 31536000
                  },
                  "expected": {
                    "interest": 100000
                  }
                }
              ]
            },
            {
              "id": "lesson-14-2-4",
              "type": "challenge",
              "title": "Flash Loan Validator Challenge",
              "description": "Implement flash loan validation logic.",
              "starterCode": "pub struct FlashLoan {\n    pub amount: u64,\n    pub fee_bps: u64,\n    pub token: String,\n}\n\npub struct FlashLoanReceipt {\n    pub borrowed: u64,\n    pub fee: u64,\n    pub total_repay: u64,\n}\n\npub struct FlashLoanValidator;\n\nimpl FlashLoanValidator {\n    pub fn calculate_repayment(loan: &FlashLoan) -> FlashLoanReceipt {\n        // TODO: Calculate total amount that must be repaid\n        todo!(\"Implement calculate_repayment\")\n    }\n\n    pub fn validate_repayment(loan: &FlashLoan, repayment: u64) -> bool {\n        // TODO: Check if repayment covers principal + fee\n        todo!(\"Implement validate_repayment\")\n    }\n\n    pub fn calculate_profit(opportunity_gain: u64, loan: &FlashLoan) -> i64 {\n        // TODO: Calculate net profit from arbitrage opportunity\n        todo!(\"Implement calculate_profit\")\n    }\n\n    pub fn is_profitable(opportunity_gain: u64, loan: &FlashLoan) -> bool {\n        // TODO: Check if flash loan arbitrage is profitable\n        todo!(\"Implement is_profitable\")\n    }\n}",
              "solution": "pub struct FlashLoan {\n    pub amount: u64,\n    pub fee_bps: u64,\n    pub token: String,\n}\n\npub struct FlashLoanReceipt {\n    pub borrowed: u64,\n    pub fee: u64,\n    pub total_repay: u64,\n}\n\npub struct FlashLoanValidator;\n\nimpl FlashLoanValidator {\n    pub fn calculate_repayment(loan: &FlashLoan) -> FlashLoanReceipt {\n        let fee = ((loan.amount as u128 * loan.fee_bps as u128) / 10000) as u64;\n        FlashLoanReceipt {\n            borrowed: loan.amount,\n            fee,\n            total_repay: loan.amount + fee,\n        }\n    }\n\n    pub fn validate_repayment(loan: &FlashLoan, repayment: u64) -> bool {\n        let receipt = Self::calculate_repayment(loan);\n        repayment >= receipt.total_repay\n    }\n\n    pub fn calculate_profit(opportunity_gain: u64, loan: &FlashLoan) -> i64 {\n        let receipt = Self::calculate_repayment(loan);\n        opportunity_gain as i64 - receipt.fee as i64\n    }\n\n    pub fn is_profitable(opportunity_gain: u64, loan: &FlashLoan) -> bool {\n        let receipt = Self::calculate_repayment(loan);\n        opportunity_gain > receipt.fee\n    }\n}",
              "hints": [
                "Fee is amount times fee_bps divided by 10000",
                "Total repay is principal plus fee",
                "Profit is gain minus fee (use i64 for signed result)"
              ],
              "testCases": [
                {
                  "input": {
                    "amount": 1000000,
                    "fee_bps": 9
                  },
                  "expected": {
                    "fee": 900,
                    "total_repay": 1000900
                  }
                },
                {
                  "input": {
                    "amount": 1000000,
                    "fee_bps": 9,
                    "repayment": 1000900
                  },
                  "expected": {
                    "valid": true
                  }
                },
                {
                  "input": {
                    "amount": 1000000,
                    "fee_bps": 9,
                    "gain": 2000
                  },
                  "expected": {
                    "profitable": true,
                    "profit": 1100
                  }
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course-039",
      "slug": "solana-nft-standards",
      "title": "NFT Standards on Solana",
      "description": "Implement Solana NFTs with production-ready standards: metadata integrity, collection discipline, and advanced programmable/non-transferable behaviors.",
      "difficulty": "intermediate",
      "duration": "5 weeks",
      "totalXP": 1850,
      "tags": [
        "nft",
        "metaplex",
        "token-metadata",
        "candy-machine",
        "soulbound"
      ],
      "imageUrl": "/images/courses/solana-nft.svg",
      "modules": [
        {
          "id": "mod-15-1",
          "title": "NFT Fundamentals",
          "description": "Build core NFT functionality with standards-compliant metadata, collection verification, and deterministic asset-state handling.",
          "lessons": [
            {
              "id": "lesson-15-1-1",
              "type": "content",
              "title": "NFT Architecture on Solana",
              "content": "NFT architecture on Solana combines token mechanics with metadata and collection semantics. A correct implementation requires more than minting a token with supply one.\n\nCore components include:\n- mint/state ownership correctness,\n- metadata integrity and schema consistency,\n- collection linkage and verification status,\n- transfer and authority policy clarity.\n\nProduction NFT systems should treat metadata as a contract. If fields drift or verification flags are inconsistent, marketplaces and wallets may interpret assets differently.\n\nReliable implementations include deterministic validation for metadata structure, creator share totals, collection references, and authority expectations. Standards compliance is what preserves interoperability."
            },
            {
              "id": "lesson-15-1-2",
              "type": "challenge",
              "title": "NFT Metadata Parser Challenge",
              "description": "Parse and validate NFT metadata according to Metaplex standards.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct NFTMetadata {\n    pub name: String,\n    pub symbol: String,\n    pub uri: String,\n    pub seller_fee_basis_points: u16,\n    pub creators: Vec<Creator>,\n}\n\n#[derive(Debug, Clone)]\npub struct Creator {\n    pub address: String,\n    pub verified: bool,\n    pub share: u8,\n}\n\npub struct MetadataParser;\n\nimpl MetadataParser {\n    pub fn validate_name(name: &str) -> bool {\n        // TODO: Validate name length (1-32 chars)\n        todo!(\"Implement validate_name\")\n    }\n\n    pub fn validate_symbol(symbol: &str) -> bool {\n        // TODO: Validate symbol length (0-10 chars)\n        todo!(\"Implement validate_symbol\")\n    }\n\n    pub fn validate_creators(creators: &[Creator]) -> Result<(), String> {\n        // TODO: Validate creators: max 5, shares sum to 100\n        todo!(\"Implement validate_creators\")\n    }\n\n    pub fn calculate_royalty(sale_price: u64, fee_basis_points: u16) -> u64 {\n        // TODO: Calculate royalty amount from sale price\n        todo!(\"Implement calculate_royalty\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct NFTMetadata {\n    pub name: String,\n    pub symbol: String,\n    pub uri: String,\n    pub seller_fee_basis_points: u16,\n    pub creators: Vec<Creator>,\n}\n\n#[derive(Debug, Clone)]\npub struct Creator {\n    pub address: String,\n    pub verified: bool,\n    pub share: u8,\n}\n\npub struct MetadataParser;\n\nimpl MetadataParser {\n    pub fn validate_name(name: &str) -> bool {\n        !name.is_empty() && name.len() <= 32\n    }\n\n    pub fn validate_symbol(symbol: &str) -> bool {\n        symbol.len() <= 10\n    }\n\n    pub fn validate_creators(creators: &[Creator]) -> Result<(), String> {\n        if creators.len() > 5 {\n            return Err(\"Too many creators (max 5)\".to_string());\n        }\n\n        let total_share: u8 = creators.iter().map(|c| c.share).sum();\n        if total_share != 100 {\n            return Err(format!(\"Creator shares must sum to 100, got {}\", total_share));\n        }\n\n        Ok(())\n    }\n\n    pub fn calculate_royalty(sale_price: u64, fee_basis_points: u16) -> u64 {\n        ((sale_price as u128 * fee_basis_points as u128) / 10000) as u64\n    }\n}",
              "hints": [
                "Check string lengths with len() method",
                "Sum creator shares and verify equals 100",
                "Royalty is sale_price * fee_bps / 10000"
              ],
              "testCases": [
                {
                  "input": {
                    "name": "Cool NFT #1234"
                  },
                  "expected": {
                    "valid": true
                  }
                },
                {
                  "input": {
                    "symbol": "COOL"
                  },
                  "expected": {
                    "valid": true
                  }
                },
                {
                  "input": {
                    "creators": [
                      {
                        "share": 60
                      },
                      {
                        "share": 40
                      }
                    ]
                  },
                  "expected": {
                    "valid": true
                  }
                },
                {
                  "input": {
                    "sale_price": 10000,
                    "fee_bps": 500
                  },
                  "expected": {
                    "royalty": 500
                  }
                }
              ]
            },
            {
              "id": "lesson-15-1-3",
              "type": "challenge",
              "title": "Collection Manager Challenge",
              "description": "Implement NFT collection management with size tracking.",
              "starterCode": "pub struct Collection {\n    pub name: String,\n    pub symbol: String,\n    pub max_size: u32,\n    pub current_size: u32,\n    pub verified: bool,\n}\n\npub struct CollectionManager;\n\nimpl CollectionManager {\n    pub fn can_mint(collection: &Collection) -> bool {\n        // TODO: Check if collection can accept new NFTs\n        todo!(\"Implement can_mint\")\n    }\n\n    pub fn remaining_spots(collection: &Collection) -> u32 {\n        // TODO: Calculate remaining mint spots\n        todo!(\"Implement remaining_spots\")\n    }\n\n    pub fn mint_percentage(collection: &Collection) -> f64 {\n        // TODO: Calculate percentage minted (0.0 to 100.0)\n        todo!(\"Implement mint_percentage\")\n    }\n\n    pub fn is_complete(collection: &Collection) -> bool {\n        // TODO: Check if collection is fully minted\n        todo!(\"Implement is_complete\")\n    }\n\n    pub fn verify_collection(collection: &mut Collection) -> Result<(), String> {\n        // TODO: Mark collection as verified if complete\n        todo!(\"Implement verify_collection\")\n    }\n}",
              "solution": "pub struct Collection {\n    pub name: String,\n    pub symbol: String,\n    pub max_size: u32,\n    pub current_size: u32,\n    pub verified: bool,\n}\n\npub struct CollectionManager;\n\nimpl CollectionManager {\n    pub fn can_mint(collection: &Collection) -> bool {\n        collection.current_size < collection.max_size\n    }\n\n    pub fn remaining_spots(collection: &Collection) -> u32 {\n        collection.max_size - collection.current_size\n    }\n\n    pub fn mint_percentage(collection: &Collection) -> f64 {\n        if collection.max_size == 0 {\n            return 0.0;\n        }\n        (collection.current_size as f64 / collection.max_size as f64) * 100.0\n    }\n\n    pub fn is_complete(collection: &Collection) -> bool {\n        collection.current_size >= collection.max_size\n    }\n\n    pub fn verify_collection(collection: &mut Collection) -> Result<(), String> {\n        if !Self::is_complete(collection) {\n            return Err(\"Collection must be complete to verify\".to_string());\n        }\n        collection.verified = true;\n        Ok(())\n    }\n}",
              "hints": [
                "Can mint if current_size < max_size",
                "Percentage is (current / max) * 100",
                "Only verify if collection is complete"
              ],
              "testCases": [
                {
                  "input": {
                    "max": 10000,
                    "current": 5000
                  },
                  "expected": {
                    "can_mint": true,
                    "remaining": 5000
                  }
                },
                {
                  "input": {
                    "max": 10000,
                    "current": 7500
                  },
                  "expected": {
                    "percentage": 75
                  }
                },
                {
                  "input": {
                    "max": 10000,
                    "current": 10000
                  },
                  "expected": {
                    "complete": true
                  }
                },
                {
                  "input": {
                    "max": 10000,
                    "current": 10000,
                    "verify": true
                  },
                  "expected": {
                    "verified": true
                  }
                }
              ]
            },
            {
              "id": "lesson-15-1-4",
              "type": "challenge",
              "title": "Attribute Rarity Calculator Challenge",
              "description": "Calculate NFT attribute rarity scores.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct Attribute {\n    pub trait_type: String,\n    pub value: String,\n}\n\npub struct RarityCalculator;\n\nimpl RarityCalculator {\n    pub fn calculate_trait_rarity(count_with_trait: u32, total_supply: u32) -> f64 {\n        // TODO: Calculate rarity percentage for a trait\n        // rarity = count / total * 100\n        todo!(\"Implement calculate_trait_rarity\")\n    }\n\n    pub fn calculate_rarity_score(count_with_trait: u32, total_supply: u32) -> f64 {\n        // TODO: Calculate rarity score (1 / rarity_percentage)\n        // Higher score = rarer trait\n        todo!(\"Implement calculate_rarity_score\")\n    }\n\n    pub fn calculate_nft_rarity_score(trait_counts: &[u32], total_supply: u32) -> f64 {\n        // TODO: Calculate overall NFT rarity score from all traits\n        // Sum of individual rarity scores\n        todo!(\"Implement calculate_nft_rarity_score\")\n    }\n\n    pub fn rank_by_rarity(nft_scores: &mut [(String, f64)]) -> Vec<(String, u32)> {\n        // TODO: Sort NFTs by rarity score and assign ranks\n        // Highest score gets rank 1\n        todo!(\"Implement rank_by_rarity\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct Attribute {\n    pub trait_type: String,\n    pub value: String,\n}\n\npub struct RarityCalculator;\n\nimpl RarityCalculator {\n    pub fn calculate_trait_rarity(count_with_trait: u32, total_supply: u32) -> f64 {\n        if total_supply == 0 {\n            return 0.0;\n        }\n        (count_with_trait as f64 / total_supply as f64) * 100.0\n    }\n\n    pub fn calculate_rarity_score(count_with_trait: u32, total_supply: u32) -> f64 {\n        let rarity = Self::calculate_trait_rarity(count_with_trait, total_supply);\n        if rarity == 0.0 {\n            return 0.0;\n        }\n        1.0 / (rarity / 100.0)\n    }\n\n    pub fn calculate_nft_rarity_score(trait_counts: &[u32], total_supply: u32) -> f64 {\n        trait_counts\n            .iter()\n            .map(|&count| Self::calculate_rarity_score(count, total_supply))\n            .sum()\n    }\n\n    pub fn rank_by_rarity(nft_scores: &mut [(String, f64)]) -> Vec<(String, u32)> {\n        // Sort by score descending (highest first)\n        nft_scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());\n\n        nft_scores\n            .iter()\n            .enumerate()\n            .map(|(i, (name, _))| (name.clone(), (i + 1) as u32))\n            .collect()\n    }\n}",
              "hints": [
                "Rarity percentage is (count / total) * 100",
                "Rarity score is inverse of rarity (1 / rarity)",
                "Sort descending by score for ranking (highest = rank 1)"
              ],
              "testCases": [
                {
                  "input": {
                    "count": 100,
                    "total": 10000
                  },
                  "expected": {
                    "rarity": 1,
                    "score": 100
                  }
                },
                {
                  "input": {
                    "trait_counts": [
                      100,
                      200,
                      50
                    ],
                    "total": 10000
                  },
                  "expected": {
                    "score": 350
                  }
                },
                {
                  "input": {
                    "nfts": [
                      [
                        "A",
                        150
                      ],
                      [
                        "B",
                        200
                      ],
                      [
                        "C",
                        100
                      ]
                    ]
                  },
                  "expected": {
                    "ranks": [
                      [
                        "B",
                        1
                      ],
                      [
                        "A",
                        2
                      ],
                      [
                        "C",
                        3
                      ]
                    ]
                  }
                }
              ]
            }
          ]
        },
        {
          "id": "mod-15-2",
          "title": "Advanced NFT Features",
          "description": "Implement advanced NFT behaviors (soulbound and programmable flows) with explicit policy controls and safe update semantics.",
          "lessons": [
            {
              "id": "lesson-15-2-1",
              "type": "content",
              "title": "Soulbound and Programmable NFTs",
              "content": "Advanced NFT features introduce policy complexity that must be explicit. Soulbound behavior, programmable restrictions, and dynamic metadata updates all expand failure surface.\n\nFor soulbound models, non-transferability must be enforced by clear rule paths, not UI assumptions. For programmable NFTs, update permissions and transition rules should be deterministic and auditable.\n\nDynamic NFT updates should include strong validation and event clarity so indexers and clients can track state changes correctly.\n\nAdvanced NFT engineering succeeds when flexibility is paired with strict policy boundaries and transparent update behavior."
            },
            {
              "id": "lesson-15-2-2",
              "type": "challenge",
              "title": "Soulbound Token Validator Challenge",
              "description": "Implement validation for soulbound (non-transferable) tokens.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct TokenRules {\n    pub is_soulbound: bool,\n    pub is_burnable: bool,\n    pub transfer_restrictions: Vec<String>,\n}\n\npub struct SoulboundValidator;\n\nimpl SoulboundValidator {\n    pub fn can_transfer(rules: &TokenRules, from: &str, to: &str) -> bool {\n        // TODO: Check if transfer is allowed\n        // Soulbound tokens cannot be transferred\n        todo!(\"Implement can_transfer\")\n    }\n\n    pub fn can_burn(rules: &TokenRules, owner: &str, burner: &str) -> bool {\n        // TODO: Check if burn is allowed\n        // Only owner can burn if burnable\n        todo!(\"Implement can_burn\")\n    }\n\n    pub fn validate_mint(rules: &TokenRules, recipient: &str) -> Result<(), String> {\n        // TODO: Validate mint operation\n        // Soulbound tokens can only be minted to specific recipients\n        todo!(\"Implement validate_mint\")\n    }\n\n    pub fn is_restricted_transfer(rules: &TokenRules, from: &str, to: &str) -> bool {\n        // TODO: Check if transfer is restricted\n        todo!(\"Implement is_restricted_transfer\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct TokenRules {\n    pub is_soulbound: bool,\n    pub is_burnable: bool,\n    pub transfer_restrictions: Vec<String>,\n}\n\npub struct SoulboundValidator;\n\nimpl SoulboundValidator {\n    pub fn can_transfer(rules: &TokenRules, _from: &str, _to: &str) -> bool {\n        !rules.is_soulbound\n    }\n\n    pub fn can_burn(rules: &TokenRules, owner: &str, burner: &str) -> bool {\n        rules.is_burnable && owner == burner\n    }\n\n    pub fn validate_mint(rules: &TokenRules, recipient: &str) -> Result<(), String> {\n        if rules.is_soulbound && recipient.is_empty() {\n            return Err(\"Soulbound tokens require valid recipient\".to_string());\n        }\n        Ok(())\n    }\n\n    pub fn is_restricted_transfer(rules: &TokenRules, from: &str, to: &str) -> bool {\n        rules.transfer_restrictions.iter().any(|r| {\n            r == from || r == to\n        })\n    }\n}",
              "hints": [
                "Soulbound tokens return false for can_transfer",
                "Burn requires is_burnable and owner == burner",
                "Use any() to check if address is in restrictions list"
              ],
              "testCases": [
                {
                  "input": {
                    "soulbound": true,
                    "from": "A",
                    "to": "B"
                  },
                  "expected": {
                    "can_transfer": false
                  }
                },
                {
                  "input": {
                    "burnable": true,
                    "owner": "A",
                    "burner": "A"
                  },
                  "expected": {
                    "can_burn": true
                  }
                },
                {
                  "input": {
                    "restrictions": [
                      "A",
                      "B"
                    ],
                    "from": "C",
                    "to": "A"
                  },
                  "expected": {
                    "restricted": true
                  }
                }
              ]
            },
            {
              "id": "lesson-15-2-3",
              "type": "challenge",
              "title": "Dynamic NFT Updater Challenge",
              "description": "Implement dynamic NFT attributes that can evolve over time.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct DynamicAttribute {\n    pub name: String,\n    pub value: String,\n    pub last_updated: u64,\n    pub update_cooldown: u64,\n}\n\npub struct DynamicNFTUpdater;\n\nimpl DynamicNFTUpdater {\n    pub fn can_update(attribute: &DynamicAttribute, current_time: u64) -> bool {\n        // TODO: Check if attribute can be updated (cooldown passed)\n        todo!(\"Implement can_update\")\n    }\n\n    pub fn update_attribute(\n        attribute: &mut DynamicAttribute,\n        new_value: &str,\n        current_time: u64,\n    ) -> Result<(), String> {\n        // TODO: Update attribute value if cooldown passed\n        todo!(\"Implement update_attribute\")\n    }\n\n    pub fn evolve_attribute(\n        attribute: &mut DynamicAttribute,\n        evolution_stage: u32,\n        current_time: u64,\n    ) -> Result<(), String> {\n        // TODO: Evolve attribute to next stage (e.g., Level 1 -> Level 2)\n        todo!(\"Implement evolve_attribute\")\n    }\n\n    pub fn time_until_update(attribute: &DynamicAttribute, current_time: u64) -> u64 {\n        // TODO: Return seconds until next update is allowed\n        todo!(\"Implement time_until_update\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct DynamicAttribute {\n    pub name: String,\n    pub value: String,\n    pub last_updated: u64,\n    pub update_cooldown: u64,\n}\n\npub struct DynamicNFTUpdater;\n\nimpl DynamicNFTUpdater {\n    pub fn can_update(attribute: &DynamicAttribute, current_time: u64) -> bool {\n        current_time >= attribute.last_updated + attribute.update_cooldown\n    }\n\n    pub fn update_attribute(\n        attribute: &mut DynamicAttribute,\n        new_value: &str,\n        current_time: u64,\n    ) -> Result<(), String> {\n        if !Self::can_update(attribute, current_time) {\n            return Err(\"Update cooldown not elapsed\".to_string());\n        }\n        attribute.value = new_value.to_string();\n        attribute.last_updated = current_time;\n        Ok(())\n    }\n\n    pub fn evolve_attribute(\n        attribute: &mut DynamicAttribute,\n        evolution_stage: u32,\n        current_time: u64,\n    ) -> Result<(), String> {\n        if !Self::can_update(attribute, current_time) {\n            return Err(\"Evolution cooldown not elapsed\".to_string());\n        }\n        attribute.value = format!(\"{} Level {}\", attribute.name, evolution_stage);\n        attribute.last_updated = current_time;\n        Ok(())\n    }\n\n    pub fn time_until_update(attribute: &DynamicAttribute, current_time: u64) -> u64 {\n        let next_update = attribute.last_updated + attribute.update_cooldown;\n        if current_time >= next_update {\n            0\n        } else {\n            next_update - current_time\n        }\n    }\n}",
              "hints": [
                "Can update if current_time >= last_updated + cooldown",
                "Update last_updated timestamp after successful update",
                "Time until update is max(0, next_update - current_time)"
              ],
              "testCases": [
                {
                  "input": {
                    "last_updated": 0,
                    "cooldown": 86400,
                    "current": 90000
                  },
                  "expected": {
                    "can_update": true
                  }
                },
                {
                  "input": {
                    "last_updated": 0,
                    "cooldown": 86400,
                    "current": 43200
                  },
                  "expected": {
                    "time_until": 43200
                  }
                },
                {
                  "input": {
                    "name": "Power",
                    "stage": 3
                  },
                  "expected": {
                    "value": "Power Level 3"
                  }
                }
              ]
            },
            {
              "id": "lesson-15-2-4",
              "type": "challenge",
              "title": "NFT Composability Challenge",
              "description": "Implement NFT composability for equipping items to base NFTs.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct BaseNFT {\n    pub id: String,\n    pub equipped_items: Vec<String>,\n    pub max_slots: u8,\n}\n\n#[derive(Debug, Clone)]\npub struct ItemNFT {\n    pub id: String,\n    pub item_type: String,\n    pub compatible_with: Vec<String>,\n}\n\npub struct NFTComposability;\n\nimpl NFTComposability {\n    pub fn can_equip(base: &BaseNFT, item: &ItemNFT) -> bool {\n        // TODO: Check if item can be equipped to base\n        // Must have available slot and be compatible\n        todo!(\"Implement can_equip\")\n    }\n\n    pub fn equip_item(base: &mut BaseNFT, item: &ItemNFT) -> Result<(), String> {\n        // TODO: Equip item to base NFT\n        todo!(\"Implement equip_item\")\n    }\n\n    pub fn unequip_item(base: &mut BaseNFT, item_id: &str) -> Result<String, String> {\n        // TODO: Remove item from base and return item ID\n        todo!(\"Implement unequip_item\")\n    }\n\n    pub fn get_equipped_by_type(base: &BaseNFT, item_type: &str, items: &[ItemNFT]) -> Vec<String> {\n        // TODO: Return IDs of equipped items matching the type\n        todo!(\"Implement get_equipped_by_type\")\n    }\n\n    pub fn available_slots(base: &BaseNFT) -> u8 {\n        // TODO: Calculate remaining equipment slots\n        todo!(\"Implement available_slots\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct BaseNFT {\n    pub id: String,\n    pub equipped_items: Vec<String>,\n    pub max_slots: u8,\n}\n\n#[derive(Debug, Clone)]\npub struct ItemNFT {\n    pub id: String,\n    pub item_type: String,\n    pub compatible_with: Vec<String>,\n}\n\npub struct NFTComposability;\n\nimpl NFTComposability {\n    pub fn can_equip(base: &BaseNFT, item: &ItemNFT) -> bool {\n        let has_slot = base.equipped_items.len() < base.max_slots as usize;\n        let is_compatible = item.compatible_with.contains(&base.id);\n        let not_equipped = !base.equipped_items.contains(&item.id);\n        has_slot && is_compatible && not_equipped\n    }\n\n    pub fn equip_item(base: &mut BaseNFT, item: &ItemNFT) -> Result<(), String> {\n        if !Self::can_equip(base, item) {\n            return Err(\"Cannot equip item\".to_string());\n        }\n        base.equipped_items.push(item.id.clone());\n        Ok(())\n    }\n\n    pub fn unequip_item(base: &mut BaseNFT, item_id: &str) -> Result<String, String> {\n        if let Some(pos) = base.equipped_items.iter().position(|id| id == item_id) {\n            base.equipped_items.remove(pos);\n            Ok(item_id.to_string())\n        } else {\n            Err(\"Item not equipped\".to_string())\n        }\n    }\n\n    pub fn get_equipped_by_type(base: &BaseNFT, item_type: &str, items: &[ItemNFT]) -> Vec<String> {\n        base.equipped_items\n            .iter()\n            .filter(|equipped_id| {\n                items.iter().any(|item| {\n                    &item.id == *equipped_id && item.item_type == item_type\n                })\n            })\n            .cloned()\n            .collect()\n    }\n\n    pub fn available_slots(base: &BaseNFT) -> u8 {\n        base.max_slots - base.equipped_items.len() as u8\n    }\n}",
              "hints": [
                "Check available slots, compatibility, and not already equipped",
                "Use position() and remove() to unequip items",
                "Filter equipped items by matching type in items list"
              ],
              "testCases": [
                {
                  "input": {
                    "equipped": 2,
                    "max": 5,
                    "compatible": true
                  },
                  "expected": {
                    "can_equip": true,
                    "available": 3
                  }
                },
                {
                  "input": {
                    "equipped": [
                      "item1",
                      "item2"
                    ],
                    "unequip": "item1"
                  },
                  "expected": {
                    "equipped": [
                      "item2"
                    ]
                  }
                },
                {
                  "input": {
                    "equipped": [
                      "sword1",
                      "shield1"
                    ],
                    "items": [
                      {
                        "id": "sword1",
                        "type": "weapon"
                      }
                    ],
                    "type": "weapon"
                  },
                  "expected": {
                    "matching": [
                      "sword1"
                    ]
                  }
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course-040",
      "slug": "solana-cpi-patterns",
      "title": "Cross-Program Invocation Patterns",
      "description": "Master CPI composition on Solana with safe account validation, PDA signer discipline, and deterministic multi-program orchestration patterns.",
      "difficulty": "advanced",
      "duration": "6 weeks",
      "totalXP": 2100,
      "tags": [
        "cpi",
        "cross-program-invocation",
        "composition",
        "pda-signing"
      ],
      "imageUrl": "/images/courses/solana-cpi.svg",
      "modules": [
        {
          "id": "mod-16-1",
          "title": "CPI Fundamentals",
          "description": "Build CPI fundamentals with strict account/signer checks, ownership validation, and safe PDA signing boundaries.",
          "lessons": [
            {
              "id": "lesson-16-1-1",
              "type": "content",
              "title": "Cross-Program Invocation Architecture",
              "content": "Cross-Program Invocation (CPI) is where Solana composability becomes practical and where many security failures appear. The caller controls account lists, so every CPI boundary must be treated as untrusted input.\n\nSafe CPI design requires:\n- explicit account identity and owner validation,\n- signer and writable scope minimization,\n- deterministic PDA derivation and signer-seed handling,\n- bounded assumptions about downstream program behavior.\n\ninvoke and invoke_signed are not interchangeable conveniences. invoke_signed should only be used when signer proof is truly required and seed recipes are canonical.\n\nProduction CPI reliability comes from repeatable guard patterns. If constraints vary handler to handler, reviewers cannot reason about security consistently."
            },
            {
              "id": "lesson-16-1-2",
              "type": "challenge",
              "title": "CPI Account Validator Challenge",
              "description": "Validate accounts for cross-program invocations.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct CPIAccount {\n    pub key: String,\n    pub is_signer: bool,\n    pub is_writable: bool,\n    pub lamports: u64,\n}\n\npub struct CPIAccountValidator;\n\nimpl CPIAccountValidator {\n    pub fn validate_signer(account: &CPIAccount) -> Result<(), String> {\n        // TODO: Validate account is a signer\n        todo!(\"Implement validate_signer\")\n    }\n\n    pub fn validate_writable(account: &CPIAccount) -> Result<(), String> {\n        // TODO: Validate account is writable\n        todo!(\"Implement validate_writable\")\n    }\n\n    pub fn validate_balance(account: &CPIAccount, min_balance: u64) -> Result<(), String> {\n        // TODO: Validate account has minimum balance\n        todo!(\"Implement validate_balance\")\n    }\n\n    pub fn prepare_account_metas(accounts: &[CPIAccount], caller_is_signer: bool) -> Vec<(String, bool, bool)> {\n        // TODO: Prepare account metas for CPI\n        // Returns Vec of (key, is_signer, is_writable)\n        // If caller_is_signer, mark accounts that are signers in parent\n        todo!(\"Implement prepare_account_metas\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct CPIAccount {\n    pub key: String,\n    pub is_signer: bool,\n    pub is_writable: bool,\n    pub lamports: u64,\n}\n\npub struct CPIAccountValidator;\n\nimpl CPIAccountValidator {\n    pub fn validate_signer(account: &CPIAccount) -> Result<(), String> {\n        if account.is_signer {\n            Ok(())\n        } else {\n            Err(format!(\"Account {} must be a signer\", account.key))\n        }\n    }\n\n    pub fn validate_writable(account: &CPIAccount) -> Result<(), String> {\n        if account.is_writable {\n            Ok(())\n        } else {\n            Err(format!(\"Account {} must be writable\", account.key))\n        }\n    }\n\n    pub fn validate_balance(account: &CPIAccount, min_balance: u64) -> Result<(), String> {\n        if account.lamports >= min_balance {\n            Ok(())\n        } else {\n            Err(format!(\n                \"Account {} has insufficient balance: {} < {}\",\n                account.key, account.lamports, min_balance\n            ))\n        }\n    }\n\n    pub fn prepare_account_metas(accounts: &[CPIAccount], caller_is_signer: bool) -> Vec<(String, bool, bool)> {\n        accounts\n            .iter()\n            .map(|acc| {\n                let is_signer = acc.is_signer || caller_is_signer;\n                (acc.key.clone(), is_signer, acc.is_writable)\n            })\n            .collect()\n    }\n}",
              "hints": [
                "Check boolean flags for signer and writable validation",
                "For balance, compare lamports against minimum required",
                "Privilege extension: if caller is signer, child can sign too"
              ],
              "testCases": [
                {
                  "input": {
                    "is_signer": true
                  },
                  "expected": {
                    "valid": true
                  }
                },
                {
                  "input": {
                    "lamports": 1000,
                    "min": 500
                  },
                  "expected": {
                    "valid": true
                  }
                },
                {
                  "input": {
                    "accounts": [
                      {
                        "signer": false,
                        "writable": true
                      }
                    ],
                    "caller_signer": true
                  },
                  "expected": {
                    "metas": [
                      [
                        "",
                        true,
                        true
                      ]
                    ]
                  }
                }
              ]
            },
            {
              "id": "lesson-16-1-3",
              "type": "challenge",
              "title": "PDA Signer Challenge",
              "description": "Implement PDA signing for CPI operations.",
              "starterCode": "pub struct PDASigner {\n    pub seeds: Vec<Vec<u8>>,\n    pub bump: u8,\n}\n\npub struct PDASignerGenerator;\n\nimpl PDASignerGenerator {\n    pub fn create_seed_slices(seeds: &[&str]) -> Vec<Vec<u8>> {\n        // TODO: Convert string seeds to byte vectors\n        todo!(\"Implement create_seed_slices\")\n    }\n\n    pub fn find_program_address(seeds: &[Vec<u8>], program_id: &str) -> (String, u8) {\n        // TODO: Find valid PDA (address ending with valid bump)\n        // Return (address, bump) - simplified simulation\n        todo!(\"Implement find_program_address\")\n    }\n\n    pub fn sign_message(message: &[u8], pda: &PDASigner) -> Vec<u8> {\n        // TODO: Create signature using PDA seeds (simplified)\n        // In reality, this uses Ed25519, we simulate with hash\n        todo!(\"Implement sign_message\")\n    }\n\n    pub fn verify_pda_ownership(address: &str, expected_program: &str) -> bool {\n        // TODO: Verify PDA was derived from expected program\n        // Simplified: check if address contains program identifier\n        todo!(\"Implement verify_pda_ownership\")\n    }\n}",
              "solution": "pub struct PDASigner {\n    pub seeds: Vec<Vec<u8>>,\n    pub bump: u8,\n}\n\npub struct PDASignerGenerator;\n\nimpl PDASignerGenerator {\n    pub fn create_seed_slices(seeds: &[&str]) -> Vec<Vec<u8>> {\n        seeds.iter().map(|s| s.as_bytes().to_vec()).collect()\n    }\n\n    pub fn find_program_address(seeds: &[Vec<u8>], program_id: &str) -> (String, u8) {\n        // Simplified simulation - concatenate seeds and program_id, then hash\n        let mut combined = vec![];\n        for seed in seeds {\n            combined.extend_from_slice(seed);\n        }\n        combined.extend_from_slice(program_id.as_bytes());\n\n        // Simulate finding valid bump (off-curve point)\n        let mut bump = 255u8;\n        loop {\n            let mut with_bump = combined.clone();\n            with_bump.push(bump);\n\n            // Simple hash simulation\n            let hash: u32 = with_bump.iter().map(|&b| b as u32).sum();\n            if hash % 256 < 128 {\n                let address = format!(\"pda_{:x}_{}\", hash, bump);\n                return (address, bump);\n            }\n\n            bump -= 1;\n            if bump == 0 {\n                break;\n            }\n        }\n\n        (\"invalid\".to_string(), 0)\n    }\n\n    pub fn sign_message(message: &[u8], pda: &PDASigner) -> Vec<u8> {\n        // Simulate signature by combining message hash with seeds\n        let msg_hash: u32 = message.iter().map(|&b| b as u32).sum();\n        let seed_hash: u32 = pda.seeds.iter().flatten().map(|&b| b as u32).sum();\n\n        format!(\"sig_{:x}_{:x}_{}\", msg_hash, seed_hash, pda.bump)\n            .as_bytes()\n            .to_vec()\n    }\n\n    pub fn verify_pda_ownership(address: &str, expected_program: &str) -> bool {\n        // Simplified: check if address was generated from program\n        address.contains(&expected_program[..8.min(expected_program.len())])\n    }\n}",
              "hints": [
                "Convert string seeds to bytes using as_bytes()",
                "Simulate PDA finding by trying different bump values",
                "Signature simulation combines message and seed hashes"
              ],
              "testCases": [
                {
                  "input": {
                    "seeds": [
                      "user",
                      "data"
                    ]
                  },
                  "expected": {
                    "count": 2
                  }
                },
                {
                  "input": {
                    "seeds": [
                      [
                        1,
                        2
                      ]
                    ],
                    "program": "prog123"
                  },
                  "expected": {
                    "has_bump": true
                  }
                },
                {
                  "input": {
                    "message": [
                      1,
                      2,
                      3
                    ],
                    "pda": {
                      "bump": 254
                    }
                  },
                  "expected": {
                    "has_sig": true
                  }
                }
              ]
            },
            {
              "id": "lesson-16-1-4",
              "type": "challenge",
              "title": "Instruction Router Challenge",
              "description": "Implement an instruction router for directing CPI calls.",
              "starterCode": "#[derive(Debug, Clone)]\npub enum InstructionType {\n    Transfer,\n    Mint,\n    Burn,\n    Swap,\n}\n\npub struct Instruction {\n    pub program_id: String,\n    pub instruction_type: InstructionType,\n    pub data: Vec<u8>,\n}\n\npub struct InstructionRouter {\n    pub handlers: std::collections::HashMap<InstructionType, String>,\n}\n\nimpl InstructionRouter {\n    pub fn new() -> Self {\n        Self {\n            handlers: std::collections::HashMap::new(),\n        }\n    }\n\n    pub fn register_handler(&mut self, instruction_type: InstructionType, program_id: String) {\n        // TODO: Register a handler program for instruction type\n        todo!(\"Implement register_handler\")\n    }\n\n    pub fn route(&self, instruction: &Instruction) -> Result<String, String> {\n        // TODO: Route instruction to appropriate handler\n        // Return the program_id to call\n        todo!(\"Implement route\")\n    }\n\n    pub fn create_cpi_call(&self, instruction: &Instruction, accounts: Vec<String>) -> Result<(String, Vec<String>), String> {\n        // TODO: Create CPI call details (program_id, accounts)\n        todo!(\"Implement create_cpi_call\")\n    }\n\n    pub fn is_supported(&self, instruction_type: &InstructionType) -> bool {\n        // TODO: Check if instruction type has registered handler\n        todo!(\"Implement is_supported\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub enum InstructionType {\n    Transfer,\n    Mint,\n    Burn,\n    Swap,\n}\n\npub struct Instruction {\n    pub program_id: String,\n    pub instruction_type: InstructionType,\n    pub data: Vec<u8>,\n}\n\npub struct InstructionRouter {\n    pub handlers: std::collections::HashMap<InstructionType, String>,\n}\n\nimpl InstructionRouter {\n    pub fn new() -> Self {\n        Self {\n            handlers: std::collections::HashMap::new(),\n        }\n    }\n\n    pub fn register_handler(&mut self, instruction_type: InstructionType, program_id: String) {\n        self.handlers.insert(instruction_type, program_id);\n    }\n\n    pub fn route(&self, instruction: &Instruction) -> Result<String, String> {\n        if let Some(handler) = self.handlers.get(&instruction.instruction_type) {\n            Ok(handler.clone())\n        } else {\n            Err(format!(\"No handler for {:?}\", instruction.instruction_type))\n        }\n    }\n\n    pub fn create_cpi_call(&self, instruction: &Instruction, accounts: Vec<String>) -> Result<(String, Vec<String>), String> {\n        let program_id = self.route(instruction)?;\n        Ok((program_id, accounts))\n    }\n\n    pub fn is_supported(&self, instruction_type: &InstructionType) -> bool {\n        self.handlers.contains_key(instruction_type)\n    }\n}",
              "hints": [
                "Use HashMap insert to register handlers",
                "Route by looking up instruction_type in handlers map",
                "create_cpi_call combines route with account preparation"
              ],
              "testCases": [
                {
                  "input": {
                    "register": [
                      "Transfer",
                      "token_program"
                    ]
                  },
                  "expected": {
                    "supported": true
                  }
                },
                {
                  "input": {
                    "route": "Transfer"
                  },
                  "expected": {
                    "program": "token_program"
                  }
                },
                {
                  "input": {
                    "route": "Swap"
                  },
                  "expected": {
                    "error": "No handler"
                  }
                },
                {
                  "input": {
                    "accounts": [
                      "acc1",
                      "acc2"
                    ]
                  },
                  "expected": {
                    "cpi_accounts": 2
                  }
                }
              ]
            }
          ]
        },
        {
          "id": "mod-16-2",
          "title": "Advanced CPI Patterns",
          "description": "Compose advanced multi-program flows with atomicity awareness, consistency checks, and deterministic failure handling.",
          "lessons": [
            {
              "id": "lesson-16-2-1",
              "type": "content",
              "title": "Multi-Program Composition",
              "content": "Multi-program composition introduces sequencing and consistency risk. Even when each CPI call is correct in isolation, combined flows can violate business invariants if ordering or rollback assumptions are weak.\n\nRobust composition patterns include:\n1) explicit stage boundaries,\n2) invariant checks between CPI steps,\n3) deterministic error classes for partial-failure diagnosis,\n4) idempotent recovery paths where possible.\n\nFor complex operations (atomic swaps, flash-loan sequences), model expected preconditions and postconditions per stage. This keeps orchestration testable and prevents hidden state drift.\n\nCPI mastery is less about calling many programs and more about preserving correctness across program boundaries under adverse inputs."
            },
            {
              "id": "lesson-16-2-2",
              "type": "challenge",
              "title": "Atomic Swap Orchestrator Challenge",
              "description": "Implement an atomic swap across multiple programs.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct SwapStep {\n    pub program_id: String,\n    pub input_token: String,\n    pub output_token: String,\n    pub expected_output: u64,\n}\n\npub struct AtomicSwap {\n    pub steps: Vec<SwapStep>,\n    pub minimum_output: u64,\n}\n\npub struct SwapOrchestrator;\n\nimpl SwapOrchestrator {\n    pub fn validate_swap(swap: &AtomicSwap) -> Result<(), String> {\n        // TODO: Validate swap has at least one step and valid amounts\n        todo!(\"Implement validate_swap\")\n    }\n\n    pub fn calculate_total_expected(swap: &AtomicSwap) -> u64 {\n        // TODO: Calculate expected output from final step\n        todo!(\"Implement calculate_total_expected\")\n    }\n\n    pub fn verify_atomicity(swap: &AtomicSwap) -> bool {\n        // TODO: Verify all steps are connected (output of one is input of next)\n        todo!(\"Implement verify_atomicity\")\n    }\n\n    pub fn prepare_cpi_sequence(swap: &AtomicSwap) -> Vec<(String, String, u64)> {\n        // TODO: Prepare sequence of CPI calls\n        // Returns Vec of (program_id, input_token, expected_output)\n        todo!(\"Implement prepare_cpi_sequence\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct SwapStep {\n    pub program_id: String,\n    pub input_token: String,\n    pub output_token: String,\n    pub expected_output: u64,\n}\n\npub struct AtomicSwap {\n    pub steps: Vec<SwapStep>,\n    pub minimum_output: u64,\n}\n\npub struct SwapOrchestrator;\n\nimpl SwapOrchestrator {\n    pub fn validate_swap(swap: &AtomicSwap) -> Result<(), String> {\n        if swap.steps.is_empty() {\n            return Err(\"Swap must have at least one step\".to_string());\n        }\n        if swap.minimum_output == 0 {\n            return Err(\"Minimum output must be greater than 0\".to_string());\n        }\n        Ok(())\n    }\n\n    pub fn calculate_total_expected(swap: &AtomicSwap) -> u64 {\n        swap.steps.last().map(|s| s.expected_output).unwrap_or(0)\n    }\n\n    pub fn verify_atomicity(swap: &AtomicSwap) -> bool {\n        for i in 0..swap.steps.len() - 1 {\n            if swap.steps[i].output_token != swap.steps[i + 1].input_token {\n                return false;\n            }\n        }\n        true\n    }\n\n    pub fn prepare_cpi_sequence(swap: &AtomicSwap) -> Vec<(String, String, u64)> {\n        swap.steps\n            .iter()\n            .map(|step| (\n                step.program_id.clone(),\n                step.input_token.clone(),\n                step.expected_output,\n            ))\n            .collect()\n    }\n}",
              "hints": [
                "Validate that steps is not empty and minimum_output > 0",
                "Atomicity requires output_token of step N equals input_token of step N+1",
                "Map steps to (program_id, input_token, expected_output) tuples"
              ],
              "testCases": [
                {
                  "input": {
                    "steps": [
                      {
                        "expected": 100
                      }
                    ],
                    "min": 50
                  },
                  "expected": {
                    "valid": true
                  }
                },
                {
                  "input": {
                    "steps": [
                      {
                        "output": "B"
                      },
                      {
                        "input": "B"
                      }
                    ]
                  },
                  "expected": {
                    "atomic": true
                  }
                },
                {
                  "input": {
                    "steps": [
                      {
                        "output": "C"
                      },
                      {
                        "input": "B"
                      }
                    ]
                  },
                  "expected": {
                    "atomic": false
                  }
                },
                {
                  "input": {
                    "steps": [
                      {
                        "program": "A",
                        "input": "X",
                        "expected": 100
                      }
                    ]
                  },
                  "expected": {
                    "cpi": [
                      [
                        "A",
                        "X",
                        100
                      ]
                    ]
                  }
                }
              ]
            },
            {
              "id": "lesson-16-2-3",
              "type": "challenge",
              "title": "State Consistency Validator Challenge",
              "description": "Validate state consistency across multiple CPI calls.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct AccountState {\n    pub address: String,\n    pub balance: u64,\n    pub data_hash: String,\n}\n\npub struct StateSnapshot {\n    pub accounts: Vec<AccountState>,\n    pub timestamp: u64,\n}\n\npub struct ConsistencyValidator;\n\nimpl ConsistencyValidator {\n    pub fn capture_snapshot(accounts: &[AccountState], timestamp: u64) -> StateSnapshot {\n        // TODO: Create a state snapshot\n        todo!(\"Implement capture_snapshot\")\n    }\n\n    pub fn verify_no_changes(before: &StateSnapshot, after: &StateSnapshot, except: &[String]) -> bool {\n        // TODO: Verify no account changed except those in except list\n        todo!(\"Implement verify_no_changes\")\n    }\n\n    pub fn verify_balance_change(\n        before: &StateSnapshot,\n        after: &StateSnapshot,\n        address: &str,\n        expected_delta: i64,\n    ) -> bool {\n        // TODO: Verify specific account balance changed by expected amount\n        todo!(\"Implement verify_balance_change\")\n    }\n\n    pub fn find_differences(before: &StateSnapshot, after: &StateSnapshot) -> Vec<String> {\n        // TODO: Find all accounts that changed between snapshots\n        todo!(\"Implement find_differences\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct AccountState {\n    pub address: String,\n    pub balance: u64,\n    pub data_hash: String,\n}\n\npub struct StateSnapshot {\n    pub accounts: Vec<AccountState>,\n    pub timestamp: u64,\n}\n\npub struct ConsistencyValidator;\n\nimpl ConsistencyValidator {\n    pub fn capture_snapshot(accounts: &[AccountState], timestamp: u64) -> StateSnapshot {\n        StateSnapshot {\n            accounts: accounts.to_vec(),\n            timestamp,\n        }\n    }\n\n    pub fn verify_no_changes(before: &StateSnapshot, after: &StateSnapshot, except: &[String]) -> bool {\n        let changed = Self::find_differences(before, after);\n        changed.iter().all(|addr| except.contains(addr))\n    }\n\n    pub fn verify_balance_change(\n        before: &StateSnapshot,\n        after: &StateSnapshot,\n        address: &str,\n        expected_delta: i64,\n    ) -> bool {\n        let before_balance = before.accounts.iter().find(|a| a.address == address).map(|a| a.balance);\n        let after_balance = after.accounts.iter().find(|a| a.address == address).map(|a| a.balance);\n\n        match (before_balance, after_balance) {\n            (Some(before), Some(after)) => {\n                let actual_delta = after as i64 - before as i64;\n                actual_delta == expected_delta\n            }\n            _ => false,\n        }\n    }\n\n    pub fn find_differences(before: &StateSnapshot, after: &StateSnapshot) -> Vec<String> {\n        let mut differences = vec![];\n\n        for before_acc in &before.accounts {\n            if let Some(after_acc) = after.accounts.iter().find(|a| a.address == before_acc.address) {\n                if before_acc.balance != after_acc.balance || before_acc.data_hash != after_acc.data_hash {\n                    differences.push(before_acc.address.clone());\n                }\n            } else {\n                differences.push(before_acc.address.clone());\n            }\n        }\n\n        // Check for new accounts\n        for after_acc in &after.accounts {\n            if !before.accounts.iter().any(|a| a.address == after_acc.address) {\n                differences.push(after_acc.address.clone());\n            }\n        }\n\n        differences\n    }\n}",
              "hints": [
                "Clone accounts vector to create independent snapshot",
                "For no_changes, verify all changed accounts are in except list",
                "Compare balance and data_hash to detect changes"
              ],
              "testCases": [
                {
                  "input": {
                    "before": [
                      {
                        "balance": 100
                      }
                    ],
                    "after": [
                      {
                        "balance": 100
                      }
                    ]
                  },
                  "expected": {
                    "changed": []
                  }
                },
                {
                  "input": {
                    "before": [
                      {
                        "addr": "A",
                        "balance": 100
                      }
                    ],
                    "after": [
                      {
                        "addr": "A",
                        "balance": 150
                      }
                    ],
                    "delta": 50
                  },
                  "expected": {
                    "valid": true
                  }
                },
                {
                  "input": {
                    "before": [
                      {
                        "addr": "A",
                        "balance": 100
                      },
                      {
                        "addr": "B",
                        "balance": 200
                      }
                    ],
                    "after": [
                      {
                        "addr": "A",
                        "balance": 150
                      },
                      {
                        "addr": "B",
                        "balance": 200
                      }
                    ]
                  },
                  "expected": {
                    "changed": [
                      "A"
                    ]
                  }
                }
              ]
            },
            {
              "id": "lesson-16-2-4",
              "type": "challenge",
              "title": "Permissioned Invocation Challenge",
              "description": "Implement permission checks for program invocations.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct Permission {\n    pub program_id: String,\n    pub allowed_callers: Vec<String>,\n    pub allowed_instructions: Vec<String>,\n}\n\npub struct PermissionRegistry {\n    pub permissions: Vec<Permission>,\n}\n\nimpl PermissionRegistry {\n    pub fn new() -> Self {\n        Self {\n            permissions: vec![],\n        }\n    }\n\n    pub fn register_permission(&mut self, permission: Permission) {\n        // TODO: Register a permission configuration\n        todo!(\"Implement register_permission\")\n    }\n\n    pub fn can_invoke(&self, program_id: &str, caller: &str, instruction: &str) -> bool {\n        // TODO: Check if caller can invoke instruction on program\n        todo!(\"Implement can_invoke\")\n    }\n\n    pub fn get_allowed_callers(&self, program_id: &str) -> Option<Vec<String>> {\n        // TODO: Return list of allowed callers for a program\n        todo!(\"Implement get_allowed_callers\")\n    }\n\n    pub fn revoke_permission(&mut self, program_id: &str, caller: &str) -> bool {\n        // TODO: Remove caller from allowed list\n        todo!(\"Implement revoke_permission\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct Permission {\n    pub program_id: String,\n    pub allowed_callers: Vec<String>,\n    pub allowed_instructions: Vec<String>,\n}\n\npub struct PermissionRegistry {\n    pub permissions: Vec<Permission>,\n}\n\nimpl PermissionRegistry {\n    pub fn new() -> Self {\n        Self {\n            permissions: vec![],\n        }\n    }\n\n    pub fn register_permission(&mut self, permission: Permission) {\n        self.permissions.push(permission);\n    }\n\n    pub fn can_invoke(&self, program_id: &str, caller: &str, instruction: &str) -> bool {\n        self.permissions\n            .iter()\n            .find(|p| p.program_id == program_id)\n            .map(|p| {\n                p.allowed_callers.contains(&caller.to_string()) &&\n                p.allowed_instructions.contains(&instruction.to_string())\n            })\n            .unwrap_or(false)\n    }\n\n    pub fn get_allowed_callers(&self, program_id: &str) -> Option<Vec<String>> {\n        self.permissions\n            .iter()\n            .find(|p| p.program_id == program_id)\n            .map(|p| p.allowed_callers.clone())\n    }\n\n    pub fn revoke_permission(&mut self, program_id: &str, caller: &str) -> bool {\n        if let Some(permission) = self.permissions.iter_mut().find(|p| p.program_id == program_id) {\n            let before_len = permission.allowed_callers.len();\n            permission.allowed_callers.retain(|c| c != caller);\n            permission.allowed_callers.len() < before_len\n        } else {\n            false\n        }\n    }\n}",
              "hints": [
                "Push permission into vector to register",
                "Use find() to locate permission for program_id",
                "Use retain() to remove caller from allowed list"
              ],
              "testCases": [
                {
                  "input": {
                    "program": "A",
                    "caller": "B",
                    "instruction": "transfer"
                  },
                  "expected": {
                    "can_invoke": true
                  }
                },
                {
                  "input": {
                    "program": "A",
                    "caller": "C",
                    "instruction": "transfer"
                  },
                  "expected": {
                    "can_invoke": false
                  }
                },
                {
                  "input": {
                    "program": "A"
                  },
                  "expected": {
                    "callers": [
                      "B"
                    ]
                  }
                },
                {
                  "input": {
                    "program": "A",
                    "revoke": "B"
                  },
                  "expected": {
                    "revoked": true
                  }
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course-041",
      "slug": "solana-mev-strategies",
      "title": "MEV and Transaction Ordering",
      "description": "Production-focused transaction-ordering engineering on Solana: MEV-aware routing, bundle strategy, liquidation/arbitrage modeling, and user-protective execution controls.",
      "difficulty": "advanced",
      "duration": "6 weeks",
      "totalXP": 2200,
      "tags": [
        "mev",
        "arbitrage",
        "liquidation",
        "jito",
        "priority-fees",
        "sandwich"
      ],
      "imageUrl": "/images/courses/solana-mev.svg",
      "modules": [
        {
          "id": "mod-17-1",
          "title": "MEV Fundamentals",
          "description": "Understand MEV mechanics and transaction ordering realities, then model opportunities and risks with deterministic safety-aware policies.",
          "lessons": [
            {
              "id": "lesson-17-1-1",
              "type": "content",
              "title": "MEV on Solana",
              "content": "Maximal Extractable Value (MEV) on Solana is fundamentally about transaction ordering under limited blockspace. Whether you are building trading tools, liquidation infrastructure, or user-facing apps, you need a realistic model of how ordering pressure changes outcomes.\n\nKey Solana-specific context:\n- ordering can be influenced by priority fees and relay/bundle paths,\n- opportunities are short-lived and highly competitive,\n- failed or delayed execution can convert expected profit into loss.\n\nA mature MEV approach begins with classification:\n1) opportunity class (arbitrage, liquidation, backrun-style sequencing),\n2) dependency class (single-hop vs multi-hop, oracle-sensitive vs pool-state-sensitive),\n3) risk class (staleness, fill failure, adverse movement, execution contention).\n\nFor production systems, raw opportunity detection is not enough. You need deterministic filters that reject fragile setups: stale quotes, weak depth, or excessive path complexity relative to expected edge.\n\nMost operational failures come from execution assumptions, not math. Teams should model inclusion probability, fallback paths, and cancellation thresholds explicitly.\n\nUser-protective design matters even for advanced orderflow systems. Clear policy around slippage limits, quote freshness, and failure reporting prevents silent value leakage and reduces support incidents."
            },
            {
              "id": "lesson-17-1-2",
              "type": "challenge",
              "title": "Arbitrage Opportunity Detector Challenge",
              "description": "Detect arbitrage opportunities across DEXes.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct DEXPrice {\n    pub dex: String,\n    pub token_a: String,\n    pub token_b: String,\n    pub price: f64,  // Price of A in terms of B\n}\n\n#[derive(Debug, Clone)]\npub struct ArbitrageOpportunity {\n    pub buy_dex: String,\n    pub sell_dex: String,\n    pub token_a: String,\n    pub token_b: String,\n    pub profit_percent: f64,\n}\n\npub struct ArbitrageDetector;\n\nimpl ArbitrageDetector {\n    pub fn find_opportunities(prices: &[DEXPrice]) -> Vec<ArbitrageOpportunity> {\n        // TODO: Find all arbitrage opportunities between DEXes\n        // Opportunity exists when buy_price < sell_price for same pair\n        todo!(\"Implement find_opportunities\")\n    }\n\n    pub fn calculate_profit_percent(buy_price: f64, sell_price: f64) -> f64 {\n        // TODO: Calculate profit percentage\n        // profit = (sell - buy) / buy * 100\n        todo!(\"Implement calculate_profit_percent\")\n    }\n\n    pub fn filter_profitable(opportunities: &[ArbitrageOpportunity], min_profit: f64) -> Vec<ArbitrageOpportunity> {\n        // TODO: Filter opportunities above minimum profit threshold\n        todo!(\"Implement filter_profitable\")\n    }\n\n    pub fn best_opportunity(opportunities: &[ArbitrageOpportunity]) -> Option<ArbitrageOpportunity> {\n        // TODO: Return the opportunity with highest profit\n        todo!(\"Implement best_opportunity\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct DEXPrice {\n    pub dex: String,\n    pub token_a: String,\n    pub token_b: String,\n    pub price: f64,\n}\n\n#[derive(Debug, Clone)]\npub struct ArbitrageOpportunity {\n    pub buy_dex: String,\n    pub sell_dex: String,\n    pub token_a: String,\n    pub token_b: String,\n    pub profit_percent: f64,\n}\n\npub struct ArbitrageDetector;\n\nimpl ArbitrageDetector {\n    pub fn find_opportunities(prices: &[DEXPrice]) -> Vec<ArbitrageOpportunity> {\n        let mut opportunities = vec![];\n\n        for i in 0..prices.len() {\n            for j in (i + 1)..prices.len() {\n                let p1 = &prices[i];\n                let p2 = &prices[j];\n\n                // Check if same trading pair\n                if p1.token_a == p2.token_a && p1.token_b == p2.token_b {\n                    // p1 cheaper to buy, p2 more expensive to sell\n                    if p1.price < p2.price {\n                        opportunities.push(ArbitrageOpportunity {\n                            buy_dex: p1.dex.clone(),\n                            sell_dex: p2.dex.clone(),\n                            token_a: p1.token_a.clone(),\n                            token_b: p1.token_b.clone(),\n                            profit_percent: Self::calculate_profit_percent(p1.price, p2.price),\n                        });\n                    } else if p2.price < p1.price {\n                        opportunities.push(ArbitrageOpportunity {\n                            buy_dex: p2.dex.clone(),\n                            sell_dex: p1.dex.clone(),\n                            token_a: p1.token_a.clone(),\n                            token_b: p1.token_b.clone(),\n                            profit_percent: Self::calculate_profit_percent(p2.price, p1.price),\n                        });\n                    }\n                }\n            }\n        }\n\n        opportunities\n    }\n\n    pub fn calculate_profit_percent(buy_price: f64, sell_price: f64) -> f64 {\n        if buy_price == 0.0 {\n            return 0.0;\n        }\n        ((sell_price - buy_price) / buy_price) * 100.0\n    }\n\n    pub fn filter_profitable(opportunities: &[ArbitrageOpportunity], min_profit: f64) -> Vec<ArbitrageOpportunity> {\n        opportunities\n            .iter()\n            .filter(|opp| opp.profit_percent >= min_profit)\n            .cloned()\n            .collect()\n    }\n\n    pub fn best_opportunity(opportunities: &[ArbitrageOpportunity]) -> Option<ArbitrageOpportunity> {\n        opportunities\n            .iter()\n            .max_by(|a, b| a.profit_percent.partial_cmp(&b.profit_percent).unwrap())\n            .cloned()\n    }\n}",
              "hints": [
                "Compare all pairs of DEX prices for same token pair",
                "Profit percent is (sell - buy) / buy * 100",
                "Use max_by to find best opportunity"
              ],
              "testCases": [
                {
                  "input": {
                    "prices": [
                      {
                        "dex": "A",
                        "price": 100
                      },
                      {
                        "dex": "B",
                        "price": 105
                      }
                    ]
                  },
                  "expected": {
                    "opportunities": 1,
                    "profit": 5
                  }
                },
                {
                  "input": {
                    "buy": 100,
                    "sell": 110
                  },
                  "expected": {
                    "profit": 10
                  }
                },
                {
                  "input": {
                    "opportunities": [
                      {
                        "profit": 1
                      },
                      {
                        "profit": 5
                      }
                    ],
                    "min": 3
                  },
                  "expected": {
                    "filtered": 1
                  }
                },
                {
                  "input": {
                    "opportunities": [
                      {
                        "profit": 3
                      },
                      {
                        "profit": 7
                      }
                    ]
                  },
                  "expected": {
                    "best_profit": 7
                  }
                }
              ]
            },
            {
              "id": "lesson-17-1-3",
              "type": "challenge",
              "title": "Liquidation Opportunity Finder Challenge",
              "description": "Find undercollateralized positions for liquidation.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct LendingPosition {\n    pub owner: String,\n    pub collateral_amount: u64,\n    pub borrowed_amount: u64,\n    pub collateral_price: u64,\n    pub liquidation_threshold: u64,  // Basis points\n}\n\n#[derive(Debug, Clone)]\npub struct LiquidationOpportunity {\n    pub owner: String,\n    pub collateral_to_liquidate: u64,\n    pub debt_to_repay: u64,\n    pub profit_estimate: u64,\n}\n\npub struct LiquidationFinder;\n\nimpl LiquidationFinder {\n    pub fn is_liquidatable(position: &LendingPosition) -> bool {\n        // TODO: Check if position is undercollateralized\n        // liquidatable if borrowed > collateral_value * threshold / 10000\n        todo!(\"Implement is_liquidatable\")\n    }\n\n    pub fn calculate_collateral_value(position: &LendingPosition) -> u64 {\n        // TODO: Calculate USD value of collateral\n        todo!(\"Implement calculate_collateral_value\")\n    }\n\n    pub fn find_opportunities(positions: &[LendingPosition]) -> Vec<LiquidationOpportunity> {\n        // TODO: Find all liquidatable positions\n        todo!(\"Implement find_opportunities\")\n    }\n\n    pub fn calculate_liquidation_profit(position: &LendingPosition, bonus_bps: u64) -> u64 {\n        // TODO: Calculate profit from liquidation (bonus on collateral)\n        todo!(\"Implement calculate_liquidation_profit\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct LendingPosition {\n    pub owner: String,\n    pub collateral_amount: u64,\n    pub borrowed_amount: u64,\n    pub collateral_price: u64,\n    pub liquidation_threshold: u64,\n}\n\n#[derive(Debug, Clone)]\npub struct LiquidationOpportunity {\n    pub owner: String,\n    pub collateral_to_liquidate: u64,\n    pub debt_to_repay: u64,\n    pub profit_estimate: u64,\n}\n\npub struct LiquidationFinder;\n\nimpl LiquidationFinder {\n    pub fn is_liquidatable(position: &LendingPosition) -> bool {\n        let collateral_value = Self::calculate_collateral_value(position);\n        let max_safe_borrow = (collateral_value as u128 * position.liquidation_threshold as u128 / 10000) as u64;\n        position.borrowed_amount > max_safe_borrow\n    }\n\n    pub fn calculate_collateral_value(position: &LendingPosition) -> u64 {\n        (position.collateral_amount as u128 * position.collateral_price as u128 / 1_000_000) as u64\n    }\n\n    pub fn find_opportunities(positions: &[LendingPosition]) -> Vec<LiquidationOpportunity> {\n        positions\n            .iter()\n            .filter(|p| Self::is_liquidatable(p))\n            .map(|p| {\n                let bonus_bps = 500; // 5% liquidation bonus\n                LiquidationOpportunity {\n                    owner: p.owner.clone(),\n                    collateral_to_liquidate: p.collateral_amount,\n                    debt_to_repay: p.borrowed_amount,\n                    profit_estimate: Self::calculate_liquidation_profit(p, bonus_bps),\n                }\n            })\n            .collect()\n    }\n\n    pub fn calculate_liquidation_profit(position: &LendingPosition, bonus_bps: u64) -> u64 {\n        let collateral_value = Self::calculate_collateral_value(position);\n        ((collateral_value as u128 * bonus_bps as u128) / 10000) as u64\n    }\n}",
              "hints": [
                "Position is liquidatable when borrowed > threshold * collateral_value",
                "Calculate collateral value using price (with 6 decimals)",
                "Liquidation profit is bonus percentage of collateral value"
              ],
              "testCases": [
                {
                  "input": {
                    "collateral": 1000,
                    "price": 2000000,
                    "borrowed": 1800,
                    "threshold": 7500
                  },
                  "expected": {
                    "liquidatable": true
                  }
                },
                {
                  "input": {
                    "collateral": 1000,
                    "price": 1000000
                  },
                  "expected": {
                    "value": 1000
                  }
                },
                {
                  "input": {
                    "collateral": 1000,
                    "price": 2000000,
                    "bonus": 500
                  },
                  "expected": {
                    "profit": 100
                  }
                }
              ]
            },
            {
              "id": "lesson-17-1-4",
              "type": "challenge",
              "title": "Priority Fee Calculator Challenge",
              "description": "Calculate optimal priority fees for transaction ordering.",
              "starterCode": "pub struct PriorityFeeConfig {\n    pub base_fee: u64,\n    pub multiplier: f64,\n    pub max_fee: u64,\n}\n\npub struct FeeCalculator;\n\nimpl FeeCalculator {\n    pub fn calculate_priority_fee(config: &PriorityFeeConfig, urgency: u8) -> u64 {\n        // TODO: Calculate fee based on urgency (0-100)\n        // fee = base * (1 + multiplier * urgency / 100)\n        todo!(\"Implement calculate_priority_fee\")\n    }\n\n    pub fn estimate_execution_probability(fee: u64, competing_fees: &[u64]) -> f64 {\n        // TODO: Estimate probability of execution based on fee ranking\n        // Higher fee = higher probability\n        todo!(\"Implement estimate_execution_probability\")\n    }\n\n    pub fn optimal_fee_for_target(config: &PriorityFeeConfig, target_probability: f64, competing_fees: &[u64]) -> u64 {\n        // TODO: Calculate minimum fee needed for target execution probability\n        todo!(\"Implement optimal_fee_for_target\")\n    }\n\n    pub fn total_transaction_cost(priority_fee: u64, base_cost: u64, compute_units: u64) -> u64 {\n        // TODO: Calculate total transaction cost\n        // Include priority fee, base cost, and compute unit cost (0.000005 SOL per CU)\n        todo!(\"Implement total_transaction_cost\")\n    }\n}",
              "solution": "pub struct PriorityFeeConfig {\n    pub base_fee: u64,\n    pub multiplier: f64,\n    pub max_fee: u64,\n}\n\npub struct FeeCalculator;\n\nimpl FeeCalculator {\n    pub fn calculate_priority_fee(config: &PriorityFeeConfig, urgency: u8) -> u64 {\n        let urgency_factor = 1.0 + (config.multiplier * urgency as f64 / 100.0);\n        let fee = (config.base_fee as f64 * urgency_factor) as u64;\n        fee.min(config.max_fee)\n    }\n\n    pub fn estimate_execution_probability(fee: u64, competing_fees: &[u64]) -> f64 {\n        if competing_fees.is_empty() {\n            return 1.0;\n        }\n\n        let higher_fees = competing_fees.iter().filter(|&&f| f > fee).count();\n        let rank = higher_fees + 1;\n\n        // Simple model: probability decreases with rank\n        1.0 / (1.0 + (rank as f64 - 1.0) * 0.5)\n    }\n\n    pub fn optimal_fee_for_target(config: &PriorityFeeConfig, target_probability: f64, competing_fees: &[u64]) -> u64 {\n        // Sort competing fees descending\n        let mut sorted = competing_fees.to_vec();\n        sorted.sort_by(|a, b| b.cmp(a));\n\n        // Find fee that puts us at desired rank\n        let target_rank = ((1.0 / target_probability - 1.0) / 0.5 + 1.0) as usize;\n\n        if target_rank == 1 || sorted.is_empty() {\n            return config.base_fee;\n        }\n\n        // Fee slightly higher than the fee at target rank\n        let idx = (target_rank - 1).min(sorted.len() - 1);\n        sorted[idx] + 1000\n    }\n\n    pub fn total_transaction_cost(priority_fee: u64, base_cost: u64, compute_units: u64) -> u64 {\n        let cu_cost = (compute_units as f64 * 0.000005 * 1_000_000_0) as u64; // Convert to micro-lamports\n        priority_fee + base_cost + cu_cost\n    }\n}",
              "hints": [
                "Urgency factor scales the base fee",
                "Execution probability decreases as more fees are higher",
                "Total cost includes priority fee, base, and compute unit cost"
              ],
              "testCases": [
                {
                  "input": {
                    "base": 10000,
                    "multiplier": 2,
                    "urgency": 50,
                    "max": 50000
                  },
                  "expected": {
                    "fee": 20000
                  }
                },
                {
                  "input": {
                    "fee": 5000,
                    "competing": [
                      10000,
                      8000,
                      3000
                    ]
                  },
                  "expected": {
                    "probability": 0.5
                  }
                },
                {
                  "input": {
                    "priority": 10000,
                    "base": 5000,
                    "cu": 200000
                  },
                  "expected": {
                    "total": 25000
                  }
                }
              ]
            }
          ]
        },
        {
          "id": "mod-17-2",
          "title": "Advanced MEV Strategies",
          "description": "Design advanced ordering/bundle strategies with explicit risk controls, failure handling, and user-impact guardrails.",
          "lessons": [
            {
              "id": "lesson-17-2-1",
              "type": "content",
              "title": "Advanced MEV Techniques",
              "content": "Advanced transaction-ordering strategies require disciplined orchestration, not just faster opportunity scans.\n\nBundle-oriented execution is valuable because it can express dependency sets and all-or-nothing intent, but bundle design must include:\n- strict preconditions,\n- deterministic abort rules,\n- replay-safe identifiers,\n- post-execution reconciliation.\n\nWhen strategy complexity increases (multi-hop paths, conditional liquidations), failure modes multiply: partial fills, stale assumptions, and contention spikes. A robust system ranks candidates by expected net value after execution risk, not gross theoretical edge.\n\nOperational controls should include:\n1) bounded retries with fresh-state checks,\n2) confidence scoring for each candidate,\n3) kill-switch thresholds for abnormal failure streaks,\n4) deterministic run reports for incident replay.\n\nAdvanced MEV tooling is successful when it is both profitable and controllable. Deterministic artifacts (decision inputs, chosen path, reason codes) are what make that control real in production."
            },
            {
              "id": "lesson-17-2-2",
              "type": "challenge",
              "title": "Bundle Composer Challenge",
              "description": "Compose transaction bundles for atomic MEV extraction.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct Transaction {\n    pub id: String,\n    pub program_id: String,\n    pub estimated_profit: i64,\n    pub priority_fee: u64,\n}\n\n#[derive(Debug, Clone)]\npub struct Bundle {\n    pub transactions: Vec<Transaction>,\n    pub total_tip: u64,\n}\n\npub struct BundleComposer;\n\nimpl BundleComposer {\n    pub fn create_bundle(transactions: Vec<Transaction>, tip_percent: f64) -> Bundle {\n        // TODO: Create bundle with tip calculated from profit\n        todo!(\"Implement create_bundle\")\n    }\n\n    pub fn calculate_total_profit(bundle: &Bundle) -> i64 {\n        // TODO: Sum all transaction profits\n        todo!(\"Implement calculate_total_profit\")\n    }\n\n    pub fn is_profitable(bundle: &Bundle) -> bool {\n        // TODO: Check if bundle is profitable after tips\n        todo!(\"Implement is_profitable\")\n    }\n\n    pub fn optimize_order(bundle: &mut Bundle) {\n        // TODO: Sort transactions by priority fee (highest first)\n        todo!(\"Implement optimize_order\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct Transaction {\n    pub id: String,\n    pub program_id: String,\n    pub estimated_profit: i64,\n    pub priority_fee: u64,\n}\n\n#[derive(Debug, Clone)]\npub struct Bundle {\n    pub transactions: Vec<Transaction>,\n    pub total_tip: u64,\n}\n\npub struct BundleComposer;\n\nimpl BundleComposer {\n    pub fn create_bundle(transactions: Vec<Transaction>, tip_percent: f64) -> Bundle {\n        let total_profit: i64 = transactions.iter().map(|t| t.estimated_profit).sum();\n        let tip = ((total_profit.max(0) as f64) * tip_percent / 100.0) as u64;\n\n        Bundle {\n            transactions,\n            total_tip: tip,\n        }\n    }\n\n    pub fn calculate_total_profit(bundle: &Bundle) -> i64 {\n        bundle.transactions.iter().map(|t| t.estimated_profit).sum()\n    }\n\n    pub fn is_profitable(bundle: &Bundle) -> bool {\n        let total_profit = Self::calculate_total_profit(bundle);\n        total_profit > bundle.total_tip as i64\n    }\n\n    pub fn optimize_order(bundle: &mut Bundle) {\n        bundle.transactions.sort_by(|a, b| b.priority_fee.cmp(&a.priority_fee));\n    }\n}",
              "hints": [
                "Tip is percentage of total profit",
                "Bundle is profitable if profit exceeds tip",
                "Sort by priority fee descending for optimal ordering"
              ],
              "testCases": [
                {
                  "input": {
                    "txs": [
                      {
                        "profit": 1000
                      },
                      {
                        "profit": 2000
                      }
                    ],
                    "tip": 10
                  },
                  "expected": {
                    "tip": 300
                  }
                },
                {
                  "input": {
                    "txs": [
                      {
                        "profit": 1000
                      },
                      {
                        "profit": 2000
                      }
                    ]
                  },
                  "expected": {
                    "total_profit": 3000
                  }
                },
                {
                  "input": {
                    "txs": [
                      {
                        "fee": 500
                      },
                      {
                        "fee": 100
                      }
                    ]
                  },
                  "expected_after_sort": [
                    {
                      "fee": 500
                    },
                    {
                      "fee": 100
                    }
                  ]
                }
              ]
            },
            {
              "id": "lesson-17-2-3",
              "type": "challenge",
              "title": "Multi-Hop Arbitrage Finder Challenge",
              "description": "Find multi-hop arbitrage paths across token pairs.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct Pool {\n    pub token_a: String,\n    pub token_b: String,\n    pub reserve_a: u64,\n    pub reserve_b: u64,\n    pub fee_bps: u64,\n}\n\n#[derive(Debug, Clone)]\npub struct ArbitragePath {\n    pub hops: Vec<String>,  // Token sequence\n    pub expected_output: u64,\n    pub profit: i64,\n}\n\npub struct MultiHopArbitrage;\n\nimpl MultiHopArbitrage {\n    pub fn calculate_output(pool: &Pool, input_amount: u64, a_to_b: bool) -> u64 {\n        // TODO: Calculate output amount through pool\n        // Constant product formula with fee\n        todo!(\"Implement calculate_output\")\n    }\n\n    pub fn find_two_hop_arbitrage(pools: &[Pool], start_token: &str, amount: u64) -> Vec<ArbitragePath> {\n        // TODO: Find A -> B -> A arbitrage opportunities\n        todo!(\"Implement find_two_hop_arbitrage\")\n    }\n\n    pub fn is_profitable_path(path: &ArbitragePath, min_profit: i64) -> bool {\n        // TODO: Check if path meets minimum profit threshold\n        todo!(\"Implement is_profitable_path\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct Pool {\n    pub token_a: String,\n    pub token_b: String,\n    pub reserve_a: u64,\n    pub reserve_b: u64,\n    pub fee_bps: u64,\n}\n\n#[derive(Debug, Clone)]\npub struct ArbitragePath {\n    pub hops: Vec<String>,\n    pub expected_output: u64,\n    pub profit: i64,\n}\n\npub struct MultiHopArbitrage;\n\nimpl MultiHopArbitrage {\n    pub fn calculate_output(pool: &Pool, input_amount: u64, a_to_b: bool) -> u64 {\n        let fee_multiplier = 10000 - pool.fee_bps;\n        let input_with_fee = (input_amount as u128 * fee_multiplier as u128) / 10000;\n\n        let (input_reserve, output_reserve) = if a_to_b {\n            (pool.reserve_a as u128, pool.reserve_b as u128)\n        } else {\n            (pool.reserve_b as u128, pool.reserve_a as u128)\n        };\n\n        let numerator = output_reserve * input_with_fee;\n        let denominator = input_reserve + input_with_fee;\n\n        (numerator / denominator) as u64\n    }\n\n    pub fn find_two_hop_arbitrage(pools: &[Pool], start_token: &str, amount: u64) -> Vec<ArbitragePath> {\n        let mut paths = vec![];\n\n        // Find all A -> B pools\n        for pool1 in pools.iter().filter(|p| p.token_a == start_token || p.token_b == start_token) {\n            let intermediate = if pool1.token_a == start_token { &pool1.token_b } else { &pool1.token_a };\n            let a_to_b_first = pool1.token_a == start_token;\n\n            let first_output = Self::calculate_output(pool1, amount, a_to_b_first);\n\n            // Find B -> A pools\n            for pool2 in pools.iter().filter(|p| {\n                (p.token_a == *intermediate && p.token_b == start_token) ||\n                (p.token_b == *intermediate && p.token_a == start_token)\n            }) {\n                let a_to_b_second = pool2.token_a == *intermediate;\n                let final_output = Self::calculate_output(pool2, first_output, a_to_b_second);\n\n                let profit = final_output as i64 - amount as i64;\n\n                paths.push(ArbitragePath {\n                    hops: vec![start_token.to_string(), intermediate.to_string(), start_token.to_string()],\n                    expected_output: final_output,\n                    profit,\n                });\n            }\n        }\n\n        paths\n    }\n\n    pub fn is_profitable_path(path: &ArbitragePath, min_profit: i64) -> bool {\n        path.profit >= min_profit\n    }\n}",
              "hints": [
                "Use constant product formula with fee for output calculation",
                "Two-hop arbitrage goes A -> B -> A through different pools",
                "Profit is final output minus initial input"
              ],
              "testCases": [
                {
                  "input": {
                    "reserve_a": 10000,
                    "reserve_b": 20000,
                    "input": 100,
                    "fee": 30
                  },
                  "expected": {
                    "output": 197
                  }
                },
                {
                  "input": {
                    "pools": [
                      {
                        "a": "SOL",
                        "b": "USDC"
                      },
                      {
                        "a": "USDC",
                        "b": "SOL"
                      }
                    ],
                    "start": "SOL",
                    "amount": 1000
                  },
                  "expected": {
                    "paths": 1
                  }
                },
                {
                  "input": {
                    "path": {
                      "profit": 500
                    },
                    "min": 300
                  },
                  "expected": {
                    "profitable": true
                  }
                }
              ]
            },
            {
              "id": "lesson-17-2-4",
              "type": "challenge",
              "title": "MEV Simulation Engine Challenge",
              "description": "Simulate MEV extraction to estimate profitability.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct SimulationConfig {\n    pub slippage_tolerance: f64,\n    pub gas_cost_per_tx: u64,\n    pub failure_rate: f64,\n}\n\n#[derive(Debug, Clone)]\npub struct SimulationResult {\n    pub expected_profit: i64,\n    pub success_probability: f64,\n    pub risk_score: u8,  // 0-100\n}\n\npub struct MEVSimulator;\n\nimpl MEVSimulator {\n    pub fn simulate_arbitrage(\n        buy_price: f64,\n        sell_price: f64,\n        amount: u64,\n        config: &SimulationConfig,\n    ) -> SimulationResult {\n        // TODO: Simulate arbitrage with slippage and gas costs\n        todo!(\"Implement simulate_arbitrage\")\n    }\n\n    pub fn calculate_risk_score(profit: i64, success_prob: f64, capital_at_risk: u64) -> u8 {\n        // TODO: Calculate risk score (0-100, higher = riskier)\n        todo!(\"Implement calculate_risk_score\")\n    }\n\n    pub fn expected_value(profit: i64, success_prob: f64, loss_on_failure: u64) -> i64 {\n        // TODO: Calculate expected value considering success and failure\n        // EV = success_prob * profit - (1 - success_prob) * loss\n        todo!(\"Implement expected_value\")\n    }\n\n    pub fn should_execute(result: &SimulationResult, min_ev: i64) -> bool {\n        // TODO: Determine if MEV opportunity should be executed\n        todo!(\"Implement should_execute\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct SimulationConfig {\n    pub slippage_tolerance: f64,\n    pub gas_cost_per_tx: u64,\n    pub failure_rate: f64,\n}\n\n#[derive(Debug, Clone)]\npub struct SimulationResult {\n    pub expected_profit: i64,\n    pub success_probability: f64,\n    pub risk_score: u8,\n}\n\npub struct MEVSimulator;\n\nimpl MEVSimulator {\n    pub fn simulate_arbitrage(\n        buy_price: f64,\n        sell_price: f64,\n        amount: u64,\n        config: &SimulationConfig,\n    ) -> SimulationResult {\n        // Apply slippage to prices\n        let effective_buy = buy_price * (1.0 + config.slippage_tolerance);\n        let effective_sell = sell_price * (1.0 - config.slippage_tolerance);\n\n        // Calculate gross profit\n        let gross_profit = (effective_sell - effective_buy) * amount as f64;\n\n        // Subtract gas costs\n        let net_profit = gross_profit as i64 - config.gas_cost_per_tx as i64 * 2; // Buy + Sell\n\n        // Success probability decreases with failure rate\n        let success_prob = 1.0 - config.failure_rate;\n\n        // Risk score based on failure rate and profit volatility\n        let risk_score = (config.failure_rate * 100.0) as u8 + \n            if net_profit < 0 { 50 } else { 0 };\n\n        SimulationResult {\n            expected_profit: net_profit,\n            success_probability: success_prob,\n            risk_score: risk_score.min(100),\n        }\n    }\n\n    pub fn calculate_risk_score(profit: i64, success_prob: f64, capital_at_risk: u64) -> u8 {\n        let profit_risk = if profit < 0 { 50 } else { 0 };\n        let prob_risk = ((1.0 - success_prob) * 50.0) as u8;\n        let capital_risk = (capital_at_risk / 1_000_000).min(50) as u8;\n\n        (profit_risk + prob_risk + capital_risk).min(100)\n    }\n\n    pub fn expected_value(profit: i64, success_prob: f64, loss_on_failure: u64) -> i64 {\n        let success_contribution = success_prob * profit as f64;\n        let failure_contribution = (1.0 - success_prob) * -(loss_on_failure as f64);\n        (success_contribution + failure_contribution) as i64\n    }\n\n    pub fn should_execute(result: &SimulationResult, min_ev: i64) -> bool {\n        let ev = Self::expected_value(\n            result.expected_profit,\n            result.success_probability,\n            result.expected_profit.abs() as u64,\n        );\n        ev >= min_ev && result.risk_score < 80\n    }\n}",
              "hints": [
                "Apply slippage to both buy (increase) and sell (decrease) prices",
                "Risk score combines failure rate, profit negativity, and capital",
                "Expected value weights profit by success probability"
              ],
              "testCases": [
                {
                  "input": {
                    "buy": 100,
                    "sell": 105,
                    "amount": 1000,
                    "slippage": 0.01,
                    "gas": 5000
                  },
                  "expected": {
                    "profit_positive": true
                  }
                },
                {
                  "input": {
                    "profit": 1000,
                    "prob": 0.8,
                    "loss": 500
                  },
                  "expected": {
                    "ev": 700
                  }
                },
                {
                  "input": {
                    "result": {
                      "profit": 1000,
                      "prob": 0.9,
                      "risk": 30
                    },
                    "min_ev": 500
                  },
                  "expected": {
                    "execute": true
                  }
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course-042",
      "slug": "solana-deployment-cicd",
      "title": "Program Deployment and CI/CD",
      "description": "Production deployment engineering for Solana programs: environment strategy, release gating, CI/CD quality controls, and upgrade-safe operational workflows.",
      "difficulty": "beginner",
      "duration": "4 weeks",
      "totalXP": 1500,
      "tags": [
        "deployment",
        "cicd",
        "devnet",
        "mainnet",
        "upgrades",
        "testing"
      ],
      "imageUrl": "/images/courses/solana-deployment.svg",
      "modules": [
        {
          "id": "mod-18-1",
          "title": "Deployment Fundamentals",
          "description": "Model environment-specific deployment behavior with deterministic configs, artifact checks, and release preflight validation.",
          "lessons": [
            {
              "id": "lesson-18-1-1",
              "type": "content",
              "title": "Solana Deployment Environments",
              "content": "Solana deployment is not one command; it is a release system with environment-specific risk. Localnet, devnet, and mainnet each serve different validation goals, and production quality depends on using them intentionally.\n\nA reliable deployment workflow defines:\n1) environment purpose and promotion criteria,\n2) deterministic config sources,\n3) artifact identity checks,\n4) rollback triggers.\n\nCommon failure patterns include mismatched program IDs, inconsistent config between environments, and unverified artifact drift between build and deploy. These are process issues that tooling should prevent.\n\nPreflight checks should be mandatory:\n- expected network and signer identity,\n- build artifact hash,\n- program size and upgrade constraints,\n- required account/address assumptions.\n\nEnvironment promotion should be evidence-driven. Passing local tests alone is not enough for mainnet readiness; devnet/staging behavior must confirm operational assumptions under realistic RPC and timing conditions.\n\nDeployment maturity is measured by reproducibility. If another engineer cannot replay the release inputs and get the same artifact and checklist outcome, the pipeline is too fragile."
            },
            {
              "id": "lesson-18-1-2",
              "type": "challenge",
              "title": "Deployment Config Manager Challenge",
              "description": "Manage deployment configurations for different environments.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct DeploymentConfig {\n    pub environment: String,\n    pub rpc_url: String,\n    pub commitment: String,\n    pub program_id: Option<String>,\n}\n\npub struct ConfigManager {\n    configs: Vec<DeploymentConfig>,\n}\n\nimpl ConfigManager {\n    pub fn new() -> Self {\n        Self { configs: vec![] }\n    }\n\n    pub fn add_config(&mut self, config: DeploymentConfig) {\n        // TODO: Add a deployment configuration\n        todo!(\"Implement add_config\")\n    }\n\n    pub fn get_config(&self, environment: &str) -> Option<&DeploymentConfig> {\n        // TODO: Get configuration for specific environment\n        todo!(\"Implement get_config\")\n    }\n\n    pub fn is_deployed(&self, environment: &str) -> bool {\n        // TODO: Check if program is deployed to environment\n        todo!(\"Implement is_deployed\")\n    }\n\n    pub fn get_all_environments(&self) -> Vec<String> {\n        // TODO: Return list of all configured environments\n        todo!(\"Implement get_all_environments\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct DeploymentConfig {\n    pub environment: String,\n    pub rpc_url: String,\n    pub commitment: String,\n    pub program_id: Option<String>,\n}\n\npub struct ConfigManager {\n    configs: Vec<DeploymentConfig>,\n}\n\nimpl ConfigManager {\n    pub fn new() -> Self {\n        Self { configs: vec![] }\n    }\n\n    pub fn add_config(&mut self, config: DeploymentConfig) {\n        self.configs.push(config);\n    }\n\n    pub fn get_config(&self, environment: &str) -> Option<&DeploymentConfig> {\n        self.configs.iter().find(|c| c.environment == environment)\n    }\n\n    pub fn is_deployed(&self, environment: &str) -> bool {\n        self.get_config(environment)\n            .map(|c| c.program_id.is_some())\n            .unwrap_or(false)\n    }\n\n    pub fn get_all_environments(&self) -> Vec<String> {\n        self.configs.iter().map(|c| c.environment.clone()).collect()\n    }\n}",
              "hints": [
                "Push config into vector to add",
                "Use find() to locate config by environment name",
                "is_deployed checks if program_id is Some"
              ],
              "testCases": [
                {
                  "input": {
                    "add": {
                      "environment": "devnet",
                      "program_id": "abc"
                    }
                  },
                  "expected": {
                    "count": 1
                  }
                },
                {
                  "input": {
                    "get": "devnet"
                  },
                  "expected": {
                    "found": true
                  }
                },
                {
                  "input": {
                    "check": "devnet"
                  },
                  "expected": {
                    "deployed": true
                  }
                },
                {
                  "input": {
                    "check": "mainnet"
                  },
                  "expected": {
                    "deployed": false
                  }
                }
              ]
            },
            {
              "id": "lesson-18-1-3",
              "type": "challenge",
              "title": "Program Size Validator Challenge",
              "description": "Validate program binary size and compute budget.",
              "starterCode": "pub struct ProgramBinary {\n    pub data: Vec<u8>,\n    pub name: String,\n}\n\npub struct SizeValidator;\n\nimpl SizeValidator {\n    pub const MAX_PROGRAM_SIZE: usize = 10 * 1024 * 1024;\n    pub const MAX_PER_TRANSACTION: usize = 1232;\n\n    pub fn validate_size(binary: &ProgramBinary) -> Result<(), String> {\n        // TODO: Check if program size is within limits\n        todo!(\"Implement validate_size\")\n    }\n\n    pub fn calculate_transactions_needed(binary: &ProgramBinary) -> u32 {\n        // TODO: Calculate number of transactions needed for deployment\n        todo!(\"Implement calculate_transactions_needed\")\n    }\n\n    pub fn estimate_deployment_cost(binary: &ProgramBinary, lamports_per_byte: u64) -> u64 {\n        // TODO: Estimate deployment cost in lamports\n        todo!(\"Implement estimate_deployment_cost\")\n    }\n\n    pub fn compression_ratio(original: usize, compressed: usize) -> f64 {\n        // TODO: Calculate compression ratio\n        todo!(\"Implement compression_ratio\")\n    }\n}",
              "solution": "pub struct ProgramBinary {\n    pub data: Vec<u8>,\n    pub name: String,\n}\n\npub struct SizeValidator;\n\nimpl SizeValidator {\n    pub const MAX_PROGRAM_SIZE: usize = 10 * 1024 * 1024;\n    pub const MAX_PER_TRANSACTION: usize = 1232;\n\n    pub fn validate_size(binary: &ProgramBinary) -> Result<(), String> {\n        if binary.data.len() > Self::MAX_PROGRAM_SIZE {\n            Err(format!(\"Program size {} exceeds maximum {}\", binary.data.len(), Self::MAX_PROGRAM_SIZE))\n        } else {\n            Ok(())\n        }\n    }\n\n    pub fn calculate_transactions_needed(binary: &ProgramBinary) -> u32 {\n        let chunks = (binary.data.len() + Self::MAX_PER_TRANSACTION - 1) / Self::MAX_PER_TRANSACTION;\n        chunks as u32\n    }\n\n    pub fn estimate_deployment_cost(binary: &ProgramBinary, lamports_per_byte: u64) -> u64 {\n        (binary.data.len() as u64 * lamports_per_byte) + \n        (Self::calculate_transactions_needed(binary) as u64 * 5000)\n    }\n\n    pub fn compression_ratio(original: usize, compressed: usize) -> f64 {\n        if original == 0 {\n            return 0.0;\n        }\n        (1.0 - (compressed as f64 / original as f64)) * 100.0\n    }\n}",
              "hints": [
                "Compare binary length against MAX_PROGRAM_SIZE",
                "Use ceiling division for transaction count",
                "Compression ratio shows percentage size reduction"
              ],
              "testCases": [
                {
                  "input": {
                    "size": 5000000
                  },
                  "expected": {
                    "valid": true
                  }
                },
                {
                  "input": {
                    "size": 11000000
                  },
                  "expected": {
                    "valid": false
                  }
                },
                {
                  "input": {
                    "size": 2464
                  },
                  "expected": {
                    "transactions": 2
                  }
                },
                {
                  "input": {
                    "original": 1000,
                    "compressed": 600
                  },
                  "expected": {
                    "ratio": 40
                  }
                }
              ]
            },
            {
              "id": "lesson-18-1-4",
              "type": "challenge",
              "title": "Upgrade Authority Manager Challenge",
              "description": "Manage program upgrade authorities and permissions.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct ProgramMetadata {\n    pub program_id: String,\n    pub upgrade_authority: String,\n    pub last_upgrade: u64,\n    pub version: String,\n}\n\npub struct UpgradeManager {\n    programs: Vec<ProgramMetadata>,\n}\n\nimpl UpgradeManager {\n    pub fn new() -> Self {\n        Self { programs: vec![] }\n    }\n\n    pub fn register_program(&mut self, metadata: ProgramMetadata) {\n        // TODO: Register a program with its metadata\n        todo!(\"Implement register_program\")\n    }\n\n    pub fn can_upgrade(&self, program_id: &str, authority: &str) -> bool {\n        // TODO: Check if authority can upgrade the program\n        todo!(\"Implement can_upgrade\")\n    }\n\n    pub fn transfer_authority(&mut self, program_id: &str, new_authority: &str) -> Result<(), String> {\n        // TODO: Transfer upgrade authority to new address\n        todo!(\"Implement transfer_authority\")\n    }\n\n    pub fn get_upgrade_history(&self, program_id: &str) -> Option<u64> {\n        // TODO: Get last upgrade timestamp for program\n        todo!(\"Implement get_upgrade_history\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct ProgramMetadata {\n    pub program_id: String,\n    pub upgrade_authority: String,\n    pub last_upgrade: u64,\n    pub version: String,\n}\n\npub struct UpgradeManager {\n    programs: Vec<ProgramMetadata>,\n}\n\nimpl UpgradeManager {\n    pub fn new() -> Self {\n        Self { programs: vec![] }\n    }\n\n    pub fn register_program(&mut self, metadata: ProgramMetadata) {\n        self.programs.push(metadata);\n    }\n\n    pub fn can_upgrade(&self, program_id: &str, authority: &str) -> bool {\n        self.programs\n            .iter()\n            .find(|p| p.program_id == program_id)\n            .map(|p| p.upgrade_authority == authority)\n            .unwrap_or(false)\n    }\n\n    pub fn transfer_authority(&mut self, program_id: &str, new_authority: &str) -> Result<(), String> {\n        if let Some(program) = self.programs.iter_mut().find(|p| p.program_id == program_id) {\n            program.upgrade_authority = new_authority.to_string();\n            Ok(())\n        } else {\n            Err(\"Program not found\".to_string())\n        }\n    }\n\n    pub fn get_upgrade_history(&self, program_id: &str) -> Option<u64> {\n        self.programs\n            .iter()\n            .find(|p| p.program_id == program_id)\n            .map(|p| p.last_upgrade)\n    }\n}",
              "hints": [
                "Push metadata into vector to register",
                "can_upgrade checks if authority matches stored authority",
                "Use find_mut to locate and modify program metadata"
              ],
              "testCases": [
                {
                  "input": {
                    "register": {
                      "program_id": "prog1",
                      "authority": "auth1"
                    }
                  },
                  "expected": {
                    "count": 1
                  }
                },
                {
                  "input": {
                    "program": "prog1",
                    "authority": "auth1"
                  },
                  "expected": {
                    "can_upgrade": true
                  }
                },
                {
                  "input": {
                    "program": "prog1",
                    "authority": "auth2"
                  },
                  "expected": {
                    "can_upgrade": false
                  }
                },
                {
                  "input": {
                    "transfer": "prog1",
                    "new": "auth2"
                  },
                  "expected": {
                    "success": true
                  }
                }
              ]
            }
          ]
        },
        {
          "id": "mod-18-2",
          "title": "CI/CD Pipelines",
          "description": "Build CI/CD pipelines that enforce build/test/security gates, compatibility checks, and controlled rollout/rollback evidence.",
          "lessons": [
            {
              "id": "lesson-18-2-1",
              "type": "content",
              "title": "CI/CD for Solana Programs",
              "content": "CI/CD for Solana should enforce release quality, not just automate command execution.\n\nA practical pipeline includes staged gates:\n1) static quality gate (lint/type/security checks),\n2) deterministic unit/integration tests,\n3) build reproducibility and artifact hashing,\n4) deployment preflight validation,\n5) controlled rollout with observability checks.\n\nEach gate should produce machine-readable evidence. Release decisions become faster and safer when teams can inspect deterministic artifacts instead of scanning raw logs.\n\nVersion compatibility checks are critical in Solana ecosystems where CLI/toolchain mismatches can break builds or runtime expectations. Pipelines should fail fast on incompatible matrices.\n\nRollout strategy should also be explicit: canary/degraded mode, monitoring window, and rollback conditions. Deploy and hope is not a strategy.\n\nThe best CI/CD systems reduce human toil while increasing decision clarity. Automation should encode operational policy, not bypass it."
            },
            {
              "id": "lesson-18-2-2",
              "type": "challenge",
              "title": "Build Pipeline Validator Challenge",
              "description": "Validate CI/CD pipeline stages and dependencies.",
              "starterCode": "#[derive(Debug, Clone)]\npub enum PipelineStage {\n    Build,\n    Test,\n    Lint,\n    Security,\n    Deploy,\n}\n\npub struct PipelineConfig {\n    pub stages: Vec<PipelineStage>,\n    pub required_passes: usize,\n}\n\npub struct PipelineValidator;\n\nimpl PipelineValidator {\n    pub fn validate_order(stages: &[PipelineStage]) -> bool {\n        // TODO: Validate stage order (Build before Test, Test before Deploy)\n        todo!(\"Implement validate_order\")\n    }\n\n    pub fn has_required_stages(config: &PipelineConfig) -> bool {\n        // TODO: Check if pipeline has minimum required stages\n        todo!(\"Implement has_required_stages\")\n    }\n\n    pub fn calculate_pipeline_duration(stages: &[PipelineStage], avg_time_per_stage: u64) -> u64 {\n        // TODO: Calculate total pipeline duration\n        todo!(\"Implement calculate_pipeline_duration\")\n    }\n\n    pub fn can_skip_stage(stage: &PipelineStage, changed_files: &[String]) -> bool {\n        // TODO: Determine if stage can be skipped based on changed files\n        todo!(\"Implement can_skip_stage\")\n    }\n}",
              "solution": "#[derive(Debug, Clone, PartialEq)]\npub enum PipelineStage {\n    Build,\n    Test,\n    Lint,\n    Security,\n    Deploy,\n}\n\npub struct PipelineConfig {\n    pub stages: Vec<PipelineStage>,\n    pub required_passes: usize,\n}\n\npub struct PipelineValidator;\n\nimpl PipelineValidator {\n    pub fn validate_order(stages: &[PipelineStage]) -> bool {\n        let mut build_seen = false;\n        let mut test_seen = false;\n\n        for stage in stages {\n            match stage {\n                PipelineStage::Build => build_seen = true,\n                PipelineStage::Test => {\n                    if !build_seen { return false; }\n                    test_seen = true;\n                }\n                PipelineStage::Deploy => {\n                    if !test_seen { return false; }\n                }\n                _ => {}\n            }\n        }\n        true\n    }\n\n    pub fn has_required_stages(config: &PipelineConfig) -> bool {\n        let has_build = config.stages.iter().any(|s| matches!(s, PipelineStage::Build));\n        let has_test = config.stages.iter().any(|s| matches!(s, PipelineStage::Test));\n        has_build && has_test\n    }\n\n    pub fn calculate_pipeline_duration(stages: &[PipelineStage], avg_time_per_stage: u64) -> u64 {\n        stages.len() as u64 * avg_time_per_stage\n    }\n\n    pub fn can_skip_stage(stage: &PipelineStage, changed_files: &[String]) -> bool {\n        let only_docs = changed_files.iter().all(|f| f.ends_with(\".md\") || f.contains(\"README\"));\n        match stage {\n            PipelineStage::Build | PipelineStage::Test if only_docs => true,\n            _ => false,\n        }\n    }\n}",
              "hints": [
                "Track seen stages to enforce ordering constraints",
                "Use any() with matches! to check for required stages",
                "Can skip build/test if only documentation files changed"
              ],
              "testCases": [
                {
                  "input": {
                    "stages": [
                      "Build",
                      "Test",
                      "Deploy"
                    ]
                  },
                  "expected": {
                    "valid_order": true
                  }
                },
                {
                  "input": {
                    "stages": [
                      "Test",
                      "Build"
                    ]
                  },
                  "expected": {
                    "valid_order": false
                  }
                },
                {
                  "input": {
                    "stages": [
                      "Build",
                      "Test"
                    ],
                    "time": 60
                  },
                  "expected": {
                    "duration": 120
                  }
                },
                {
                  "input": {
                    "stage": "Build",
                    "files": [
                      "README.md"
                    ]
                  },
                  "expected": {
                    "can_skip": true
                  }
                }
              ]
            },
            {
              "id": "lesson-18-2-3",
              "type": "challenge",
              "title": "Version Compatibility Checker Challenge",
              "description": "Check version compatibility between tools and dependencies.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct Version {\n    pub major: u32,\n    pub minor: u32,\n    pub patch: u32,\n}\n\npub struct CompatibilityChecker;\n\nimpl CompatibilityChecker {\n    pub fn parse_version(version_str: &str) -> Result<Version, String> {\n        // TODO: Parse version string (e.g., \"1.2.3\")\n        todo!(\"Implement parse_version\")\n    }\n\n    pub fn is_compatible(required: &Version, actual: &Version) -> bool {\n        // TODO: Check if actual version meets requirements\n        todo!(\"Implement is_compatible\")\n    }\n\n    pub fn compare_versions(v1: &Version, v2: &Version) -> i8 {\n        // TODO: Compare versions (-1 if v1 < v2, 0 if equal, 1 if v1 > v2)\n        todo!(\"Implement compare_versions\")\n    }\n\n    pub fn find_minimum_compatible(versions: &[Version], required: &Version) -> Option<Version> {\n        // TODO: Find minimum version that meets requirements\n        todo!(\"Implement find_minimum_compatible\")\n    }\n}",
              "solution": "#[derive(Debug, Clone, PartialEq)]\npub struct Version {\n    pub major: u32,\n    pub minor: u32,\n    pub patch: u32,\n}\n\npub struct CompatibilityChecker;\n\nimpl CompatibilityChecker {\n    pub fn parse_version(version_str: &str) -> Result<Version, String> {\n        let parts: Vec<&str> = version_str.split('.').collect();\n        if parts.len() != 3 {\n            return Err(\"Version must be in format X.Y.Z\".to_string());\n        }\n        Ok(Version {\n            major: parts[0].parse().map_err(|_| \"Invalid major\")?,\n            minor: parts[1].parse().map_err(|_| \"Invalid minor\")?,\n            patch: parts[2].parse().map_err(|_| \"Invalid patch\")?,\n        })\n    }\n\n    pub fn is_compatible(required: &Version, actual: &Version) -> bool {\n        if actual.major != required.major { return false; }\n        if actual.minor < required.minor { return false; }\n        if actual.minor == required.minor && actual.patch < required.patch { return false; }\n        true\n    }\n\n    pub fn compare_versions(v1: &Version, v2: &Version) -> i8 {\n        if v1.major != v2.major { return if v1.major > v2.major { 1 } else { -1 }; }\n        if v1.minor != v2.minor { return if v1.minor > v2.minor { 1 } else { -1 }; }\n        if v1.patch != v2.patch { return if v1.patch > v2.patch { 1 } else { -1 }; }\n        0\n    }\n\n    pub fn find_minimum_compatible(versions: &[Version], required: &Version) -> Option<Version> {\n        versions.iter().filter(|v| Self::is_compatible(required, v)).min_by(|a, b| {\n            Self::compare_versions(a, b).cmp(&0)\n        }).cloned()\n    }\n}",
              "hints": [
                "Split version string by '.' and parse each component",
                "Compatibility requires same major, actual >= required",
                "Use min_by to find smallest compatible version"
              ],
              "testCases": [
                {
                  "input": {
                    "version": "1.2.3"
                  },
                  "expected": {
                    "major": 1,
                    "minor": 2,
                    "patch": 3
                  }
                },
                {
                  "input": {
                    "required": "1.2.0",
                    "actual": "1.3.0"
                  },
                  "expected": {
                    "compatible": true
                  }
                },
                {
                  "input": {
                    "required": "1.2.0",
                    "actual": "2.0.0"
                  },
                  "expected": {
                    "compatible": false
                  }
                },
                {
                  "input": {
                    "v1": "1.2.0",
                    "v2": "1.3.0"
                  },
                  "expected": {
                    "comparison": -1
                  }
                }
              ]
            },
            {
              "id": "lesson-18-2-4",
              "type": "challenge",
              "title": "Deployment Rollback Manager Challenge",
              "description": "Manage deployment rollbacks and recovery.",
              "starterCode": "#[derive(Debug, Clone)]\npub struct Deployment {\n    pub version: String,\n    pub program_id: String,\n    pub timestamp: u64,\n    pub successful: bool,\n}\n\npub struct RollbackManager {\n    deployments: Vec<Deployment>,\n    current_index: Option<usize>,\n}\n\nimpl RollbackManager {\n    pub fn new() -> Self {\n        Self { deployments: vec![], current_index: None }\n    }\n\n    pub fn record_deployment(&mut self, deployment: Deployment) {\n        // TODO: Record a new deployment\n        todo!(\"Implement record_deployment\")\n    }\n\n    pub fn can_rollback(&self) -> bool {\n        // TODO: Check if rollback is possible\n        todo!(\"Implement can_rollback\")\n    }\n\n    pub fn get_rollback_target(&self) -> Option<&Deployment> {\n        // TODO: Get the deployment to rollback to\n        todo!(\"Implement get_rollback_target\")\n    }\n\n    pub fn rollback(&mut self) -> Result<Deployment, String> {\n        // TODO: Perform rollback to previous version\n        todo!(\"Implement rollback\")\n    }\n}",
              "solution": "#[derive(Debug, Clone)]\npub struct Deployment {\n    pub version: String,\n    pub program_id: String,\n    pub timestamp: u64,\n    pub successful: bool,\n}\n\npub struct RollbackManager {\n    deployments: Vec<Deployment>,\n    current_index: Option<usize>,\n}\n\nimpl RollbackManager {\n    pub fn new() -> Self {\n        Self { deployments: vec![], current_index: None }\n    }\n\n    pub fn record_deployment(&mut self, deployment: Deployment) {\n        self.deployments.push(deployment);\n        self.current_index = Some(self.deployments.len() - 1);\n    }\n\n    pub fn can_rollback(&self) -> bool {\n        if let Some(current) = self.current_index {\n            self.deployments[..current].iter().any(|d| d.successful)\n        } else {\n            false\n        }\n    }\n\n    pub fn get_rollback_target(&self) -> Option<&Deployment> {\n        if let Some(current) = self.current_index {\n            self.deployments[..current].iter().rev().find(|d| d.successful)\n        } else {\n            None\n        }\n    }\n\n    pub fn rollback(&mut self) -> Result<Deployment, String> {\n        if !self.can_rollback() {\n            return Err(\"No rollback target available\".to_string());\n        }\n        if let Some(target) = self.get_rollback_target() {\n            let target_version = target.version.clone();\n            if let Some(target_idx) = self.deployments.iter().position(|d| d.version == target_version) {\n                self.current_index = Some(target_idx);\n                return Ok(self.deployments[target_idx].clone());\n            }\n        }\n        Err(\"Rollback failed\".to_string())\n    }\n}",
              "hints": [
                "Push deployment and update current_index to new deployment",
                "can_rollback checks for any successful deployment before current",
                "get_rollback_target finds most recent successful deployment"
              ],
              "testCases": [
                {
                  "input": {
                    "record": {
                      "version": "1.0.0",
                      "successful": true
                    }
                  },
                  "expected": {
                    "count": 1
                  }
                },
                {
                  "input": {
                    "record": [
                      {
                        "v": "1.0",
                        "ok": true
                      },
                      {
                        "v": "2.0",
                        "ok": false
                      }
                    ]
                  },
                  "expected": {
                    "can_rollback": true
                  }
                },
                {
                  "input": {
                    "record": [
                      {
                        "v": "1.0",
                        "ok": true
                      },
                      {
                        "v": "2.0",
                        "ok": false
                      }
                    ]
                  },
                  "expected": {
                    "rollback_target": "1.0.0"
                  }
                },
                {
                  "input": {
                    "record": [
                      {
                        "v": "1.0",
                        "ok": true
                      }
                    ]
                  },
                  "expected": {
                    "can_rollback": false
                  }
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}
